{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Build a feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import *\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, GlobalMaxPool1D, Flatten, Input, concatenate, Dropout, Activation, regularizers, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "print('TF version:',tf.__version__)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import classification_report,accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brizio\\Documents\\PythonNB\\FICOchallenge\n",
      "./results\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "os.chdir(cwd)\n",
    "\n",
    "RESULT_PATH = './results'\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "        os.mkdir(RESULT_PATH)\n",
    "print(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepped data\n",
    "- Normal Scaling of numeric variables: f_load_data(1)\n",
    "- Binning (following Rudin) and one hot encoding: f_load_data(2)\n",
    "- Binning and applying WOE, calculating WOE on Rudin's bins: f_load_data(3)\n",
    "- Binning and applying WOE, following Rudin: f_load_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Scaling of numeric variables (prep_option = 1)\n",
      "Target: Bad (y=1)\n",
      "Bad     5459\n",
      "Good    5000\n",
      "Name: RiskPerformance, dtype: int64\n",
      "[[   0 5000]\n",
      " [   1 5459]]\n",
      "X shape: (10459, 23)\n",
      "(7844, 23) (2615, 23) (7844, 1) (2615, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <th>AverageMInFile</th>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <th>...</th>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.588324</td>\n",
       "      <td>-0.366575</td>\n",
       "      <td>-0.341585</td>\n",
       "      <td>0.261899</td>\n",
       "      <td>0.043983</td>\n",
       "      <td>1.176415</td>\n",
       "      <td>0.060341</td>\n",
       "      <td>-0.140837</td>\n",
       "      <td>-0.232309</td>\n",
       "      <td>-0.513377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538241</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>-0.273077</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>0.045581</td>\n",
       "      <td>-1.120175</td>\n",
       "      <td>1.091102</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.292417</td>\n",
       "      <td>0.249757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304241</td>\n",
       "      <td>-1.150684</td>\n",
       "      <td>0.485414</td>\n",
       "      <td>-0.846892</td>\n",
       "      <td>-1.340237</td>\n",
       "      <td>1.574221</td>\n",
       "      <td>1.750041</td>\n",
       "      <td>0.513051</td>\n",
       "      <td>-0.671328</td>\n",
       "      <td>-1.312078</td>\n",
       "      <td>...</td>\n",
       "      <td>1.730629</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>-0.273077</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>-1.052271</td>\n",
       "      <td>-1.120175</td>\n",
       "      <td>-0.721739</td>\n",
       "      <td>-2.210425</td>\n",
       "      <td>-2.387770</td>\n",
       "      <td>-2.240297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.020158</td>\n",
       "      <td>-1.077744</td>\n",
       "      <td>-0.266403</td>\n",
       "      <td>-1.285252</td>\n",
       "      <td>-0.801929</td>\n",
       "      <td>-0.017002</td>\n",
       "      <td>0.060341</td>\n",
       "      <td>0.513051</td>\n",
       "      <td>-0.671328</td>\n",
       "      <td>0.551559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587924</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>0.985121</td>\n",
       "      <td>1.013949</td>\n",
       "      <td>0.710946</td>\n",
       "      <td>0.637562</td>\n",
       "      <td>0.184681</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.292417</td>\n",
       "      <td>0.863249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067506</td>\n",
       "      <td>-0.138636</td>\n",
       "      <td>-0.567130</td>\n",
       "      <td>-0.021745</td>\n",
       "      <td>0.659193</td>\n",
       "      <td>0.380804</td>\n",
       "      <td>0.482766</td>\n",
       "      <td>0.243803</td>\n",
       "      <td>3.377399</td>\n",
       "      <td>0.285325</td>\n",
       "      <td>...</td>\n",
       "      <td>1.233801</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>1.299670</td>\n",
       "      <td>1.013949</td>\n",
       "      <td>1.343042</td>\n",
       "      <td>1.041366</td>\n",
       "      <td>0.637892</td>\n",
       "      <td>0.744657</td>\n",
       "      <td>0.888014</td>\n",
       "      <td>1.043688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642701</td>\n",
       "      <td>1.356643</td>\n",
       "      <td>1.387594</td>\n",
       "      <td>1.499621</td>\n",
       "      <td>-0.571226</td>\n",
       "      <td>-0.017002</td>\n",
       "      <td>0.060341</td>\n",
       "      <td>0.513051</td>\n",
       "      <td>-0.671328</td>\n",
       "      <td>0.551559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356050</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>0.041473</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>0.644409</td>\n",
       "      <td>1.183886</td>\n",
       "      <td>-0.041924</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>0.646722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExternalRiskEstimate  MSinceOldestTradeOpen  MSinceMostRecentTradeOpen  \\\n",
       "0             -0.588324              -0.366575                  -0.341585   \n",
       "1             -0.304241              -1.150684                   0.485414   \n",
       "2             -0.020158              -1.077744                  -0.266403   \n",
       "3             -0.067506              -0.138636                  -0.567130   \n",
       "4              0.642701               1.356643                   1.387594   \n",
       "\n",
       "   AverageMInFile  NumSatisfactoryTrades  NumTrades60Ever2DerogPubRec  \\\n",
       "0        0.261899               0.043983                     1.176415   \n",
       "1       -0.846892              -1.340237                     1.574221   \n",
       "2       -1.285252              -0.801929                    -0.017002   \n",
       "3       -0.021745               0.659193                     0.380804   \n",
       "4        1.499621              -0.571226                    -0.017002   \n",
       "\n",
       "   NumTrades90Ever2DerogPubRec  PercentTradesNeverDelq  MSinceMostRecentDelq  \\\n",
       "0                     0.060341               -0.140837             -0.232309   \n",
       "1                     1.750041                0.513051             -0.671328   \n",
       "2                     0.060341                0.513051             -0.671328   \n",
       "3                     0.482766                0.243803              3.377399   \n",
       "4                     0.060341                0.513051             -0.671328   \n",
       "\n",
       "   MaxDelq2PublicRecLast12M  ...  PercentInstallTrades  \\\n",
       "0                 -0.513377  ...              0.538241   \n",
       "1                 -1.312078  ...              1.730629   \n",
       "2                  0.551559  ...              0.587924   \n",
       "3                  0.285325  ...              1.233801   \n",
       "4                  0.551559  ...             -0.356050   \n",
       "\n",
       "   MSinceMostRecentInqexcl7days  NumInqLast6M  NumInqLast6Mexcl7days  \\\n",
       "0                      0.053626     -0.273077              -0.258498   \n",
       "1                      0.053626     -0.273077              -0.258498   \n",
       "2                      0.053626      0.985121               1.013949   \n",
       "3                      0.053626      1.299670               1.013949   \n",
       "4                      0.053626      0.041473               0.059614   \n",
       "\n",
       "   NetFractionRevolvingBurden  NetFractionInstallBurden  \\\n",
       "0                    0.045581                 -1.120175   \n",
       "1                   -1.052271                 -1.120175   \n",
       "2                    0.710946                  0.637562   \n",
       "3                    1.343042                  1.041366   \n",
       "4                    0.644409                  1.183886   \n",
       "\n",
       "   NumRevolvingTradesWBalance  NumInstallTradesWBalance  \\\n",
       "0                    1.091102                  0.005886   \n",
       "1                   -0.721739                 -2.210425   \n",
       "2                    0.184681                  0.252143   \n",
       "3                    0.637892                  0.744657   \n",
       "4                   -0.041924                  0.005886   \n",
       "\n",
       "   NumBank2NatlTradesWHighUtilization  PercentTradesWBalance  \n",
       "0                            0.292417               0.249757  \n",
       "1                           -2.387770              -2.240297  \n",
       "2                            0.292417               0.863249  \n",
       "3                            0.888014               1.043688  \n",
       "4                           -0.005381               0.646722  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, X1, y, y_onehot = f_load_data(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y_onehot, test_size = .25, random_state = 2020, shuffle = True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and/or Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "\n",
    "def get_FFNN_model(X, y, hidden_layers_size = [4]):\n",
    "    \"\"\"\n",
    "        BASIC MODEL for the FF-NN\n",
    "    \"\"\"\n",
    "    input_size = len(X.columns.values)\n",
    "    output_size = len(y.columns.values)\n",
    "    \n",
    "    if len(hidden_layers_size) == 0:\n",
    "        # No hidden layer (linear regression equivalent)\n",
    "        ff_layers = [ Dense(output_size, input_shape=(input_size,), activation='softmax') ]\n",
    "    else:\n",
    "        ff_layers = [\n",
    "            tf.keras.layers.Dense(hidden_layers_size[0], input_shape=(input_size,), activation=ACTIVATION,\n",
    "                  kernel_initializer='he_uniform'\n",
    "#                   bias_initializer = 'zeros',\n",
    "                ## specific layer regularizer\n",
    "#                   kernel_regularizer=regularizers.l1(0.001)\n",
    "#                   ,activity_regularizer=regularizers.l2(0.001)\n",
    "                 ),\n",
    "            ## batch normalisation\n",
    "#             tf.keras.layers.BatchNormalization(),  # <- Batch normalisation layer\n",
    "            ## dropout\n",
    "#             Dropout(0.3),\n",
    "            ## elastic regularization\n",
    "#             Dense(hidden_layers_size[0], input_shape=(input_size,), activation='sigmoid', activity_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)),\n",
    "            tf.keras.layers.Dense(output_size, activation='sigmoid') \n",
    "        ]\n",
    "          \n",
    "            \n",
    "    print(ff_layers)\n",
    "    model = tf.keras.models.Sequential(ff_layers)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=L_RATE),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy','AUC',recall_m,precision_m,f1_m])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "\n",
    "def net_train(model, bestmodel_path, X_train, y_train_onehot, X_validate, y_validate_onehot, epochs, save_model, VERBOSE):\n",
    "    # Define four callbacks to use\n",
    "    checkpointer = ModelCheckpoint(filepath = bestmodel_path, verbose = VERBOSE, save_best_only = True, save_weights_only=False)\n",
    "    early_stopping = EarlyStopping(monitor = 'val_acc', mode = 'max', patience = PATIENCE)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 20, verbose = VERBOSE)\n",
    "\n",
    "    # Train the model\n",
    "    if save_model:\n",
    "        history = model.fit(X_train, y_train_onehot, verbose = VERBOSE, epochs=epochs, batch_size=BATCH_SIZE, \n",
    "                            callbacks=[\n",
    "                                checkpointer,\n",
    "                                early_stopping, \n",
    "                                learning_rate_reduction\n",
    "                            ], \n",
    "    #                         validation_data=(X_validate, y_validate_onehot)\n",
    "                            validation_split = 0.2\n",
    "                           )\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train_onehot, verbose = VERBOSE, epochs=epochs, batch_size=BATCH_SIZE, \n",
    "                            callbacks=[\n",
    "                                early_stopping, \n",
    "                                learning_rate_reduction\n",
    "                            ], \n",
    "                            validation_split = 0.2\n",
    "                           )        \n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Dense object at 0x000001838638C408>, <tensorflow.python.keras.layers.core.Dense object at 0x000001838C08F488>]\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6694 samples, validate on 1674 samples\n",
      "Epoch 1/500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56627, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 3s - loss: 0.6168 - acc: 0.6612 - auc_32: 0.7215 - recall_m: 0.6987 - precision_m: 0.6735 - f1_m: 0.6580 - val_loss: 0.5663 - val_acc: 0.7168 - val_auc_32: 0.7855 - val_recall_m: 0.7688 - val_precision_m: 0.6718 - val_f1_m: 0.6923\n",
      "Epoch 2/500\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56627 to 0.54783, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 1s - loss: 0.5623 - acc: 0.7217 - auc_32: 0.7818 - recall_m: 0.7569 - precision_m: 0.7195 - f1_m: 0.7153 - val_loss: 0.5478 - val_acc: 0.7401 - val_auc_32: 0.8023 - val_recall_m: 0.7777 - val_precision_m: 0.7046 - val_f1_m: 0.7154\n",
      "Epoch 3/500\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.54783\n",
      "6694/6694 - 2s - loss: 0.5563 - acc: 0.7227 - auc_32: 0.7874 - recall_m: 0.7604 - precision_m: 0.7215 - f1_m: 0.7170 - val_loss: 0.5483 - val_acc: 0.7306 - val_auc_32: 0.8026 - val_recall_m: 0.7981 - val_precision_m: 0.6996 - val_f1_m: 0.7167\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54783 to 0.54769, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 2s - loss: 0.5533 - acc: 0.7235 - auc_32: 0.7904 - recall_m: 0.7582 - precision_m: 0.7282 - f1_m: 0.7187 - val_loss: 0.5477 - val_acc: 0.7330 - val_auc_32: 0.8007 - val_recall_m: 0.7651 - val_precision_m: 0.6995 - val_f1_m: 0.7111\n",
      "Epoch 5/500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54769 to 0.54258, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 1s - loss: 0.5516 - acc: 0.7263 - auc_32: 0.7916 - recall_m: 0.7659 - precision_m: 0.7255 - f1_m: 0.7223 - val_loss: 0.5426 - val_acc: 0.7354 - val_auc_32: 0.8056 - val_recall_m: 0.7823 - val_precision_m: 0.7027 - val_f1_m: 0.7154\n",
      "Epoch 6/500\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54258 to 0.54056, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 1s - loss: 0.5505 - acc: 0.7253 - auc_32: 0.7924 - recall_m: 0.7692 - precision_m: 0.7270 - f1_m: 0.7246 - val_loss: 0.5406 - val_acc: 0.7360 - val_auc_32: 0.8068 - val_recall_m: 0.7848 - val_precision_m: 0.7070 - val_f1_m: 0.7242\n",
      "Epoch 7/500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.54056\n",
      "6694/6694 - 1s - loss: 0.5489 - acc: 0.7248 - auc_32: 0.7944 - recall_m: 0.7623 - precision_m: 0.7260 - f1_m: 0.7180 - val_loss: 0.5500 - val_acc: 0.7288 - val_auc_32: 0.7992 - val_recall_m: 0.7935 - val_precision_m: 0.7117 - val_f1_m: 0.7223\n",
      "Epoch 8/500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.54056\n",
      "6694/6694 - 2s - loss: 0.5481 - acc: 0.7289 - auc_32: 0.7946 - recall_m: 0.7776 - precision_m: 0.7330 - f1_m: 0.7290 - val_loss: 0.5427 - val_acc: 0.7312 - val_auc_32: 0.8055 - val_recall_m: 0.7838 - val_precision_m: 0.6991 - val_f1_m: 0.7159\n",
      "Epoch 9/500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54056\n",
      "6694/6694 - 2s - loss: 0.5475 - acc: 0.7283 - auc_32: 0.7955 - recall_m: 0.7647 - precision_m: 0.7261 - f1_m: 0.7227 - val_loss: 0.5443 - val_acc: 0.7461 - val_auc_32: 0.8082 - val_recall_m: 0.7924 - val_precision_m: 0.7064 - val_f1_m: 0.7260\n",
      "Epoch 10/500\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54056\n",
      "6694/6694 - 1s - loss: 0.5460 - acc: 0.7289 - auc_32: 0.7964 - recall_m: 0.7692 - precision_m: 0.7290 - f1_m: 0.7238 - val_loss: 0.5451 - val_acc: 0.7318 - val_auc_32: 0.8057 - val_recall_m: 0.7887 - val_precision_m: 0.6820 - val_f1_m: 0.7119\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54056 to 0.53803, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 2s - loss: 0.5459 - acc: 0.7295 - auc_32: 0.7966 - recall_m: 0.7790 - precision_m: 0.7332 - f1_m: 0.7311 - val_loss: 0.5380 - val_acc: 0.7473 - val_auc_32: 0.8085 - val_recall_m: 0.7777 - val_precision_m: 0.7251 - val_f1_m: 0.7273\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5460 - acc: 0.7290 - auc_32: 0.7966 - recall_m: 0.7794 - precision_m: 0.7360 - f1_m: 0.7306 - val_loss: 0.5530 - val_acc: 0.7294 - val_auc_32: 0.7954 - val_recall_m: 0.7874 - val_precision_m: 0.7013 - val_f1_m: 0.7158\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.53803\n",
      "6694/6694 - 2s - loss: 0.5455 - acc: 0.7275 - auc_32: 0.7971 - recall_m: 0.7714 - precision_m: 0.7312 - f1_m: 0.7257 - val_loss: 0.5425 - val_acc: 0.7306 - val_auc_32: 0.8059 - val_recall_m: 0.7944 - val_precision_m: 0.6969 - val_f1_m: 0.7167\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5445 - acc: 0.7278 - auc_32: 0.7979 - recall_m: 0.7691 - precision_m: 0.7313 - f1_m: 0.7237 - val_loss: 0.5419 - val_acc: 0.7330 - val_auc_32: 0.8097 - val_recall_m: 0.8087 - val_precision_m: 0.6905 - val_f1_m: 0.7156\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.53803\n",
      "6694/6694 - 2s - loss: 0.5437 - acc: 0.7283 - auc_32: 0.7985 - recall_m: 0.7619 - precision_m: 0.7223 - f1_m: 0.7188 - val_loss: 0.5452 - val_acc: 0.7312 - val_auc_32: 0.8042 - val_recall_m: 0.7948 - val_precision_m: 0.6970 - val_f1_m: 0.7179\n",
      "Epoch 16/500\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.53803\n",
      "6694/6694 - 2s - loss: 0.5435 - acc: 0.7311 - auc_32: 0.7988 - recall_m: 0.7789 - precision_m: 0.7257 - f1_m: 0.7276 - val_loss: 0.5402 - val_acc: 0.7348 - val_auc_32: 0.8089 - val_recall_m: 0.8066 - val_precision_m: 0.7009 - val_f1_m: 0.7290\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5430 - acc: 0.7302 - auc_32: 0.7991 - recall_m: 0.7726 - precision_m: 0.7267 - f1_m: 0.7263 - val_loss: 0.5415 - val_acc: 0.7306 - val_auc_32: 0.8073 - val_recall_m: 0.8027 - val_precision_m: 0.6991 - val_f1_m: 0.7247\n",
      "Epoch 18/500\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5421 - acc: 0.7304 - auc_32: 0.8002 - recall_m: 0.7771 - precision_m: 0.7305 - f1_m: 0.7290 - val_loss: 0.5395 - val_acc: 0.7336 - val_auc_32: 0.8084 - val_recall_m: 0.7853 - val_precision_m: 0.6852 - val_f1_m: 0.7091\n",
      "Epoch 19/500\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5423 - acc: 0.7296 - auc_32: 0.8002 - recall_m: 0.7691 - precision_m: 0.7228 - f1_m: 0.7220 - val_loss: 0.5417 - val_acc: 0.7306 - val_auc_32: 0.8085 - val_recall_m: 0.7932 - val_precision_m: 0.6917 - val_f1_m: 0.7147\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5415 - acc: 0.7317 - auc_32: 0.8005 - recall_m: 0.7781 - precision_m: 0.7237 - f1_m: 0.7279 - val_loss: 0.5446 - val_acc: 0.7318 - val_auc_32: 0.8052 - val_recall_m: 0.7901 - val_precision_m: 0.6965 - val_f1_m: 0.7122\n",
      "Epoch 21/500\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5412 - acc: 0.7295 - auc_32: 0.8009 - recall_m: 0.7756 - precision_m: 0.7294 - f1_m: 0.7284 - val_loss: 0.5442 - val_acc: 0.7306 - val_auc_32: 0.8057 - val_recall_m: 0.7898 - val_precision_m: 0.6873 - val_f1_m: 0.7135\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5399 - acc: 0.7289 - auc_32: 0.8022 - recall_m: 0.7754 - precision_m: 0.7340 - f1_m: 0.7303 - val_loss: 0.5380 - val_acc: 0.7312 - val_auc_32: 0.8081 - val_recall_m: 0.7970 - val_precision_m: 0.7018 - val_f1_m: 0.7132\n",
      "Epoch 23/500\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5401 - acc: 0.7318 - auc_32: 0.8019 - recall_m: 0.7701 - precision_m: 0.7238 - f1_m: 0.7235 - val_loss: 0.5440 - val_acc: 0.7318 - val_auc_32: 0.8024 - val_recall_m: 0.7872 - val_precision_m: 0.7100 - val_f1_m: 0.7228\n",
      "Epoch 24/500\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5399 - acc: 0.7299 - auc_32: 0.8018 - recall_m: 0.7736 - precision_m: 0.7310 - f1_m: 0.7272 - val_loss: 0.5406 - val_acc: 0.7246 - val_auc_32: 0.8089 - val_recall_m: 0.7905 - val_precision_m: 0.6958 - val_f1_m: 0.7109\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5401 - acc: 0.7259 - auc_32: 0.8018 - recall_m: 0.7719 - precision_m: 0.7272 - f1_m: 0.7233 - val_loss: 0.5428 - val_acc: 0.7288 - val_auc_32: 0.8049 - val_recall_m: 0.7727 - val_precision_m: 0.6999 - val_f1_m: 0.7080\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5383 - acc: 0.7326 - auc_32: 0.8036 - recall_m: 0.7730 - precision_m: 0.7374 - f1_m: 0.7309 - val_loss: 0.5414 - val_acc: 0.7372 - val_auc_32: 0.8094 - val_recall_m: 0.7872 - val_precision_m: 0.6983 - val_f1_m: 0.7160\n",
      "Epoch 27/500\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.53803\n",
      "6694/6694 - 1s - loss: 0.5389 - acc: 0.7317 - auc_32: 0.8029 - recall_m: 0.7760 - precision_m: 0.7283 - f1_m: 0.7267 - val_loss: 0.5431 - val_acc: 0.7288 - val_auc_32: 0.8034 - val_recall_m: 0.7738 - val_precision_m: 0.6952 - val_f1_m: 0.7108\n",
      "Epoch 28/500\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.53803 to 0.53742, saving model to ./results\\FF_ori_ep500_pa500_bs8_hs[10]_lr_0.001_relu\n",
      "6694/6694 - 1s - loss: 0.5386 - acc: 0.7304 - auc_32: 0.8033 - recall_m: 0.7727 - precision_m: 0.7280 - f1_m: 0.7251 - val_loss: 0.5374 - val_acc: 0.7378 - val_auc_32: 0.8095 - val_recall_m: 0.7616 - val_precision_m: 0.7076 - val_f1_m: 0.7097\n",
      "Epoch 29/500\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5378 - acc: 0.7311 - auc_32: 0.8041 - recall_m: 0.7705 - precision_m: 0.7304 - f1_m: 0.7262 - val_loss: 0.5404 - val_acc: 0.7336 - val_auc_32: 0.8092 - val_recall_m: 0.7629 - val_precision_m: 0.6868 - val_f1_m: 0.7008\n",
      "Epoch 30/500\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5375 - acc: 0.7330 - auc_32: 0.8042 - recall_m: 0.7778 - precision_m: 0.7324 - f1_m: 0.7317 - val_loss: 0.5480 - val_acc: 0.7264 - val_auc_32: 0.8026 - val_recall_m: 0.7978 - val_precision_m: 0.7000 - val_f1_m: 0.7198\n",
      "Epoch 31/500\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5370 - acc: 0.7295 - auc_32: 0.8047 - recall_m: 0.7741 - precision_m: 0.7294 - f1_m: 0.7270 - val_loss: 0.5451 - val_acc: 0.7234 - val_auc_32: 0.8055 - val_recall_m: 0.7868 - val_precision_m: 0.6739 - val_f1_m: 0.7009\n",
      "Epoch 32/500\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5375 - acc: 0.7323 - auc_32: 0.8039 - recall_m: 0.7841 - precision_m: 0.7308 - f1_m: 0.7323 - val_loss: 0.5410 - val_acc: 0.7240 - val_auc_32: 0.8083 - val_recall_m: 0.7851 - val_precision_m: 0.6902 - val_f1_m: 0.7091\n",
      "Epoch 33/500\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5370 - acc: 0.7313 - auc_32: 0.8043 - recall_m: 0.7787 - precision_m: 0.7256 - f1_m: 0.7274 - val_loss: 0.5391 - val_acc: 0.7246 - val_auc_32: 0.8081 - val_recall_m: 0.7870 - val_precision_m: 0.6916 - val_f1_m: 0.7120\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5355 - acc: 0.7345 - auc_32: 0.8059 - recall_m: 0.7798 - precision_m: 0.7365 - f1_m: 0.7333 - val_loss: 0.5440 - val_acc: 0.7240 - val_auc_32: 0.8072 - val_recall_m: 0.7984 - val_precision_m: 0.6731 - val_f1_m: 0.7079\n",
      "Epoch 35/500\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5358 - acc: 0.7317 - auc_32: 0.8056 - recall_m: 0.7811 - precision_m: 0.7321 - f1_m: 0.7310 - val_loss: 0.5489 - val_acc: 0.7222 - val_auc_32: 0.7999 - val_recall_m: 0.7886 - val_precision_m: 0.6886 - val_f1_m: 0.7088\n",
      "Epoch 36/500\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5359 - acc: 0.7302 - auc_32: 0.8055 - recall_m: 0.7738 - precision_m: 0.7317 - f1_m: 0.7275 - val_loss: 0.5483 - val_acc: 0.7228 - val_auc_32: 0.8070 - val_recall_m: 0.8217 - val_precision_m: 0.6808 - val_f1_m: 0.7197\n",
      "Epoch 37/500\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5349 - acc: 0.7354 - auc_32: 0.8063 - recall_m: 0.7812 - precision_m: 0.7333 - f1_m: 0.7321 - val_loss: 0.5446 - val_acc: 0.7264 - val_auc_32: 0.8075 - val_recall_m: 0.7974 - val_precision_m: 0.6843 - val_f1_m: 0.7114\n",
      "Epoch 38/500\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5356 - acc: 0.7307 - auc_32: 0.8056 - recall_m: 0.7745 - precision_m: 0.7263 - f1_m: 0.7272 - val_loss: 0.5430 - val_acc: 0.7240 - val_auc_32: 0.8062 - val_recall_m: 0.7973 - val_precision_m: 0.6909 - val_f1_m: 0.7173\n",
      "Epoch 39/500\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5349 - acc: 0.7298 - auc_32: 0.8063 - recall_m: 0.7781 - precision_m: 0.7291 - f1_m: 0.7293 - val_loss: 0.5434 - val_acc: 0.7258 - val_auc_32: 0.8063 - val_recall_m: 0.8065 - val_precision_m: 0.6928 - val_f1_m: 0.7209\n",
      "Epoch 40/500\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5343 - acc: 0.7342 - auc_32: 0.8070 - recall_m: 0.7867 - precision_m: 0.7320 - f1_m: 0.7342 - val_loss: 0.5439 - val_acc: 0.7258 - val_auc_32: 0.8069 - val_recall_m: 0.8034 - val_precision_m: 0.6923 - val_f1_m: 0.7194\n",
      "Epoch 41/500\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5347 - acc: 0.7327 - auc_32: 0.8062 - recall_m: 0.7810 - precision_m: 0.7292 - f1_m: 0.7298 - val_loss: 0.5439 - val_acc: 0.7252 - val_auc_32: 0.8073 - val_recall_m: 0.7866 - val_precision_m: 0.6719 - val_f1_m: 0.7028\n",
      "Epoch 42/500\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5346 - acc: 0.7286 - auc_32: 0.8065 - recall_m: 0.7735 - precision_m: 0.7254 - f1_m: 0.7282 - val_loss: 0.5458 - val_acc: 0.7222 - val_auc_32: 0.8058 - val_recall_m: 0.7876 - val_precision_m: 0.6770 - val_f1_m: 0.7077\n",
      "Epoch 43/500\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5340 - acc: 0.7338 - auc_32: 0.8069 - recall_m: 0.7856 - precision_m: 0.7302 - f1_m: 0.7351 - val_loss: 0.5434 - val_acc: 0.7234 - val_auc_32: 0.8062 - val_recall_m: 0.7949 - val_precision_m: 0.6868 - val_f1_m: 0.7134\n",
      "Epoch 44/500\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5333 - acc: 0.7316 - auc_32: 0.8078 - recall_m: 0.7771 - precision_m: 0.7272 - f1_m: 0.7276 - val_loss: 0.5395 - val_acc: 0.7258 - val_auc_32: 0.8075 - val_recall_m: 0.7692 - val_precision_m: 0.6871 - val_f1_m: 0.7032\n",
      "Epoch 45/500\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5338 - acc: 0.7307 - auc_32: 0.8071 - recall_m: 0.7686 - precision_m: 0.7319 - f1_m: 0.7260 - val_loss: 0.5443 - val_acc: 0.7240 - val_auc_32: 0.8077 - val_recall_m: 0.7912 - val_precision_m: 0.6784 - val_f1_m: 0.7076\n",
      "Epoch 46/500\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5332 - acc: 0.7335 - auc_32: 0.8075 - recall_m: 0.7807 - precision_m: 0.7282 - f1_m: 0.7280 - val_loss: 0.5457 - val_acc: 0.7264 - val_auc_32: 0.8075 - val_recall_m: 0.8073 - val_precision_m: 0.6807 - val_f1_m: 0.7198\n",
      "Epoch 47/500\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5337 - acc: 0.7292 - auc_32: 0.8071 - recall_m: 0.7800 - precision_m: 0.7265 - f1_m: 0.7283 - val_loss: 0.5416 - val_acc: 0.7234 - val_auc_32: 0.8050 - val_recall_m: 0.7878 - val_precision_m: 0.6983 - val_f1_m: 0.7149\n",
      "Epoch 48/500\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5335 - acc: 0.7344 - auc_32: 0.8074 - recall_m: 0.7882 - precision_m: 0.7374 - f1_m: 0.7372 - val_loss: 0.5460 - val_acc: 0.7234 - val_auc_32: 0.8043 - val_recall_m: 0.7945 - val_precision_m: 0.6880 - val_f1_m: 0.7084\n",
      "Epoch 49/500\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5328 - acc: 0.7330 - auc_32: 0.8079 - recall_m: 0.7804 - precision_m: 0.7313 - f1_m: 0.7300 - val_loss: 0.5460 - val_acc: 0.7240 - val_auc_32: 0.8049 - val_recall_m: 0.8032 - val_precision_m: 0.6763 - val_f1_m: 0.7121\n",
      "Epoch 50/500\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5326 - acc: 0.7359 - auc_32: 0.8083 - recall_m: 0.7798 - precision_m: 0.7355 - f1_m: 0.7333 - val_loss: 0.5466 - val_acc: 0.7228 - val_auc_32: 0.8051 - val_recall_m: 0.8139 - val_precision_m: 0.6849 - val_f1_m: 0.7183\n",
      "Epoch 51/500\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5325 - acc: 0.7369 - auc_32: 0.8084 - recall_m: 0.7801 - precision_m: 0.7358 - f1_m: 0.7353 - val_loss: 0.5416 - val_acc: 0.7372 - val_auc_32: 0.8083 - val_recall_m: 0.7827 - val_precision_m: 0.7086 - val_f1_m: 0.7171\n",
      "Epoch 52/500\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5328 - acc: 0.7320 - auc_32: 0.8082 - recall_m: 0.7806 - precision_m: 0.7361 - f1_m: 0.7316 - val_loss: 0.5444 - val_acc: 0.7222 - val_auc_32: 0.8048 - val_recall_m: 0.7882 - val_precision_m: 0.6937 - val_f1_m: 0.7110\n",
      "Epoch 53/500\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5321 - acc: 0.7344 - auc_32: 0.8087 - recall_m: 0.7834 - precision_m: 0.7379 - f1_m: 0.7357 - val_loss: 0.5483 - val_acc: 0.7186 - val_auc_32: 0.8026 - val_recall_m: 0.7844 - val_precision_m: 0.6757 - val_f1_m: 0.7043\n",
      "Epoch 54/500\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5321 - acc: 0.7347 - auc_32: 0.8086 - recall_m: 0.7871 - precision_m: 0.7311 - f1_m: 0.7346 - val_loss: 0.5426 - val_acc: 0.7240 - val_auc_32: 0.8061 - val_recall_m: 0.7859 - val_precision_m: 0.6876 - val_f1_m: 0.7097\n",
      "Epoch 55/500\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5321 - acc: 0.7338 - auc_32: 0.8088 - recall_m: 0.7785 - precision_m: 0.7382 - f1_m: 0.7339 - val_loss: 0.5416 - val_acc: 0.7246 - val_auc_32: 0.8052 - val_recall_m: 0.7617 - val_precision_m: 0.6881 - val_f1_m: 0.6992\n",
      "Epoch 56/500\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5323 - acc: 0.7318 - auc_32: 0.8081 - recall_m: 0.7825 - precision_m: 0.7395 - f1_m: 0.7334 - val_loss: 0.5418 - val_acc: 0.7264 - val_auc_32: 0.8060 - val_recall_m: 0.7766 - val_precision_m: 0.6878 - val_f1_m: 0.7069\n",
      "Epoch 57/500\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5319 - acc: 0.7333 - auc_32: 0.8090 - recall_m: 0.7805 - precision_m: 0.7314 - f1_m: 0.7326 - val_loss: 0.5412 - val_acc: 0.7354 - val_auc_32: 0.8061 - val_recall_m: 0.7767 - val_precision_m: 0.7145 - val_f1_m: 0.7207\n",
      "Epoch 58/500\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5323 - acc: 0.7353 - auc_32: 0.8085 - recall_m: 0.7819 - precision_m: 0.7384 - f1_m: 0.7356 - val_loss: 0.5430 - val_acc: 0.7354 - val_auc_32: 0.8067 - val_recall_m: 0.7801 - val_precision_m: 0.6964 - val_f1_m: 0.7084\n",
      "Epoch 59/500\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5324 - acc: 0.7330 - auc_32: 0.8083 - recall_m: 0.7829 - precision_m: 0.7271 - f1_m: 0.7308 - val_loss: 0.5468 - val_acc: 0.7258 - val_auc_32: 0.8015 - val_recall_m: 0.7865 - val_precision_m: 0.6936 - val_f1_m: 0.7086\n",
      "Epoch 60/500\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5321 - acc: 0.7341 - auc_32: 0.8086 - recall_m: 0.7793 - precision_m: 0.7367 - f1_m: 0.7338 - val_loss: 0.5449 - val_acc: 0.7234 - val_auc_32: 0.8046 - val_recall_m: 0.7839 - val_precision_m: 0.6790 - val_f1_m: 0.6994\n",
      "Epoch 61/500\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5317 - acc: 0.7333 - auc_32: 0.8089 - recall_m: 0.7846 - precision_m: 0.7315 - f1_m: 0.7317 - val_loss: 0.5463 - val_acc: 0.7240 - val_auc_32: 0.8052 - val_recall_m: 0.7949 - val_precision_m: 0.6925 - val_f1_m: 0.7144\n",
      "Epoch 62/500\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5318 - acc: 0.7335 - auc_32: 0.8087 - recall_m: 0.7890 - precision_m: 0.7334 - f1_m: 0.7334 - val_loss: 0.5452 - val_acc: 0.7252 - val_auc_32: 0.8055 - val_recall_m: 0.7902 - val_precision_m: 0.6831 - val_f1_m: 0.7092\n",
      "Epoch 63/500\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5310 - acc: 0.7321 - auc_32: 0.8095 - recall_m: 0.7737 - precision_m: 0.7376 - f1_m: 0.7293 - val_loss: 0.5643 - val_acc: 0.7240 - val_auc_32: 0.7887 - val_recall_m: 0.7855 - val_precision_m: 0.6937 - val_f1_m: 0.7133\n",
      "Epoch 64/500\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5312 - acc: 0.7359 - auc_32: 0.8094 - recall_m: 0.7829 - precision_m: 0.7317 - f1_m: 0.7316 - val_loss: 0.5448 - val_acc: 0.7276 - val_auc_32: 0.8057 - val_recall_m: 0.8044 - val_precision_m: 0.6983 - val_f1_m: 0.7204\n",
      "Epoch 65/500\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.53742\n",
      "6694/6694 - 3s - loss: 0.5313 - acc: 0.7336 - auc_32: 0.8094 - recall_m: 0.7804 - precision_m: 0.7358 - f1_m: 0.7330 - val_loss: 0.5569 - val_acc: 0.7210 - val_auc_32: 0.7998 - val_recall_m: 0.8032 - val_precision_m: 0.6767 - val_f1_m: 0.7095\n",
      "Epoch 66/500\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5317 - acc: 0.7362 - auc_32: 0.8090 - recall_m: 0.7762 - precision_m: 0.7363 - f1_m: 0.7313 - val_loss: 0.5462 - val_acc: 0.7240 - val_auc_32: 0.8062 - val_recall_m: 0.7992 - val_precision_m: 0.6777 - val_f1_m: 0.7102\n",
      "Epoch 67/500\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5311 - acc: 0.7318 - auc_32: 0.8091 - recall_m: 0.7769 - precision_m: 0.7274 - f1_m: 0.7280 - val_loss: 0.5507 - val_acc: 0.7222 - val_auc_32: 0.8034 - val_recall_m: 0.7982 - val_precision_m: 0.6702 - val_f1_m: 0.7075\n",
      "Epoch 68/500\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5320 - acc: 0.7323 - auc_32: 0.8087 - recall_m: 0.7829 - precision_m: 0.7388 - f1_m: 0.7342 - val_loss: 0.5475 - val_acc: 0.7234 - val_auc_32: 0.8062 - val_recall_m: 0.8083 - val_precision_m: 0.6852 - val_f1_m: 0.7162\n",
      "Epoch 69/500\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5313 - acc: 0.7332 - auc_32: 0.8093 - recall_m: 0.7828 - precision_m: 0.7383 - f1_m: 0.7345 - val_loss: 0.5449 - val_acc: 0.7246 - val_auc_32: 0.8026 - val_recall_m: 0.7807 - val_precision_m: 0.6946 - val_f1_m: 0.7098\n",
      "Epoch 70/500\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5314 - acc: 0.7324 - auc_32: 0.8092 - recall_m: 0.7770 - precision_m: 0.7311 - f1_m: 0.7293 - val_loss: 0.5398 - val_acc: 0.7366 - val_auc_32: 0.8077 - val_recall_m: 0.7622 - val_precision_m: 0.6901 - val_f1_m: 0.7038\n",
      "Epoch 71/500\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5318 - acc: 0.7339 - auc_32: 0.8087 - recall_m: 0.7661 - precision_m: 0.7340 - f1_m: 0.7257 - val_loss: 0.5508 - val_acc: 0.7252 - val_auc_32: 0.8007 - val_recall_m: 0.7878 - val_precision_m: 0.6792 - val_f1_m: 0.7040\n",
      "Epoch 72/500\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5306 - acc: 0.7327 - auc_32: 0.8100 - recall_m: 0.7854 - precision_m: 0.7296 - f1_m: 0.7299 - val_loss: 0.5432 - val_acc: 0.7252 - val_auc_32: 0.8036 - val_recall_m: 0.7598 - val_precision_m: 0.6924 - val_f1_m: 0.6995\n",
      "Epoch 73/500\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5315 - acc: 0.7332 - auc_32: 0.8090 - recall_m: 0.7747 - precision_m: 0.7311 - f1_m: 0.7282 - val_loss: 0.5529 - val_acc: 0.7252 - val_auc_32: 0.7992 - val_recall_m: 0.8005 - val_precision_m: 0.6846 - val_f1_m: 0.7143\n",
      "Epoch 74/500\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5308 - acc: 0.7342 - auc_32: 0.8098 - recall_m: 0.7819 - precision_m: 0.7349 - f1_m: 0.7344 - val_loss: 0.5443 - val_acc: 0.7294 - val_auc_32: 0.8052 - val_recall_m: 0.7812 - val_precision_m: 0.6850 - val_f1_m: 0.7027\n",
      "Epoch 75/500\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5303 - acc: 0.7336 - auc_32: 0.8099 - recall_m: 0.7835 - precision_m: 0.7335 - f1_m: 0.7350 - val_loss: 0.5506 - val_acc: 0.7198 - val_auc_32: 0.8026 - val_recall_m: 0.7996 - val_precision_m: 0.6745 - val_f1_m: 0.7045\n",
      "Epoch 76/500\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5314 - acc: 0.7308 - auc_32: 0.8087 - recall_m: 0.7794 - precision_m: 0.7269 - f1_m: 0.7282 - val_loss: 0.5420 - val_acc: 0.7360 - val_auc_32: 0.8062 - val_recall_m: 0.7772 - val_precision_m: 0.7082 - val_f1_m: 0.7160\n",
      "Epoch 77/500\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5309 - acc: 0.7307 - auc_32: 0.8094 - recall_m: 0.7707 - precision_m: 0.7320 - f1_m: 0.7250 - val_loss: 0.5523 - val_acc: 0.7246 - val_auc_32: 0.8004 - val_recall_m: 0.7977 - val_precision_m: 0.6915 - val_f1_m: 0.7130\n",
      "Epoch 78/500\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5307 - acc: 0.7360 - auc_32: 0.8099 - recall_m: 0.7869 - precision_m: 0.7377 - f1_m: 0.7333 - val_loss: 0.5435 - val_acc: 0.7222 - val_auc_32: 0.8037 - val_recall_m: 0.7721 - val_precision_m: 0.6896 - val_f1_m: 0.7035\n",
      "Epoch 79/500\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5303 - acc: 0.7329 - auc_32: 0.8101 - recall_m: 0.7778 - precision_m: 0.7381 - f1_m: 0.7310 - val_loss: 0.5435 - val_acc: 0.7324 - val_auc_32: 0.8069 - val_recall_m: 0.7670 - val_precision_m: 0.6962 - val_f1_m: 0.7056\n",
      "Epoch 80/500\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5302 - acc: 0.7333 - auc_32: 0.8105 - recall_m: 0.7747 - precision_m: 0.7319 - f1_m: 0.7278 - val_loss: 0.5413 - val_acc: 0.7407 - val_auc_32: 0.8087 - val_recall_m: 0.7869 - val_precision_m: 0.7084 - val_f1_m: 0.7174\n",
      "Epoch 81/500\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5302 - acc: 0.7338 - auc_32: 0.8102 - recall_m: 0.7766 - precision_m: 0.7354 - f1_m: 0.7300 - val_loss: 0.5505 - val_acc: 0.7222 - val_auc_32: 0.8009 - val_recall_m: 0.7789 - val_precision_m: 0.6847 - val_f1_m: 0.7014\n",
      "Epoch 82/500\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5306 - acc: 0.7345 - auc_32: 0.8100 - recall_m: 0.7781 - precision_m: 0.7296 - f1_m: 0.7293 - val_loss: 0.5450 - val_acc: 0.7264 - val_auc_32: 0.8033 - val_recall_m: 0.7838 - val_precision_m: 0.6947 - val_f1_m: 0.7117\n",
      "Epoch 83/500\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5302 - acc: 0.7357 - auc_32: 0.8101 - recall_m: 0.7834 - precision_m: 0.7324 - f1_m: 0.7350 - val_loss: 0.5450 - val_acc: 0.7264 - val_auc_32: 0.8042 - val_recall_m: 0.7796 - val_precision_m: 0.6870 - val_f1_m: 0.7074\n",
      "Epoch 84/500\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5293 - acc: 0.7381 - auc_32: 0.8111 - recall_m: 0.7817 - precision_m: 0.7372 - f1_m: 0.7335 - val_loss: 0.5463 - val_acc: 0.7204 - val_auc_32: 0.8044 - val_recall_m: 0.7931 - val_precision_m: 0.6752 - val_f1_m: 0.7076\n",
      "Epoch 85/500\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5295 - acc: 0.7341 - auc_32: 0.8107 - recall_m: 0.7771 - precision_m: 0.7362 - f1_m: 0.7342 - val_loss: 0.5464 - val_acc: 0.7240 - val_auc_32: 0.8054 - val_recall_m: 0.7912 - val_precision_m: 0.6855 - val_f1_m: 0.7083\n",
      "Epoch 86/500\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5304 - acc: 0.7335 - auc_32: 0.8099 - recall_m: 0.7823 - precision_m: 0.7331 - f1_m: 0.7319 - val_loss: 0.5432 - val_acc: 0.7264 - val_auc_32: 0.8037 - val_recall_m: 0.7754 - val_precision_m: 0.6994 - val_f1_m: 0.7088\n",
      "Epoch 87/500\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5296 - acc: 0.7335 - auc_32: 0.8106 - recall_m: 0.7829 - precision_m: 0.7357 - f1_m: 0.7351 - val_loss: 0.5449 - val_acc: 0.7312 - val_auc_32: 0.8050 - val_recall_m: 0.7721 - val_precision_m: 0.6857 - val_f1_m: 0.6988\n",
      "Epoch 88/500\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5307 - acc: 0.7336 - auc_32: 0.8097 - recall_m: 0.7829 - precision_m: 0.7333 - f1_m: 0.7334 - val_loss: 0.5454 - val_acc: 0.7318 - val_auc_32: 0.8056 - val_recall_m: 0.7800 - val_precision_m: 0.7053 - val_f1_m: 0.7145\n",
      "Epoch 89/500\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5298 - acc: 0.7330 - auc_32: 0.8106 - recall_m: 0.7793 - precision_m: 0.7358 - f1_m: 0.7326 - val_loss: 0.5556 - val_acc: 0.7234 - val_auc_32: 0.7965 - val_recall_m: 0.7850 - val_precision_m: 0.6752 - val_f1_m: 0.7050\n",
      "Epoch 90/500\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5299 - acc: 0.7318 - auc_32: 0.8105 - recall_m: 0.7798 - precision_m: 0.7281 - f1_m: 0.7291 - val_loss: 0.5483 - val_acc: 0.7228 - val_auc_32: 0.8007 - val_recall_m: 0.7644 - val_precision_m: 0.6899 - val_f1_m: 0.7015\n",
      "Epoch 91/500\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5293 - acc: 0.7345 - auc_32: 0.8112 - recall_m: 0.7803 - precision_m: 0.7352 - f1_m: 0.7338 - val_loss: 0.5536 - val_acc: 0.7264 - val_auc_32: 0.7961 - val_recall_m: 0.7717 - val_precision_m: 0.6987 - val_f1_m: 0.7094\n",
      "Epoch 92/500\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5292 - acc: 0.7342 - auc_32: 0.8111 - recall_m: 0.7805 - precision_m: 0.7341 - f1_m: 0.7312 - val_loss: 0.5447 - val_acc: 0.7288 - val_auc_32: 0.8060 - val_recall_m: 0.7685 - val_precision_m: 0.7106 - val_f1_m: 0.7143\n",
      "Epoch 93/500\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5291 - acc: 0.7338 - auc_32: 0.8112 - recall_m: 0.7767 - precision_m: 0.7340 - f1_m: 0.7308 - val_loss: 0.5535 - val_acc: 0.7180 - val_auc_32: 0.8019 - val_recall_m: 0.7916 - val_precision_m: 0.6697 - val_f1_m: 0.6996\n",
      "Epoch 94/500\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5297 - acc: 0.7345 - auc_32: 0.8104 - recall_m: 0.7720 - precision_m: 0.7352 - f1_m: 0.7274 - val_loss: 0.5539 - val_acc: 0.7210 - val_auc_32: 0.7998 - val_recall_m: 0.7958 - val_precision_m: 0.6879 - val_f1_m: 0.7139\n",
      "Epoch 95/500\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5292 - acc: 0.7339 - auc_32: 0.8108 - recall_m: 0.7878 - precision_m: 0.7323 - f1_m: 0.7344 - val_loss: 0.5511 - val_acc: 0.7210 - val_auc_32: 0.8003 - val_recall_m: 0.7785 - val_precision_m: 0.6839 - val_f1_m: 0.7048\n",
      "Epoch 96/500\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5290 - acc: 0.7393 - auc_32: 0.8116 - recall_m: 0.7826 - precision_m: 0.7392 - f1_m: 0.7350 - val_loss: 0.5450 - val_acc: 0.7240 - val_auc_32: 0.8046 - val_recall_m: 0.7844 - val_precision_m: 0.6859 - val_f1_m: 0.7096\n",
      "Epoch 97/500\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5289 - acc: 0.7368 - auc_32: 0.8112 - recall_m: 0.7921 - precision_m: 0.7339 - f1_m: 0.7381 - val_loss: 0.5454 - val_acc: 0.7210 - val_auc_32: 0.8049 - val_recall_m: 0.7819 - val_precision_m: 0.6839 - val_f1_m: 0.7053\n",
      "Epoch 98/500\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5293 - acc: 0.7341 - auc_32: 0.8109 - recall_m: 0.7792 - precision_m: 0.7353 - f1_m: 0.7334 - val_loss: 0.5478 - val_acc: 0.7222 - val_auc_32: 0.8026 - val_recall_m: 0.7768 - val_precision_m: 0.6883 - val_f1_m: 0.7064\n",
      "Epoch 99/500\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5288 - acc: 0.7377 - auc_32: 0.8113 - recall_m: 0.7847 - precision_m: 0.7361 - f1_m: 0.7344 - val_loss: 0.5449 - val_acc: 0.7228 - val_auc_32: 0.8038 - val_recall_m: 0.7700 - val_precision_m: 0.6777 - val_f1_m: 0.6971\n",
      "Epoch 100/500\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5291 - acc: 0.7336 - auc_32: 0.8113 - recall_m: 0.7789 - precision_m: 0.7367 - f1_m: 0.7325 - val_loss: 0.5487 - val_acc: 0.7192 - val_auc_32: 0.8034 - val_recall_m: 0.7821 - val_precision_m: 0.6783 - val_f1_m: 0.6992\n",
      "Epoch 101/500\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5291 - acc: 0.7318 - auc_32: 0.8110 - recall_m: 0.7771 - precision_m: 0.7299 - f1_m: 0.7294 - val_loss: 0.5453 - val_acc: 0.7198 - val_auc_32: 0.8038 - val_recall_m: 0.7710 - val_precision_m: 0.6846 - val_f1_m: 0.6981\n",
      "Epoch 102/500\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5286 - acc: 0.7342 - auc_32: 0.8115 - recall_m: 0.7705 - precision_m: 0.7334 - f1_m: 0.7278 - val_loss: 0.5489 - val_acc: 0.7186 - val_auc_32: 0.8016 - val_recall_m: 0.7758 - val_precision_m: 0.6845 - val_f1_m: 0.7024\n",
      "Epoch 103/500\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5295 - acc: 0.7357 - auc_32: 0.8109 - recall_m: 0.7745 - precision_m: 0.7380 - f1_m: 0.7322 - val_loss: 0.5509 - val_acc: 0.7192 - val_auc_32: 0.8028 - val_recall_m: 0.7876 - val_precision_m: 0.6822 - val_f1_m: 0.7080\n",
      "Epoch 104/500\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5281 - acc: 0.7377 - auc_32: 0.8119 - recall_m: 0.7872 - precision_m: 0.7411 - f1_m: 0.7393 - val_loss: 0.5435 - val_acc: 0.7342 - val_auc_32: 0.8041 - val_recall_m: 0.7480 - val_precision_m: 0.7103 - val_f1_m: 0.7016\n",
      "Epoch 105/500\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5282 - acc: 0.7378 - auc_32: 0.8121 - recall_m: 0.7811 - precision_m: 0.7360 - f1_m: 0.7343 - val_loss: 0.5482 - val_acc: 0.7234 - val_auc_32: 0.8022 - val_recall_m: 0.7895 - val_precision_m: 0.6874 - val_f1_m: 0.7070\n",
      "Epoch 106/500\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5287 - acc: 0.7329 - auc_32: 0.8115 - recall_m: 0.7755 - precision_m: 0.7338 - f1_m: 0.7302 - val_loss: 0.5465 - val_acc: 0.7276 - val_auc_32: 0.8042 - val_recall_m: 0.7764 - val_precision_m: 0.7091 - val_f1_m: 0.7166\n",
      "Epoch 107/500\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5290 - acc: 0.7342 - auc_32: 0.8114 - recall_m: 0.7771 - precision_m: 0.7393 - f1_m: 0.7319 - val_loss: 0.5475 - val_acc: 0.7204 - val_auc_32: 0.8027 - val_recall_m: 0.7786 - val_precision_m: 0.6848 - val_f1_m: 0.7073\n",
      "Epoch 108/500\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5284 - acc: 0.7354 - auc_32: 0.8119 - recall_m: 0.7824 - precision_m: 0.7352 - f1_m: 0.7350 - val_loss: 0.5456 - val_acc: 0.7234 - val_auc_32: 0.8029 - val_recall_m: 0.7665 - val_precision_m: 0.6917 - val_f1_m: 0.6991\n",
      "Epoch 109/500\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5286 - acc: 0.7354 - auc_32: 0.8117 - recall_m: 0.7761 - precision_m: 0.7337 - f1_m: 0.7316 - val_loss: 0.5507 - val_acc: 0.7210 - val_auc_32: 0.8014 - val_recall_m: 0.7717 - val_precision_m: 0.6728 - val_f1_m: 0.6943\n",
      "Epoch 110/500\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5289 - acc: 0.7347 - auc_32: 0.8114 - recall_m: 0.7777 - precision_m: 0.7375 - f1_m: 0.7335 - val_loss: 0.5461 - val_acc: 0.7240 - val_auc_32: 0.8027 - val_recall_m: 0.7539 - val_precision_m: 0.6788 - val_f1_m: 0.6897\n",
      "Epoch 111/500\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5289 - acc: 0.7326 - auc_32: 0.8111 - recall_m: 0.7740 - precision_m: 0.7376 - f1_m: 0.7307 - val_loss: 0.5508 - val_acc: 0.7210 - val_auc_32: 0.8029 - val_recall_m: 0.7885 - val_precision_m: 0.6836 - val_f1_m: 0.7095\n",
      "Epoch 112/500\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5280 - acc: 0.7363 - auc_32: 0.8121 - recall_m: 0.7885 - precision_m: 0.7389 - f1_m: 0.7393 - val_loss: 0.5490 - val_acc: 0.7246 - val_auc_32: 0.8009 - val_recall_m: 0.7722 - val_precision_m: 0.6900 - val_f1_m: 0.6984\n",
      "Epoch 113/500\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5275 - acc: 0.7359 - auc_32: 0.8124 - recall_m: 0.7778 - precision_m: 0.7414 - f1_m: 0.7360 - val_loss: 0.5483 - val_acc: 0.7180 - val_auc_32: 0.8031 - val_recall_m: 0.7988 - val_precision_m: 0.6849 - val_f1_m: 0.7110\n",
      "Epoch 114/500\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5280 - acc: 0.7393 - auc_32: 0.8121 - recall_m: 0.7799 - precision_m: 0.7399 - f1_m: 0.7348 - val_loss: 0.5472 - val_acc: 0.7216 - val_auc_32: 0.8031 - val_recall_m: 0.7813 - val_precision_m: 0.6911 - val_f1_m: 0.7059\n",
      "Epoch 115/500\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5279 - acc: 0.7338 - auc_32: 0.8120 - recall_m: 0.7798 - precision_m: 0.7374 - f1_m: 0.7346 - val_loss: 0.5521 - val_acc: 0.7264 - val_auc_32: 0.7991 - val_recall_m: 0.7662 - val_precision_m: 0.6754 - val_f1_m: 0.6957\n",
      "Epoch 116/500\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5284 - acc: 0.7333 - auc_32: 0.8117 - recall_m: 0.7834 - precision_m: 0.7238 - f1_m: 0.7290 - val_loss: 0.5426 - val_acc: 0.7384 - val_auc_32: 0.8048 - val_recall_m: 0.7438 - val_precision_m: 0.7143 - val_f1_m: 0.7072\n",
      "Epoch 117/500\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5289 - acc: 0.7371 - auc_32: 0.8111 - recall_m: 0.7788 - precision_m: 0.7354 - f1_m: 0.7329 - val_loss: 0.5519 - val_acc: 0.7198 - val_auc_32: 0.8016 - val_recall_m: 0.7935 - val_precision_m: 0.6836 - val_f1_m: 0.7074\n",
      "Epoch 118/500\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5280 - acc: 0.7357 - auc_32: 0.8122 - recall_m: 0.7854 - precision_m: 0.7347 - f1_m: 0.7338 - val_loss: 0.5453 - val_acc: 0.7282 - val_auc_32: 0.8033 - val_recall_m: 0.7697 - val_precision_m: 0.6986 - val_f1_m: 0.7047\n",
      "Epoch 119/500\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5282 - acc: 0.7365 - auc_32: 0.8120 - recall_m: 0.7708 - precision_m: 0.7360 - f1_m: 0.7308 - val_loss: 0.5461 - val_acc: 0.7348 - val_auc_32: 0.8027 - val_recall_m: 0.7691 - val_precision_m: 0.7086 - val_f1_m: 0.7110\n",
      "Epoch 120/500\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5274 - acc: 0.7345 - auc_32: 0.8125 - recall_m: 0.7759 - precision_m: 0.7344 - f1_m: 0.7300 - val_loss: 0.5491 - val_acc: 0.7234 - val_auc_32: 0.8021 - val_recall_m: 0.7649 - val_precision_m: 0.6869 - val_f1_m: 0.7018\n",
      "Epoch 121/500\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5278 - acc: 0.7360 - auc_32: 0.8122 - recall_m: 0.7753 - precision_m: 0.7341 - f1_m: 0.7292 - val_loss: 0.5461 - val_acc: 0.7234 - val_auc_32: 0.8031 - val_recall_m: 0.7637 - val_precision_m: 0.6927 - val_f1_m: 0.7009\n",
      "Epoch 122/500\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5273 - acc: 0.7360 - auc_32: 0.8128 - recall_m: 0.7755 - precision_m: 0.7407 - f1_m: 0.7344 - val_loss: 0.5556 - val_acc: 0.7210 - val_auc_32: 0.7976 - val_recall_m: 0.7737 - val_precision_m: 0.6785 - val_f1_m: 0.6993\n",
      "Epoch 123/500\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5276 - acc: 0.7342 - auc_32: 0.8121 - recall_m: 0.7821 - precision_m: 0.7351 - f1_m: 0.7340 - val_loss: 0.5562 - val_acc: 0.7145 - val_auc_32: 0.8024 - val_recall_m: 0.7958 - val_precision_m: 0.6732 - val_f1_m: 0.7015\n",
      "Epoch 124/500\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5275 - acc: 0.7374 - auc_32: 0.8125 - recall_m: 0.7888 - precision_m: 0.7318 - f1_m: 0.7373 - val_loss: 0.5515 - val_acc: 0.7240 - val_auc_32: 0.7983 - val_recall_m: 0.7590 - val_precision_m: 0.6788 - val_f1_m: 0.6914\n",
      "Epoch 125/500\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5284 - acc: 0.7372 - auc_32: 0.8117 - recall_m: 0.7793 - precision_m: 0.7360 - f1_m: 0.7354 - val_loss: 0.5450 - val_acc: 0.7324 - val_auc_32: 0.8050 - val_recall_m: 0.7627 - val_precision_m: 0.7137 - val_f1_m: 0.7047\n",
      "Epoch 126/500\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5266 - acc: 0.7383 - auc_32: 0.8132 - recall_m: 0.7786 - precision_m: 0.7457 - f1_m: 0.7362 - val_loss: 0.5497 - val_acc: 0.7234 - val_auc_32: 0.8016 - val_recall_m: 0.7765 - val_precision_m: 0.6874 - val_f1_m: 0.7086\n",
      "Epoch 127/500\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5273 - acc: 0.7384 - auc_32: 0.8127 - recall_m: 0.7856 - precision_m: 0.7429 - f1_m: 0.7388 - val_loss: 0.5537 - val_acc: 0.7174 - val_auc_32: 0.8011 - val_recall_m: 0.7970 - val_precision_m: 0.6862 - val_f1_m: 0.7135\n",
      "Epoch 128/500\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5273 - acc: 0.7378 - auc_32: 0.8128 - recall_m: 0.7778 - precision_m: 0.7355 - f1_m: 0.7330 - val_loss: 0.5522 - val_acc: 0.7192 - val_auc_32: 0.8022 - val_recall_m: 0.7938 - val_precision_m: 0.6949 - val_f1_m: 0.7133\n",
      "Epoch 129/500\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5278 - acc: 0.7350 - auc_32: 0.8119 - recall_m: 0.7798 - precision_m: 0.7351 - f1_m: 0.7333 - val_loss: 0.5500 - val_acc: 0.7186 - val_auc_32: 0.8028 - val_recall_m: 0.7715 - val_precision_m: 0.6752 - val_f1_m: 0.7017\n",
      "Epoch 130/500\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5268 - acc: 0.7374 - auc_32: 0.8132 - recall_m: 0.7786 - precision_m: 0.7402 - f1_m: 0.7366 - val_loss: 0.5522 - val_acc: 0.7168 - val_auc_32: 0.8012 - val_recall_m: 0.8077 - val_precision_m: 0.6791 - val_f1_m: 0.7154\n",
      "Epoch 131/500\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5270 - acc: 0.7356 - auc_32: 0.8130 - recall_m: 0.7819 - precision_m: 0.7303 - f1_m: 0.7324 - val_loss: 0.5485 - val_acc: 0.7216 - val_auc_32: 0.8006 - val_recall_m: 0.7596 - val_precision_m: 0.6832 - val_f1_m: 0.6920\n",
      "Epoch 132/500\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5275 - acc: 0.7386 - auc_32: 0.8125 - recall_m: 0.7751 - precision_m: 0.7408 - f1_m: 0.7336 - val_loss: 0.5571 - val_acc: 0.7103 - val_auc_32: 0.8022 - val_recall_m: 0.7839 - val_precision_m: 0.6611 - val_f1_m: 0.6930\n",
      "Epoch 133/500\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5281 - acc: 0.7351 - auc_32: 0.8119 - recall_m: 0.7808 - precision_m: 0.7343 - f1_m: 0.7313 - val_loss: 0.5521 - val_acc: 0.7216 - val_auc_32: 0.7992 - val_recall_m: 0.7733 - val_precision_m: 0.6824 - val_f1_m: 0.6949\n",
      "Epoch 134/500\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5270 - acc: 0.7366 - auc_32: 0.8129 - recall_m: 0.7782 - precision_m: 0.7408 - f1_m: 0.7336 - val_loss: 0.5581 - val_acc: 0.7204 - val_auc_32: 0.7949 - val_recall_m: 0.7829 - val_precision_m: 0.6910 - val_f1_m: 0.7048\n",
      "Epoch 135/500\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5272 - acc: 0.7381 - auc_32: 0.8127 - recall_m: 0.7706 - precision_m: 0.7398 - f1_m: 0.7323 - val_loss: 0.5522 - val_acc: 0.7151 - val_auc_32: 0.8028 - val_recall_m: 0.7867 - val_precision_m: 0.6707 - val_f1_m: 0.6964\n",
      "Epoch 136/500\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5274 - acc: 0.7371 - auc_32: 0.8125 - recall_m: 0.7771 - precision_m: 0.7370 - f1_m: 0.7327 - val_loss: 0.5478 - val_acc: 0.7222 - val_auc_32: 0.8035 - val_recall_m: 0.7824 - val_precision_m: 0.6924 - val_f1_m: 0.7092\n",
      "Epoch 137/500\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5278 - acc: 0.7383 - auc_32: 0.8120 - recall_m: 0.7812 - precision_m: 0.7344 - f1_m: 0.7330 - val_loss: 0.5474 - val_acc: 0.7198 - val_auc_32: 0.8044 - val_recall_m: 0.7837 - val_precision_m: 0.6901 - val_f1_m: 0.7080\n",
      "Epoch 138/500\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5279 - acc: 0.7393 - auc_32: 0.8122 - recall_m: 0.7806 - precision_m: 0.7362 - f1_m: 0.7336 - val_loss: 0.5465 - val_acc: 0.7240 - val_auc_32: 0.8019 - val_recall_m: 0.7725 - val_precision_m: 0.6909 - val_f1_m: 0.7059\n",
      "Epoch 139/500\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5269 - acc: 0.7369 - auc_32: 0.8129 - recall_m: 0.7756 - precision_m: 0.7348 - f1_m: 0.7330 - val_loss: 0.5548 - val_acc: 0.7127 - val_auc_32: 0.8008 - val_recall_m: 0.7818 - val_precision_m: 0.6681 - val_f1_m: 0.6935\n",
      "Epoch 140/500\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5277 - acc: 0.7357 - auc_32: 0.8123 - recall_m: 0.7732 - precision_m: 0.7346 - f1_m: 0.7272 - val_loss: 0.5510 - val_acc: 0.7157 - val_auc_32: 0.8012 - val_recall_m: 0.7773 - val_precision_m: 0.6842 - val_f1_m: 0.6991\n",
      "Epoch 141/500\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5281 - acc: 0.7350 - auc_32: 0.8119 - recall_m: 0.7721 - precision_m: 0.7383 - f1_m: 0.7309 - val_loss: 0.5532 - val_acc: 0.7222 - val_auc_32: 0.7976 - val_recall_m: 0.7663 - val_precision_m: 0.7098 - val_f1_m: 0.7082\n",
      "Epoch 142/500\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5284 - acc: 0.7362 - auc_32: 0.8113 - recall_m: 0.7761 - precision_m: 0.7376 - f1_m: 0.7307 - val_loss: 0.5497 - val_acc: 0.7151 - val_auc_32: 0.8031 - val_recall_m: 0.7648 - val_precision_m: 0.6717 - val_f1_m: 0.6924\n",
      "Epoch 143/500\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5268 - acc: 0.7365 - auc_32: 0.8131 - recall_m: 0.7733 - precision_m: 0.7354 - f1_m: 0.7301 - val_loss: 0.5563 - val_acc: 0.7157 - val_auc_32: 0.7998 - val_recall_m: 0.7779 - val_precision_m: 0.6751 - val_f1_m: 0.6986\n",
      "Epoch 144/500\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5273 - acc: 0.7360 - auc_32: 0.8126 - recall_m: 0.7826 - precision_m: 0.7430 - f1_m: 0.7366 - val_loss: 0.5523 - val_acc: 0.7145 - val_auc_32: 0.8033 - val_recall_m: 0.7848 - val_precision_m: 0.6701 - val_f1_m: 0.7001\n",
      "Epoch 145/500\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5265 - acc: 0.7341 - auc_32: 0.8133 - recall_m: 0.7718 - precision_m: 0.7346 - f1_m: 0.7288 - val_loss: 0.5436 - val_acc: 0.7312 - val_auc_32: 0.8058 - val_recall_m: 0.7440 - val_precision_m: 0.6965 - val_f1_m: 0.6957\n",
      "Epoch 146/500\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5268 - acc: 0.7356 - auc_32: 0.8131 - recall_m: 0.7703 - precision_m: 0.7381 - f1_m: 0.7294 - val_loss: 0.5567 - val_acc: 0.7162 - val_auc_32: 0.7981 - val_recall_m: 0.7710 - val_precision_m: 0.6819 - val_f1_m: 0.7000\n",
      "Epoch 147/500\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5273 - acc: 0.7357 - auc_32: 0.8123 - recall_m: 0.7767 - precision_m: 0.7365 - f1_m: 0.7343 - val_loss: 0.5516 - val_acc: 0.7121 - val_auc_32: 0.8042 - val_recall_m: 0.7881 - val_precision_m: 0.6724 - val_f1_m: 0.7016\n",
      "Epoch 148/500\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5273 - acc: 0.7338 - auc_32: 0.8125 - recall_m: 0.7814 - precision_m: 0.7368 - f1_m: 0.7327 - val_loss: 0.5492 - val_acc: 0.7139 - val_auc_32: 0.8023 - val_recall_m: 0.7841 - val_precision_m: 0.6739 - val_f1_m: 0.7005\n",
      "Epoch 149/500\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5253 - acc: 0.7390 - auc_32: 0.8145 - recall_m: 0.7817 - precision_m: 0.7371 - f1_m: 0.7336 - val_loss: 0.5647 - val_acc: 0.7121 - val_auc_32: 0.7928 - val_recall_m: 0.7920 - val_precision_m: 0.6772 - val_f1_m: 0.7058\n",
      "Epoch 150/500\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5270 - acc: 0.7377 - auc_32: 0.8128 - recall_m: 0.7801 - precision_m: 0.7351 - f1_m: 0.7343 - val_loss: 0.5483 - val_acc: 0.7252 - val_auc_32: 0.8044 - val_recall_m: 0.7777 - val_precision_m: 0.6956 - val_f1_m: 0.7107\n",
      "Epoch 151/500\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5272 - acc: 0.7351 - auc_32: 0.8125 - recall_m: 0.7733 - precision_m: 0.7378 - f1_m: 0.7297 - val_loss: 0.5459 - val_acc: 0.7240 - val_auc_32: 0.8024 - val_recall_m: 0.7585 - val_precision_m: 0.6905 - val_f1_m: 0.6971\n",
      "Epoch 152/500\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5266 - acc: 0.7372 - auc_32: 0.8133 - recall_m: 0.7689 - precision_m: 0.7390 - f1_m: 0.7301 - val_loss: 0.5599 - val_acc: 0.7097 - val_auc_32: 0.8006 - val_recall_m: 0.7946 - val_precision_m: 0.6622 - val_f1_m: 0.6996\n",
      "Epoch 153/500\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5263 - acc: 0.7339 - auc_32: 0.8133 - recall_m: 0.7753 - precision_m: 0.7282 - f1_m: 0.7295 - val_loss: 0.5596 - val_acc: 0.7115 - val_auc_32: 0.7974 - val_recall_m: 0.7706 - val_precision_m: 0.6531 - val_f1_m: 0.6838\n",
      "Epoch 154/500\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5278 - acc: 0.7357 - auc_32: 0.8122 - recall_m: 0.7785 - precision_m: 0.7372 - f1_m: 0.7340 - val_loss: 0.5516 - val_acc: 0.7180 - val_auc_32: 0.8006 - val_recall_m: 0.7431 - val_precision_m: 0.6780 - val_f1_m: 0.6879\n",
      "Epoch 155/500\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5271 - acc: 0.7371 - auc_32: 0.8126 - recall_m: 0.7786 - precision_m: 0.7388 - f1_m: 0.7309 - val_loss: 0.5561 - val_acc: 0.7151 - val_auc_32: 0.8008 - val_recall_m: 0.8013 - val_precision_m: 0.6821 - val_f1_m: 0.7068\n",
      "Epoch 156/500\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5261 - acc: 0.7357 - auc_32: 0.8135 - recall_m: 0.7906 - precision_m: 0.7375 - f1_m: 0.7373 - val_loss: 0.5475 - val_acc: 0.7198 - val_auc_32: 0.8021 - val_recall_m: 0.7861 - val_precision_m: 0.6963 - val_f1_m: 0.7088\n",
      "Epoch 157/500\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5267 - acc: 0.7368 - auc_32: 0.8132 - recall_m: 0.7697 - precision_m: 0.7387 - f1_m: 0.7311 - val_loss: 0.5488 - val_acc: 0.7157 - val_auc_32: 0.8045 - val_recall_m: 0.7812 - val_precision_m: 0.6818 - val_f1_m: 0.7030\n",
      "Epoch 158/500\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5261 - acc: 0.7351 - auc_32: 0.8137 - recall_m: 0.7757 - precision_m: 0.7332 - f1_m: 0.7294 - val_loss: 0.5535 - val_acc: 0.7246 - val_auc_32: 0.7969 - val_recall_m: 0.7672 - val_precision_m: 0.7084 - val_f1_m: 0.7118\n",
      "Epoch 159/500\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5267 - acc: 0.7347 - auc_32: 0.8127 - recall_m: 0.7735 - precision_m: 0.7320 - f1_m: 0.7286 - val_loss: 0.5574 - val_acc: 0.7192 - val_auc_32: 0.7946 - val_recall_m: 0.7634 - val_precision_m: 0.6834 - val_f1_m: 0.6965\n",
      "Epoch 160/500\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5261 - acc: 0.7354 - auc_32: 0.8134 - recall_m: 0.7812 - precision_m: 0.7333 - f1_m: 0.7343 - val_loss: 0.5465 - val_acc: 0.7222 - val_auc_32: 0.8028 - val_recall_m: 0.7590 - val_precision_m: 0.6884 - val_f1_m: 0.6958\n",
      "Epoch 161/500\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5261 - acc: 0.7332 - auc_32: 0.8135 - recall_m: 0.7731 - precision_m: 0.7409 - f1_m: 0.7339 - val_loss: 0.5565 - val_acc: 0.7210 - val_auc_32: 0.7956 - val_recall_m: 0.7761 - val_precision_m: 0.7064 - val_f1_m: 0.7104\n",
      "Epoch 162/500\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5267 - acc: 0.7381 - auc_32: 0.8129 - recall_m: 0.7728 - precision_m: 0.7373 - f1_m: 0.7306 - val_loss: 0.5517 - val_acc: 0.7157 - val_auc_32: 0.8021 - val_recall_m: 0.7923 - val_precision_m: 0.6828 - val_f1_m: 0.7040\n",
      "Epoch 163/500\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5262 - acc: 0.7365 - auc_32: 0.8135 - recall_m: 0.7810 - precision_m: 0.7351 - f1_m: 0.7344 - val_loss: 0.5551 - val_acc: 0.7186 - val_auc_32: 0.7972 - val_recall_m: 0.7748 - val_precision_m: 0.6776 - val_f1_m: 0.6959\n",
      "Epoch 164/500\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5266 - acc: 0.7342 - auc_32: 0.8130 - recall_m: 0.7744 - precision_m: 0.7387 - f1_m: 0.7332 - val_loss: 0.5551 - val_acc: 0.7085 - val_auc_32: 0.8006 - val_recall_m: 0.8001 - val_precision_m: 0.6755 - val_f1_m: 0.7075\n",
      "Epoch 165/500\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5262 - acc: 0.7378 - auc_32: 0.8134 - recall_m: 0.7848 - precision_m: 0.7379 - f1_m: 0.7365 - val_loss: 0.5429 - val_acc: 0.7336 - val_auc_32: 0.8052 - val_recall_m: 0.7502 - val_precision_m: 0.7069 - val_f1_m: 0.7016\n",
      "Epoch 166/500\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5259 - acc: 0.7384 - auc_32: 0.8139 - recall_m: 0.7780 - precision_m: 0.7406 - f1_m: 0.7348 - val_loss: 0.5514 - val_acc: 0.7151 - val_auc_32: 0.8018 - val_recall_m: 0.7869 - val_precision_m: 0.6769 - val_f1_m: 0.7015\n",
      "Epoch 167/500\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5262 - acc: 0.7359 - auc_32: 0.8134 - recall_m: 0.7758 - precision_m: 0.7334 - f1_m: 0.7303 - val_loss: 0.5549 - val_acc: 0.7145 - val_auc_32: 0.8017 - val_recall_m: 0.7852 - val_precision_m: 0.6856 - val_f1_m: 0.7085\n",
      "Epoch 168/500\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5266 - acc: 0.7345 - auc_32: 0.8130 - recall_m: 0.7827 - precision_m: 0.7370 - f1_m: 0.7366 - val_loss: 0.5516 - val_acc: 0.7186 - val_auc_32: 0.8010 - val_recall_m: 0.7908 - val_precision_m: 0.6823 - val_f1_m: 0.7078\n",
      "Epoch 169/500\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "6694/6694 - 2s - loss: 0.5263 - acc: 0.7362 - auc_32: 0.8132 - recall_m: 0.7782 - precision_m: 0.7402 - f1_m: 0.7327 - val_loss: 0.5491 - val_acc: 0.7180 - val_auc_32: 0.8025 - val_recall_m: 0.7882 - val_precision_m: 0.6851 - val_f1_m: 0.7073\n",
      "Epoch 170/500\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5220 - acc: 0.7393 - auc_32: 0.8170 - recall_m: 0.7949 - precision_m: 0.7360 - f1_m: 0.7417 - val_loss: 0.5500 - val_acc: 0.7186 - val_auc_32: 0.8020 - val_recall_m: 0.7847 - val_precision_m: 0.6802 - val_f1_m: 0.7047\n",
      "Epoch 171/500\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5219 - acc: 0.7404 - auc_32: 0.8172 - recall_m: 0.8034 - precision_m: 0.7400 - f1_m: 0.7463 - val_loss: 0.5487 - val_acc: 0.7192 - val_auc_32: 0.8027 - val_recall_m: 0.7787 - val_precision_m: 0.6871 - val_f1_m: 0.7058\n",
      "Epoch 172/500\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7395 - auc_32: 0.8172 - recall_m: 0.7961 - precision_m: 0.7373 - f1_m: 0.7428 - val_loss: 0.5511 - val_acc: 0.7186 - val_auc_32: 0.8010 - val_recall_m: 0.7683 - val_precision_m: 0.6791 - val_f1_m: 0.6981\n",
      "Epoch 173/500\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7410 - auc_32: 0.8171 - recall_m: 0.7961 - precision_m: 0.7410 - f1_m: 0.7442 - val_loss: 0.5503 - val_acc: 0.7174 - val_auc_32: 0.8015 - val_recall_m: 0.7724 - val_precision_m: 0.6718 - val_f1_m: 0.6934\n",
      "Epoch 174/500\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7405 - auc_32: 0.8172 - recall_m: 0.7966 - precision_m: 0.7331 - f1_m: 0.7422 - val_loss: 0.5490 - val_acc: 0.7186 - val_auc_32: 0.8025 - val_recall_m: 0.7757 - val_precision_m: 0.6806 - val_f1_m: 0.7014\n",
      "Epoch 175/500\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7408 - auc_32: 0.8173 - recall_m: 0.7942 - precision_m: 0.7390 - f1_m: 0.7419 - val_loss: 0.5493 - val_acc: 0.7180 - val_auc_32: 0.8026 - val_recall_m: 0.7784 - val_precision_m: 0.6874 - val_f1_m: 0.7047\n",
      "Epoch 176/500\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7413 - auc_32: 0.8172 - recall_m: 0.7949 - precision_m: 0.7342 - f1_m: 0.7406 - val_loss: 0.5483 - val_acc: 0.7192 - val_auc_32: 0.8031 - val_recall_m: 0.7790 - val_precision_m: 0.6887 - val_f1_m: 0.7026\n",
      "Epoch 177/500\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7410 - auc_32: 0.8170 - recall_m: 0.7947 - precision_m: 0.7335 - f1_m: 0.7398 - val_loss: 0.5503 - val_acc: 0.7186 - val_auc_32: 0.8017 - val_recall_m: 0.7785 - val_precision_m: 0.6911 - val_f1_m: 0.7011\n",
      "Epoch 178/500\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7408 - auc_32: 0.8172 - recall_m: 0.7923 - precision_m: 0.7343 - f1_m: 0.7406 - val_loss: 0.5512 - val_acc: 0.7180 - val_auc_32: 0.8011 - val_recall_m: 0.7720 - val_precision_m: 0.6817 - val_f1_m: 0.6961\n",
      "Epoch 179/500\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5218 - acc: 0.7410 - auc_32: 0.8172 - recall_m: 0.8004 - precision_m: 0.7380 - f1_m: 0.7440 - val_loss: 0.5499 - val_acc: 0.7180 - val_auc_32: 0.8021 - val_recall_m: 0.7776 - val_precision_m: 0.6817 - val_f1_m: 0.7011\n",
      "Epoch 180/500\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7401 - auc_32: 0.8175 - recall_m: 0.7907 - precision_m: 0.7323 - f1_m: 0.7362 - val_loss: 0.5518 - val_acc: 0.7180 - val_auc_32: 0.8009 - val_recall_m: 0.7685 - val_precision_m: 0.6799 - val_f1_m: 0.6956\n",
      "Epoch 181/500\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7413 - auc_32: 0.8175 - recall_m: 0.7933 - precision_m: 0.7346 - f1_m: 0.7416 - val_loss: 0.5504 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7789 - val_precision_m: 0.6814 - val_f1_m: 0.7052\n",
      "Epoch 182/500\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7413 - auc_32: 0.8174 - recall_m: 0.7976 - precision_m: 0.7322 - f1_m: 0.7406 - val_loss: 0.5502 - val_acc: 0.7186 - val_auc_32: 0.8018 - val_recall_m: 0.7812 - val_precision_m: 0.6872 - val_f1_m: 0.7011\n",
      "Epoch 183/500\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7407 - auc_32: 0.8174 - recall_m: 0.7938 - precision_m: 0.7351 - f1_m: 0.7419 - val_loss: 0.5521 - val_acc: 0.7186 - val_auc_32: 0.8007 - val_recall_m: 0.7865 - val_precision_m: 0.6904 - val_f1_m: 0.7080\n",
      "Epoch 184/500\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7416 - auc_32: 0.8174 - recall_m: 0.7974 - precision_m: 0.7361 - f1_m: 0.7415 - val_loss: 0.5494 - val_acc: 0.7186 - val_auc_32: 0.8025 - val_recall_m: 0.7840 - val_precision_m: 0.6836 - val_f1_m: 0.7069\n",
      "Epoch 185/500\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7417 - auc_32: 0.8174 - recall_m: 0.7995 - precision_m: 0.7346 - f1_m: 0.7444 - val_loss: 0.5513 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7660 - val_precision_m: 0.6730 - val_f1_m: 0.6905\n",
      "Epoch 186/500\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7413 - auc_32: 0.8174 - recall_m: 0.7978 - precision_m: 0.7309 - f1_m: 0.7397 - val_loss: 0.5507 - val_acc: 0.7186 - val_auc_32: 0.8014 - val_recall_m: 0.7749 - val_precision_m: 0.6863 - val_f1_m: 0.7025\n",
      "Epoch 187/500\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7408 - auc_32: 0.8173 - recall_m: 0.8012 - precision_m: 0.7330 - f1_m: 0.7435 - val_loss: 0.5495 - val_acc: 0.7186 - val_auc_32: 0.8022 - val_recall_m: 0.7848 - val_precision_m: 0.6913 - val_f1_m: 0.7043\n",
      "Epoch 188/500\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7405 - auc_32: 0.8173 - recall_m: 0.7956 - precision_m: 0.7368 - f1_m: 0.7415 - val_loss: 0.5519 - val_acc: 0.7186 - val_auc_32: 0.8007 - val_recall_m: 0.7804 - val_precision_m: 0.6837 - val_f1_m: 0.7017\n",
      "Epoch 189/500\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7402 - auc_32: 0.8174 - recall_m: 0.7987 - precision_m: 0.7392 - f1_m: 0.7439 - val_loss: 0.5497 - val_acc: 0.7180 - val_auc_32: 0.8022 - val_recall_m: 0.7772 - val_precision_m: 0.6827 - val_f1_m: 0.6981\n",
      "Epoch 190/500\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7413 - auc_32: 0.8174 - recall_m: 0.7997 - precision_m: 0.7345 - f1_m: 0.7411 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7861 - val_precision_m: 0.6870 - val_f1_m: 0.7090\n",
      "Epoch 191/500\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5215 - acc: 0.7416 - auc_32: 0.8176 - recall_m: 0.7969 - precision_m: 0.7339 - f1_m: 0.7417 - val_loss: 0.5498 - val_acc: 0.7180 - val_auc_32: 0.8025 - val_recall_m: 0.7717 - val_precision_m: 0.6792 - val_f1_m: 0.6983\n",
      "Epoch 192/500\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7422 - auc_32: 0.8172 - recall_m: 0.7894 - precision_m: 0.7312 - f1_m: 0.7366 - val_loss: 0.5512 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7924 - val_precision_m: 0.6924 - val_f1_m: 0.7110\n",
      "Epoch 193/500\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7413 - auc_32: 0.8174 - recall_m: 0.7951 - precision_m: 0.7322 - f1_m: 0.7387 - val_loss: 0.5520 - val_acc: 0.7180 - val_auc_32: 0.8008 - val_recall_m: 0.7761 - val_precision_m: 0.6741 - val_f1_m: 0.6976\n",
      "Epoch 194/500\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7407 - auc_32: 0.8174 - recall_m: 0.7979 - precision_m: 0.7364 - f1_m: 0.7422 - val_loss: 0.5500 - val_acc: 0.7186 - val_auc_32: 0.8021 - val_recall_m: 0.7708 - val_precision_m: 0.6781 - val_f1_m: 0.7003\n",
      "Epoch 195/500\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5215 - acc: 0.7405 - auc_32: 0.8174 - recall_m: 0.7913 - precision_m: 0.7314 - f1_m: 0.7357 - val_loss: 0.5515 - val_acc: 0.7180 - val_auc_32: 0.8010 - val_recall_m: 0.7752 - val_precision_m: 0.6826 - val_f1_m: 0.7028\n",
      "Epoch 196/500\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7408 - auc_32: 0.8175 - recall_m: 0.7960 - precision_m: 0.7362 - f1_m: 0.7418 - val_loss: 0.5502 - val_acc: 0.7186 - val_auc_32: 0.8017 - val_recall_m: 0.7877 - val_precision_m: 0.6957 - val_f1_m: 0.7107\n",
      "Epoch 197/500\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5215 - acc: 0.7408 - auc_32: 0.8174 - recall_m: 0.7894 - precision_m: 0.7327 - f1_m: 0.7384 - val_loss: 0.5519 - val_acc: 0.7180 - val_auc_32: 0.8007 - val_recall_m: 0.7829 - val_precision_m: 0.6908 - val_f1_m: 0.7100\n",
      "Epoch 198/500\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5217 - acc: 0.7419 - auc_32: 0.8174 - recall_m: 0.7937 - precision_m: 0.7349 - f1_m: 0.7404 - val_loss: 0.5498 - val_acc: 0.7186 - val_auc_32: 0.8022 - val_recall_m: 0.7849 - val_precision_m: 0.6839 - val_f1_m: 0.7041\n",
      "Epoch 199/500\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7411 - auc_32: 0.8174 - recall_m: 0.7929 - precision_m: 0.7326 - f1_m: 0.7391 - val_loss: 0.5503 - val_acc: 0.7186 - val_auc_32: 0.8018 - val_recall_m: 0.7618 - val_precision_m: 0.6719 - val_f1_m: 0.6911\n",
      "Epoch 200/500\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7405 - auc_32: 0.8174 - recall_m: 0.7954 - precision_m: 0.7307 - f1_m: 0.7374 - val_loss: 0.5506 - val_acc: 0.7186 - val_auc_32: 0.8015 - val_recall_m: 0.7688 - val_precision_m: 0.6825 - val_f1_m: 0.7007\n",
      "Epoch 201/500\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7414 - auc_32: 0.8174 - recall_m: 0.7975 - precision_m: 0.7378 - f1_m: 0.7428 - val_loss: 0.5510 - val_acc: 0.7186 - val_auc_32: 0.8015 - val_recall_m: 0.7855 - val_precision_m: 0.6840 - val_f1_m: 0.7043\n",
      "Epoch 202/500\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7411 - auc_32: 0.8174 - recall_m: 0.7960 - precision_m: 0.7371 - f1_m: 0.7418 - val_loss: 0.5503 - val_acc: 0.7192 - val_auc_32: 0.8019 - val_recall_m: 0.7785 - val_precision_m: 0.6823 - val_f1_m: 0.7008\n",
      "Epoch 203/500\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7404 - auc_32: 0.8173 - recall_m: 0.7930 - precision_m: 0.7278 - f1_m: 0.7378 - val_loss: 0.5510 - val_acc: 0.7186 - val_auc_32: 0.8013 - val_recall_m: 0.7677 - val_precision_m: 0.6708 - val_f1_m: 0.6899\n",
      "Epoch 204/500\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7411 - auc_32: 0.8175 - recall_m: 0.7989 - precision_m: 0.7331 - f1_m: 0.7426 - val_loss: 0.5495 - val_acc: 0.7180 - val_auc_32: 0.8023 - val_recall_m: 0.7896 - val_precision_m: 0.6882 - val_f1_m: 0.7078\n",
      "Epoch 205/500\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7413 - auc_32: 0.8173 - recall_m: 0.7996 - precision_m: 0.7398 - f1_m: 0.7435 - val_loss: 0.5498 - val_acc: 0.7168 - val_auc_32: 0.8017 - val_recall_m: 0.7715 - val_precision_m: 0.6874 - val_f1_m: 0.7006\n",
      "Epoch 206/500\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7410 - auc_32: 0.8174 - recall_m: 0.7941 - precision_m: 0.7372 - f1_m: 0.7406 - val_loss: 0.5514 - val_acc: 0.7174 - val_auc_32: 0.8010 - val_recall_m: 0.7645 - val_precision_m: 0.6778 - val_f1_m: 0.6964\n",
      "Epoch 207/500\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5215 - acc: 0.7410 - auc_32: 0.8173 - recall_m: 0.7941 - precision_m: 0.7372 - f1_m: 0.7426 - val_loss: 0.5499 - val_acc: 0.7186 - val_auc_32: 0.8020 - val_recall_m: 0.7802 - val_precision_m: 0.6862 - val_f1_m: 0.6985\n",
      "Epoch 208/500\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5215 - acc: 0.7405 - auc_32: 0.8175 - recall_m: 0.8023 - precision_m: 0.7359 - f1_m: 0.7447 - val_loss: 0.5495 - val_acc: 0.7186 - val_auc_32: 0.8021 - val_recall_m: 0.7767 - val_precision_m: 0.6986 - val_f1_m: 0.7055\n",
      "Epoch 209/500\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5214 - acc: 0.7405 - auc_32: 0.8176 - recall_m: 0.7943 - precision_m: 0.7380 - f1_m: 0.7401 - val_loss: 0.5488 - val_acc: 0.7180 - val_auc_32: 0.8027 - val_recall_m: 0.7759 - val_precision_m: 0.6881 - val_f1_m: 0.6999\n",
      "Epoch 210/500\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7410 - auc_32: 0.8173 - recall_m: 0.7923 - precision_m: 0.7318 - f1_m: 0.7380 - val_loss: 0.5510 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7756 - val_precision_m: 0.6822 - val_f1_m: 0.6965\n",
      "Epoch 211/500\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "6694/6694 - 1s - loss: 0.5216 - acc: 0.7420 - auc_32: 0.8173 - recall_m: 0.7922 - precision_m: 0.7339 - f1_m: 0.7402 - val_loss: 0.5502 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7900 - val_precision_m: 0.6934 - val_f1_m: 0.7110\n",
      "Epoch 212/500\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7416 - auc_32: 0.8180 - recall_m: 0.7932 - precision_m: 0.7323 - f1_m: 0.7387 - val_loss: 0.5503 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7828 - val_precision_m: 0.6804 - val_f1_m: 0.6988\n",
      "Epoch 213/500\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7419 - auc_32: 0.8179 - recall_m: 0.7950 - precision_m: 0.7371 - f1_m: 0.7423 - val_loss: 0.5504 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7654 - val_precision_m: 0.6776 - val_f1_m: 0.6948\n",
      "Epoch 214/500\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7417 - auc_32: 0.8180 - recall_m: 0.7963 - precision_m: 0.7350 - f1_m: 0.7416 - val_loss: 0.5506 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7860 - val_precision_m: 0.6871 - val_f1_m: 0.7041\n",
      "Epoch 215/500\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7416 - auc_32: 0.8180 - recall_m: 0.8000 - precision_m: 0.7390 - f1_m: 0.7437 - val_loss: 0.5506 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7863 - val_precision_m: 0.6975 - val_f1_m: 0.7080\n",
      "Epoch 216/500\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7416 - auc_32: 0.8179 - recall_m: 0.7948 - precision_m: 0.7385 - f1_m: 0.7401 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7631 - val_precision_m: 0.6762 - val_f1_m: 0.6926\n",
      "Epoch 217/500\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7417 - auc_32: 0.8180 - recall_m: 0.7998 - precision_m: 0.7432 - f1_m: 0.7469 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7732 - val_precision_m: 0.6795 - val_f1_m: 0.6986\n",
      "Epoch 218/500\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7419 - auc_32: 0.8180 - recall_m: 0.7934 - precision_m: 0.7328 - f1_m: 0.7402 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7679 - val_precision_m: 0.6859 - val_f1_m: 0.6982\n",
      "Epoch 219/500\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7416 - auc_32: 0.8180 - recall_m: 0.7928 - precision_m: 0.7336 - f1_m: 0.7384 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7616 - val_precision_m: 0.6763 - val_f1_m: 0.6891\n",
      "Epoch 220/500\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7417 - auc_32: 0.8180 - recall_m: 0.7911 - precision_m: 0.7327 - f1_m: 0.7382 - val_loss: 0.5508 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7647 - val_precision_m: 0.6874 - val_f1_m: 0.6984\n",
      "Epoch 221/500\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7419 - auc_32: 0.8180 - recall_m: 0.7960 - precision_m: 0.7355 - f1_m: 0.7427 - val_loss: 0.5508 - val_acc: 0.7180 - val_auc_32: 0.8014 - val_recall_m: 0.7871 - val_precision_m: 0.6884 - val_f1_m: 0.7104\n",
      "Epoch 222/500\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7422 - auc_32: 0.8181 - recall_m: 0.7969 - precision_m: 0.7351 - f1_m: 0.7421 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7741 - val_precision_m: 0.6799 - val_f1_m: 0.7017\n",
      "Epoch 223/500\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7422 - auc_32: 0.8181 - recall_m: 0.8001 - precision_m: 0.7369 - f1_m: 0.7439 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7807 - val_precision_m: 0.6877 - val_f1_m: 0.7007\n",
      "Epoch 224/500\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7417 - auc_32: 0.8181 - recall_m: 0.7888 - precision_m: 0.7293 - f1_m: 0.7366 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7839 - val_precision_m: 0.6900 - val_f1_m: 0.7031\n",
      "Epoch 225/500\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7417 - auc_32: 0.8181 - recall_m: 0.7985 - precision_m: 0.7334 - f1_m: 0.7420 - val_loss: 0.5507 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7730 - val_precision_m: 0.6822 - val_f1_m: 0.7009\n",
      "Epoch 226/500\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7420 - auc_32: 0.8181 - recall_m: 0.7979 - precision_m: 0.7358 - f1_m: 0.7446 - val_loss: 0.5506 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7643 - val_precision_m: 0.6841 - val_f1_m: 0.6996\n",
      "Epoch 227/500\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7419 - auc_32: 0.8180 - recall_m: 0.7994 - precision_m: 0.7399 - f1_m: 0.7461 - val_loss: 0.5508 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7727 - val_precision_m: 0.6816 - val_f1_m: 0.6985\n",
      "Epoch 228/500\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7417 - auc_32: 0.8181 - recall_m: 0.7915 - precision_m: 0.7359 - f1_m: 0.7404 - val_loss: 0.5508 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7646 - val_precision_m: 0.6766 - val_f1_m: 0.6969\n",
      "Epoch 229/500\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7420 - auc_32: 0.8180 - recall_m: 0.7969 - precision_m: 0.7393 - f1_m: 0.7455 - val_loss: 0.5508 - val_acc: 0.7180 - val_auc_32: 0.8016 - val_recall_m: 0.7802 - val_precision_m: 0.6861 - val_f1_m: 0.7050\n",
      "Epoch 230/500\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7419 - auc_32: 0.8181 - recall_m: 0.7956 - precision_m: 0.7322 - f1_m: 0.7432 - val_loss: 0.5508 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7782 - val_precision_m: 0.6924 - val_f1_m: 0.7070\n",
      "Epoch 231/500\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7420 - auc_32: 0.8182 - recall_m: 0.7985 - precision_m: 0.7379 - f1_m: 0.7441 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7724 - val_precision_m: 0.6743 - val_f1_m: 0.6969\n",
      "Epoch 232/500\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "6694/6694 - 1s - loss: 0.5210 - acc: 0.7419 - auc_32: 0.8181 - recall_m: 0.8024 - precision_m: 0.7380 - f1_m: 0.7457 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7730 - val_precision_m: 0.6820 - val_f1_m: 0.6981\n",
      "Epoch 233/500\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7422 - auc_32: 0.8183 - recall_m: 0.7931 - precision_m: 0.7338 - f1_m: 0.7395 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7701 - val_precision_m: 0.6759 - val_f1_m: 0.6938\n",
      "Epoch 234/500\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7420 - auc_32: 0.8183 - recall_m: 0.7958 - precision_m: 0.7330 - f1_m: 0.7400 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7741 - val_precision_m: 0.6914 - val_f1_m: 0.7042\n",
      "Epoch 235/500\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8182 - recall_m: 0.7950 - precision_m: 0.7358 - f1_m: 0.7411 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7640 - val_precision_m: 0.6746 - val_f1_m: 0.6891\n",
      "Epoch 236/500\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7422 - auc_32: 0.8183 - recall_m: 0.7971 - precision_m: 0.7362 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7742 - val_precision_m: 0.6767 - val_f1_m: 0.6963\n",
      "Epoch 237/500\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7963 - precision_m: 0.7354 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7782 - val_precision_m: 0.6804 - val_f1_m: 0.6988\n",
      "Epoch 238/500\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7998 - precision_m: 0.7348 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7851 - val_precision_m: 0.6908 - val_f1_m: 0.7037\n",
      "Epoch 239/500\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7978 - precision_m: 0.7359 - f1_m: 0.7420 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7824 - val_precision_m: 0.6779 - val_f1_m: 0.6987\n",
      "Epoch 240/500\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7902 - precision_m: 0.7360 - f1_m: 0.7383 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7830 - val_precision_m: 0.6841 - val_f1_m: 0.7044\n",
      "Epoch 241/500\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8182 - recall_m: 0.7967 - precision_m: 0.7364 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7716 - val_precision_m: 0.6839 - val_f1_m: 0.7010\n",
      "Epoch 242/500\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7932 - precision_m: 0.7367 - f1_m: 0.7440 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7788 - val_precision_m: 0.6800 - val_f1_m: 0.7014\n",
      "Epoch 243/500\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7420 - auc_32: 0.8183 - recall_m: 0.7987 - precision_m: 0.7358 - f1_m: 0.7445 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7829 - val_precision_m: 0.6882 - val_f1_m: 0.7111\n",
      "Epoch 244/500\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7973 - precision_m: 0.7365 - f1_m: 0.7426 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7734 - val_precision_m: 0.6919 - val_f1_m: 0.7058\n",
      "Epoch 245/500\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7939 - precision_m: 0.7334 - f1_m: 0.7411 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7826 - val_precision_m: 0.6895 - val_f1_m: 0.7071\n",
      "Epoch 246/500\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8012 - precision_m: 0.7377 - f1_m: 0.7458 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7784 - val_precision_m: 0.6814 - val_f1_m: 0.6963\n",
      "Epoch 247/500\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8182 - recall_m: 0.7974 - precision_m: 0.7373 - f1_m: 0.7444 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7934 - val_precision_m: 0.6951 - val_f1_m: 0.7117\n",
      "Epoch 248/500\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8182 - recall_m: 0.8001 - precision_m: 0.7400 - f1_m: 0.7456 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7782 - val_precision_m: 0.6814 - val_f1_m: 0.7014\n",
      "Epoch 249/500\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8019 - precision_m: 0.7377 - f1_m: 0.7451 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7766 - val_precision_m: 0.6813 - val_f1_m: 0.7029\n",
      "Epoch 250/500\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7925 - precision_m: 0.7363 - f1_m: 0.7415 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7731 - val_precision_m: 0.6838 - val_f1_m: 0.7007\n",
      "Epoch 251/500\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7986 - precision_m: 0.7377 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7755 - val_precision_m: 0.6794 - val_f1_m: 0.6970\n",
      "Epoch 252/500\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7422 - auc_32: 0.8183 - recall_m: 0.8005 - precision_m: 0.7385 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7641 - val_precision_m: 0.6764 - val_f1_m: 0.6931\n",
      "Epoch 253/500\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7339 - f1_m: 0.7422 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7799 - val_precision_m: 0.6876 - val_f1_m: 0.7040\n",
      "Epoch 254/500\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7339 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7791 - val_precision_m: 0.6884 - val_f1_m: 0.7011\n",
      "Epoch 255/500\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7939 - precision_m: 0.7362 - f1_m: 0.7423 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7755 - val_precision_m: 0.6917 - val_f1_m: 0.7041\n",
      "Epoch 256/500\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7986 - precision_m: 0.7338 - f1_m: 0.7416 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7812 - val_precision_m: 0.6852 - val_f1_m: 0.7065\n",
      "Epoch 257/500\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7984 - precision_m: 0.7351 - f1_m: 0.7428 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7716 - val_precision_m: 0.6798 - val_f1_m: 0.6939\n",
      "Epoch 258/500\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7999 - precision_m: 0.7372 - f1_m: 0.7440 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7657 - val_precision_m: 0.6730 - val_f1_m: 0.6920\n",
      "Epoch 259/500\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7338 - f1_m: 0.7423 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7766 - val_precision_m: 0.6816 - val_f1_m: 0.7004\n",
      "Epoch 260/500\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7354 - f1_m: 0.7402 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7684 - val_precision_m: 0.6738 - val_f1_m: 0.6941\n",
      "Epoch 261/500\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7978 - precision_m: 0.7367 - f1_m: 0.7432 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7729 - val_precision_m: 0.6835 - val_f1_m: 0.6965\n",
      "Epoch 262/500\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7992 - precision_m: 0.7376 - f1_m: 0.7420 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7740 - val_precision_m: 0.6763 - val_f1_m: 0.6981\n",
      "Epoch 263/500\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7967 - precision_m: 0.7344 - f1_m: 0.7437 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7752 - val_precision_m: 0.6857 - val_f1_m: 0.7026\n",
      "Epoch 264/500\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8004 - precision_m: 0.7382 - f1_m: 0.7452 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7692 - val_precision_m: 0.6853 - val_f1_m: 0.7003\n",
      "Epoch 265/500\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7974 - precision_m: 0.7363 - f1_m: 0.7444 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7851 - val_precision_m: 0.6934 - val_f1_m: 0.7102\n",
      "Epoch 266/500\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7981 - precision_m: 0.7348 - f1_m: 0.7425 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7681 - val_precision_m: 0.6856 - val_f1_m: 0.7006\n",
      "Epoch 267/500\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7961 - precision_m: 0.7358 - f1_m: 0.7427 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7688 - val_precision_m: 0.6734 - val_f1_m: 0.6944\n",
      "Epoch 268/500\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7928 - precision_m: 0.7322 - f1_m: 0.7399 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7693 - val_precision_m: 0.6853 - val_f1_m: 0.7006\n",
      "Epoch 269/500\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8008 - precision_m: 0.7340 - f1_m: 0.7427 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7809 - val_precision_m: 0.6872 - val_f1_m: 0.7091\n",
      "Epoch 270/500\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7967 - precision_m: 0.7370 - f1_m: 0.7425 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7809 - val_precision_m: 0.6854 - val_f1_m: 0.7015\n",
      "Epoch 271/500\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7928 - precision_m: 0.7350 - f1_m: 0.7409 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7727 - val_precision_m: 0.6964 - val_f1_m: 0.7042\n",
      "Epoch 272/500\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7963 - precision_m: 0.7355 - f1_m: 0.7419 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7917 - val_precision_m: 0.6864 - val_f1_m: 0.7076\n",
      "Epoch 273/500\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7921 - precision_m: 0.7359 - f1_m: 0.7408 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7811 - val_precision_m: 0.6863 - val_f1_m: 0.7058\n",
      "Epoch 274/500\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7958 - precision_m: 0.7406 - f1_m: 0.7455 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7682 - val_precision_m: 0.6813 - val_f1_m: 0.6981\n",
      "Epoch 275/500\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7998 - precision_m: 0.7382 - f1_m: 0.7443 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7825 - val_precision_m: 0.6857 - val_f1_m: 0.7019\n",
      "Epoch 276/500\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7955 - precision_m: 0.7325 - f1_m: 0.7410 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7763 - val_precision_m: 0.6843 - val_f1_m: 0.7005\n",
      "Epoch 277/500\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7909 - precision_m: 0.7358 - f1_m: 0.7417 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7750 - val_precision_m: 0.6870 - val_f1_m: 0.7007\n",
      "Epoch 278/500\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7877 - precision_m: 0.7325 - f1_m: 0.7381 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7750 - val_precision_m: 0.6893 - val_f1_m: 0.7028\n",
      "Epoch 279/500\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7346 - f1_m: 0.7410 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7789 - val_precision_m: 0.6890 - val_f1_m: 0.7028\n",
      "Epoch 280/500\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7916 - precision_m: 0.7333 - f1_m: 0.7396 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7626 - val_precision_m: 0.6819 - val_f1_m: 0.6954\n",
      "Epoch 281/500\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7996 - precision_m: 0.7427 - f1_m: 0.7467 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7762 - val_precision_m: 0.6791 - val_f1_m: 0.7012\n",
      "Epoch 282/500\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7947 - precision_m: 0.7379 - f1_m: 0.7421 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7697 - val_precision_m: 0.6695 - val_f1_m: 0.6937\n",
      "Epoch 283/500\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7968 - precision_m: 0.7412 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7689 - val_precision_m: 0.6800 - val_f1_m: 0.6966\n",
      "Epoch 284/500\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7351 - f1_m: 0.7436 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7718 - val_precision_m: 0.6818 - val_f1_m: 0.6951\n",
      "Epoch 285/500\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7955 - precision_m: 0.7333 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7737 - val_precision_m: 0.6787 - val_f1_m: 0.6937\n",
      "Epoch 286/500\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7946 - precision_m: 0.7310 - f1_m: 0.7386 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7772 - val_precision_m: 0.6832 - val_f1_m: 0.6978\n",
      "Epoch 287/500\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7993 - precision_m: 0.7377 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7721 - val_precision_m: 0.6896 - val_f1_m: 0.7042\n",
      "Epoch 288/500\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7989 - precision_m: 0.7405 - f1_m: 0.7457 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7680 - val_precision_m: 0.6836 - val_f1_m: 0.6972\n",
      "Epoch 289/500\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7901 - precision_m: 0.7301 - f1_m: 0.7361 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7693 - val_precision_m: 0.6852 - val_f1_m: 0.7007\n",
      "Epoch 290/500\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7971 - precision_m: 0.7359 - f1_m: 0.7422 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7877 - val_precision_m: 0.6855 - val_f1_m: 0.7067\n",
      "Epoch 291/500\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7956 - precision_m: 0.7361 - f1_m: 0.7430 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7714 - val_precision_m: 0.6794 - val_f1_m: 0.6991\n",
      "Epoch 292/500\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7932 - precision_m: 0.7364 - f1_m: 0.7409 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7811 - val_precision_m: 0.6912 - val_f1_m: 0.7058\n",
      "Epoch 293/500\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7980 - precision_m: 0.7376 - f1_m: 0.7432 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7720 - val_precision_m: 0.6816 - val_f1_m: 0.6982\n",
      "Epoch 294/500\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7998 - precision_m: 0.7393 - f1_m: 0.7449 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7611 - val_precision_m: 0.6868 - val_f1_m: 0.7028\n",
      "Epoch 295/500\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7991 - precision_m: 0.7362 - f1_m: 0.7450 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7840 - val_precision_m: 0.6917 - val_f1_m: 0.7062\n",
      "Epoch 296/500\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7955 - precision_m: 0.7359 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7853 - val_precision_m: 0.6970 - val_f1_m: 0.7058\n",
      "Epoch 297/500\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7998 - precision_m: 0.7366 - f1_m: 0.7463 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7651 - val_precision_m: 0.6841 - val_f1_m: 0.6962\n",
      "Epoch 298/500\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7965 - precision_m: 0.7365 - f1_m: 0.7431 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7861 - val_precision_m: 0.6881 - val_f1_m: 0.7063\n",
      "Epoch 299/500\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7983 - precision_m: 0.7355 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7718 - val_precision_m: 0.6852 - val_f1_m: 0.7022\n",
      "Epoch 300/500\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7961 - precision_m: 0.7339 - f1_m: 0.7423 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7769 - val_precision_m: 0.6793 - val_f1_m: 0.6982\n",
      "Epoch 301/500\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7927 - precision_m: 0.7349 - f1_m: 0.7402 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7759 - val_precision_m: 0.6917 - val_f1_m: 0.7029\n",
      "Epoch 302/500\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7358 - f1_m: 0.7440 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7733 - val_precision_m: 0.6775 - val_f1_m: 0.6958\n",
      "Epoch 303/500\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7960 - precision_m: 0.7346 - f1_m: 0.7416 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7718 - val_precision_m: 0.6763 - val_f1_m: 0.6985\n",
      "Epoch 304/500\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7956 - precision_m: 0.7373 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7894 - val_precision_m: 0.6873 - val_f1_m: 0.7026\n",
      "Epoch 305/500\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7934 - precision_m: 0.7366 - f1_m: 0.7416 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7708 - val_precision_m: 0.6808 - val_f1_m: 0.6978\n",
      "Epoch 306/500\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7924 - precision_m: 0.7375 - f1_m: 0.7415 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7904 - val_precision_m: 0.6888 - val_f1_m: 0.7037\n",
      "Epoch 307/500\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7990 - precision_m: 0.7364 - f1_m: 0.7452 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7781 - val_precision_m: 0.6874 - val_f1_m: 0.7043\n",
      "Epoch 308/500\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7945 - precision_m: 0.7401 - f1_m: 0.7425 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7834 - val_precision_m: 0.6879 - val_f1_m: 0.7018\n",
      "Epoch 309/500\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8026 - precision_m: 0.7393 - f1_m: 0.7462 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7802 - val_precision_m: 0.6870 - val_f1_m: 0.7042\n",
      "Epoch 310/500\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7341 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7875 - val_precision_m: 0.6999 - val_f1_m: 0.7115\n",
      "Epoch 311/500\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7377 - f1_m: 0.7441 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7776 - val_precision_m: 0.6809 - val_f1_m: 0.7003\n",
      "Epoch 312/500\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7942 - precision_m: 0.7351 - f1_m: 0.7419 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7725 - val_precision_m: 0.6702 - val_f1_m: 0.6909\n",
      "Epoch 313/500\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7935 - precision_m: 0.7338 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7701 - val_precision_m: 0.6784 - val_f1_m: 0.6967\n",
      "Epoch 314/500\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7959 - precision_m: 0.7330 - f1_m: 0.7406 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7755 - val_precision_m: 0.6812 - val_f1_m: 0.7027\n",
      "Epoch 315/500\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8001 - precision_m: 0.7377 - f1_m: 0.7456 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7702 - val_precision_m: 0.6823 - val_f1_m: 0.6970\n",
      "Epoch 316/500\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7888 - precision_m: 0.7373 - f1_m: 0.7404 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7761 - val_precision_m: 0.6850 - val_f1_m: 0.7057\n",
      "Epoch 317/500\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7957 - precision_m: 0.7369 - f1_m: 0.7431 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7770 - val_precision_m: 0.6810 - val_f1_m: 0.7039\n",
      "Epoch 318/500\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7961 - precision_m: 0.7378 - f1_m: 0.7435 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7827 - val_precision_m: 0.6827 - val_f1_m: 0.7037\n",
      "Epoch 319/500\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7935 - precision_m: 0.7385 - f1_m: 0.7398 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7754 - val_precision_m: 0.6883 - val_f1_m: 0.7056\n",
      "Epoch 320/500\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7996 - precision_m: 0.7371 - f1_m: 0.7438 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7677 - val_precision_m: 0.6917 - val_f1_m: 0.7014\n",
      "Epoch 321/500\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7981 - precision_m: 0.7383 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7746 - val_precision_m: 0.6854 - val_f1_m: 0.7008\n",
      "Epoch 322/500\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7911 - precision_m: 0.7307 - f1_m: 0.7383 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7699 - val_precision_m: 0.6833 - val_f1_m: 0.6969\n",
      "Epoch 323/500\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8051 - precision_m: 0.7410 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7671 - val_precision_m: 0.6690 - val_f1_m: 0.6852\n",
      "Epoch 324/500\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7958 - precision_m: 0.7349 - f1_m: 0.7413 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7664 - val_precision_m: 0.6739 - val_f1_m: 0.6920\n",
      "Epoch 325/500\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8018 - precision_m: 0.7400 - f1_m: 0.7444 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7735 - val_precision_m: 0.6904 - val_f1_m: 0.7084\n",
      "Epoch 326/500\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7960 - precision_m: 0.7308 - f1_m: 0.7417 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7657 - val_precision_m: 0.6760 - val_f1_m: 0.6916\n",
      "Epoch 327/500\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7974 - precision_m: 0.7345 - f1_m: 0.7434 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7748 - val_precision_m: 0.6937 - val_f1_m: 0.7041\n",
      "Epoch 328/500\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7359 - f1_m: 0.7426 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7806 - val_precision_m: 0.6837 - val_f1_m: 0.7037\n",
      "Epoch 329/500\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7948 - precision_m: 0.7330 - f1_m: 0.7417 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7729 - val_precision_m: 0.6784 - val_f1_m: 0.6928\n",
      "Epoch 330/500\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7974 - precision_m: 0.7336 - f1_m: 0.7406 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7890 - val_precision_m: 0.6876 - val_f1_m: 0.7075\n",
      "Epoch 331/500\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8043 - precision_m: 0.7359 - f1_m: 0.7458 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7647 - val_precision_m: 0.6881 - val_f1_m: 0.6974\n",
      "Epoch 332/500\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7878 - precision_m: 0.7335 - f1_m: 0.7373 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7670 - val_precision_m: 0.6794 - val_f1_m: 0.6943\n",
      "Epoch 333/500\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00333: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7384 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7717 - val_precision_m: 0.6743 - val_f1_m: 0.6943\n",
      "Epoch 334/500\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7914 - precision_m: 0.7307 - f1_m: 0.7367 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7727 - val_precision_m: 0.6902 - val_f1_m: 0.7025\n",
      "Epoch 335/500\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7910 - precision_m: 0.7324 - f1_m: 0.7396 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7725 - val_precision_m: 0.6815 - val_f1_m: 0.6956\n",
      "Epoch 336/500\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8004 - precision_m: 0.7424 - f1_m: 0.7459 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7883 - val_precision_m: 0.6908 - val_f1_m: 0.7102\n",
      "Epoch 337/500\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7926 - precision_m: 0.7361 - f1_m: 0.7418 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7689 - val_precision_m: 0.6797 - val_f1_m: 0.7013\n",
      "Epoch 338/500\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7889 - precision_m: 0.7346 - f1_m: 0.7379 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7759 - val_precision_m: 0.6878 - val_f1_m: 0.7053\n",
      "Epoch 339/500\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8002 - precision_m: 0.7365 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7623 - val_precision_m: 0.6770 - val_f1_m: 0.6923\n",
      "Epoch 340/500\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7974 - precision_m: 0.7332 - f1_m: 0.7387 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7872 - val_precision_m: 0.6823 - val_f1_m: 0.7042\n",
      "Epoch 341/500\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7334 - f1_m: 0.7396 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7701 - val_precision_m: 0.6847 - val_f1_m: 0.6977\n",
      "Epoch 342/500\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8006 - precision_m: 0.7407 - f1_m: 0.7477 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7799 - val_precision_m: 0.6935 - val_f1_m: 0.7081\n",
      "Epoch 343/500\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7965 - precision_m: 0.7386 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7826 - val_precision_m: 0.6897 - val_f1_m: 0.7059\n",
      "Epoch 344/500\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7357 - f1_m: 0.7428 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7781 - val_precision_m: 0.6896 - val_f1_m: 0.7050\n",
      "Epoch 345/500\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7962 - precision_m: 0.7363 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7781 - val_precision_m: 0.6880 - val_f1_m: 0.7017\n",
      "Epoch 346/500\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7999 - precision_m: 0.7381 - f1_m: 0.7439 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7862 - val_precision_m: 0.6834 - val_f1_m: 0.7073\n",
      "Epoch 347/500\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7341 - f1_m: 0.7411 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7678 - val_precision_m: 0.6783 - val_f1_m: 0.6979\n",
      "Epoch 348/500\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7958 - precision_m: 0.7384 - f1_m: 0.7439 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7672 - val_precision_m: 0.6898 - val_f1_m: 0.7018\n",
      "Epoch 349/500\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7994 - precision_m: 0.7350 - f1_m: 0.7420 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7749 - val_precision_m: 0.6870 - val_f1_m: 0.6978\n",
      "Epoch 350/500\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7390 - f1_m: 0.7444 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7881 - val_precision_m: 0.6827 - val_f1_m: 0.7051\n",
      "Epoch 351/500\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7333 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7751 - val_precision_m: 0.6828 - val_f1_m: 0.7055\n",
      "Epoch 352/500\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7994 - precision_m: 0.7393 - f1_m: 0.7434 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7716 - val_precision_m: 0.6817 - val_f1_m: 0.7011\n",
      "Epoch 353/500\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7954 - precision_m: 0.7355 - f1_m: 0.7432 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7807 - val_precision_m: 0.6845 - val_f1_m: 0.6991\n",
      "Epoch 354/500\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8005 - precision_m: 0.7368 - f1_m: 0.7446 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7541 - val_precision_m: 0.6691 - val_f1_m: 0.6885\n",
      "Epoch 355/500\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7992 - precision_m: 0.7379 - f1_m: 0.7429 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7713 - val_precision_m: 0.6801 - val_f1_m: 0.6975\n",
      "Epoch 356/500\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7924 - precision_m: 0.7333 - f1_m: 0.7401 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7759 - val_precision_m: 0.6852 - val_f1_m: 0.7006\n",
      "Epoch 357/500\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7944 - precision_m: 0.7335 - f1_m: 0.7414 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7757 - val_precision_m: 0.6837 - val_f1_m: 0.7010\n",
      "Epoch 358/500\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7363 - f1_m: 0.7451 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7795 - val_precision_m: 0.6853 - val_f1_m: 0.7005\n",
      "Epoch 359/500\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7957 - precision_m: 0.7361 - f1_m: 0.7409 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7762 - val_precision_m: 0.6841 - val_f1_m: 0.7007\n",
      "Epoch 360/500\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8019 - precision_m: 0.7399 - f1_m: 0.7458 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7758 - val_precision_m: 0.6835 - val_f1_m: 0.6999\n",
      "Epoch 361/500\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8011 - precision_m: 0.7403 - f1_m: 0.7453 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7743 - val_precision_m: 0.6872 - val_f1_m: 0.7002\n",
      "Epoch 362/500\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7992 - precision_m: 0.7344 - f1_m: 0.7436 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7699 - val_precision_m: 0.6829 - val_f1_m: 0.7013\n",
      "Epoch 363/500\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7411 - f1_m: 0.7446 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7799 - val_precision_m: 0.6833 - val_f1_m: 0.7047\n",
      "Epoch 364/500\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7348 - f1_m: 0.7410 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7773 - val_precision_m: 0.6818 - val_f1_m: 0.7038\n",
      "Epoch 365/500\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8003 - precision_m: 0.7394 - f1_m: 0.7437 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7752 - val_precision_m: 0.6844 - val_f1_m: 0.6960\n",
      "Epoch 366/500\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7986 - precision_m: 0.7349 - f1_m: 0.7428 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7898 - val_precision_m: 0.6906 - val_f1_m: 0.7076\n",
      "Epoch 367/500\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7952 - precision_m: 0.7345 - f1_m: 0.7405 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7781 - val_precision_m: 0.6774 - val_f1_m: 0.6992\n",
      "Epoch 368/500\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7959 - precision_m: 0.7371 - f1_m: 0.7445 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7582 - val_precision_m: 0.6726 - val_f1_m: 0.6890\n",
      "Epoch 369/500\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8011 - precision_m: 0.7388 - f1_m: 0.7459 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7701 - val_precision_m: 0.6903 - val_f1_m: 0.7003\n",
      "Epoch 370/500\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7974 - precision_m: 0.7313 - f1_m: 0.7419 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7786 - val_precision_m: 0.6897 - val_f1_m: 0.7032\n",
      "Epoch 371/500\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7357 - f1_m: 0.7404 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7582 - val_precision_m: 0.6852 - val_f1_m: 0.6944\n",
      "Epoch 372/500\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7984 - precision_m: 0.7377 - f1_m: 0.7443 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7762 - val_precision_m: 0.6827 - val_f1_m: 0.7010\n",
      "Epoch 373/500\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00373: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7956 - precision_m: 0.7375 - f1_m: 0.7415 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7638 - val_precision_m: 0.6772 - val_f1_m: 0.6971\n",
      "Epoch 374/500\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7941 - precision_m: 0.7335 - f1_m: 0.7405 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7741 - val_precision_m: 0.6958 - val_f1_m: 0.7054\n",
      "Epoch 375/500\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7973 - precision_m: 0.7406 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7696 - val_precision_m: 0.6856 - val_f1_m: 0.6992\n",
      "Epoch 376/500\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7987 - precision_m: 0.7347 - f1_m: 0.7426 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7657 - val_precision_m: 0.6725 - val_f1_m: 0.6923\n",
      "Epoch 377/500\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7996 - precision_m: 0.7355 - f1_m: 0.7430 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7803 - val_precision_m: 0.6939 - val_f1_m: 0.7067\n",
      "Epoch 378/500\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7965 - precision_m: 0.7331 - f1_m: 0.7405 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7776 - val_precision_m: 0.6901 - val_f1_m: 0.7034\n",
      "Epoch 379/500\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7985 - precision_m: 0.7415 - f1_m: 0.7464 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7758 - val_precision_m: 0.6762 - val_f1_m: 0.6967\n",
      "Epoch 380/500\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7925 - precision_m: 0.7323 - f1_m: 0.7395 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7786 - val_precision_m: 0.6829 - val_f1_m: 0.7034\n",
      "Epoch 381/500\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7936 - precision_m: 0.7376 - f1_m: 0.7408 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7868 - val_precision_m: 0.6971 - val_f1_m: 0.7076\n",
      "Epoch 382/500\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7980 - precision_m: 0.7320 - f1_m: 0.7413 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7688 - val_precision_m: 0.6834 - val_f1_m: 0.6966\n",
      "Epoch 383/500\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7947 - precision_m: 0.7359 - f1_m: 0.7426 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7772 - val_precision_m: 0.6891 - val_f1_m: 0.7039\n",
      "Epoch 384/500\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7963 - precision_m: 0.7370 - f1_m: 0.7449 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7670 - val_precision_m: 0.6860 - val_f1_m: 0.7000\n",
      "Epoch 385/500\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8031 - precision_m: 0.7375 - f1_m: 0.7454 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7742 - val_precision_m: 0.6788 - val_f1_m: 0.7000\n",
      "Epoch 386/500\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7396 - f1_m: 0.7421 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7731 - val_precision_m: 0.6819 - val_f1_m: 0.7015\n",
      "Epoch 387/500\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7914 - precision_m: 0.7286 - f1_m: 0.7379 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7769 - val_precision_m: 0.6844 - val_f1_m: 0.7025\n",
      "Epoch 388/500\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8007 - precision_m: 0.7369 - f1_m: 0.7451 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7808 - val_precision_m: 0.6874 - val_f1_m: 0.7017\n",
      "Epoch 389/500\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7943 - precision_m: 0.7350 - f1_m: 0.7417 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7761 - val_precision_m: 0.6875 - val_f1_m: 0.7040\n",
      "Epoch 390/500\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7912 - precision_m: 0.7298 - f1_m: 0.7382 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7711 - val_precision_m: 0.6828 - val_f1_m: 0.6954\n",
      "Epoch 391/500\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7955 - precision_m: 0.7365 - f1_m: 0.7429 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7721 - val_precision_m: 0.6857 - val_f1_m: 0.7003\n",
      "Epoch 392/500\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7973 - precision_m: 0.7348 - f1_m: 0.7432 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7928 - val_precision_m: 0.6911 - val_f1_m: 0.7119\n",
      "Epoch 393/500\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00393: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7967 - precision_m: 0.7393 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7673 - val_precision_m: 0.6769 - val_f1_m: 0.6960\n",
      "Epoch 394/500\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7943 - precision_m: 0.7334 - f1_m: 0.7392 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7771 - val_precision_m: 0.6834 - val_f1_m: 0.7044\n",
      "Epoch 395/500\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7970 - precision_m: 0.7373 - f1_m: 0.7440 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7761 - val_precision_m: 0.6708 - val_f1_m: 0.6936\n",
      "Epoch 396/500\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7942 - precision_m: 0.7350 - f1_m: 0.7414 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7744 - val_precision_m: 0.6811 - val_f1_m: 0.6996\n",
      "Epoch 397/500\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8001 - precision_m: 0.7384 - f1_m: 0.7443 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7741 - val_precision_m: 0.6859 - val_f1_m: 0.6975\n",
      "Epoch 398/500\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7944 - precision_m: 0.7322 - f1_m: 0.7407 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7756 - val_precision_m: 0.6807 - val_f1_m: 0.6996\n",
      "Epoch 399/500\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7341 - f1_m: 0.7431 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7792 - val_precision_m: 0.6914 - val_f1_m: 0.7088\n",
      "Epoch 400/500\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8020 - precision_m: 0.7408 - f1_m: 0.7450 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7630 - val_precision_m: 0.6827 - val_f1_m: 0.6967\n",
      "Epoch 401/500\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7934 - precision_m: 0.7346 - f1_m: 0.7425 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7711 - val_precision_m: 0.6801 - val_f1_m: 0.7016\n",
      "Epoch 402/500\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7950 - precision_m: 0.7364 - f1_m: 0.7434 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7681 - val_precision_m: 0.6784 - val_f1_m: 0.6968\n",
      "Epoch 403/500\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7997 - precision_m: 0.7375 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7626 - val_precision_m: 0.6791 - val_f1_m: 0.6971\n",
      "Epoch 404/500\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7385 - f1_m: 0.7441 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7905 - val_precision_m: 0.6926 - val_f1_m: 0.7066\n",
      "Epoch 405/500\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8018 - precision_m: 0.7356 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7841 - val_precision_m: 0.6797 - val_f1_m: 0.7074\n",
      "Epoch 406/500\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8015 - precision_m: 0.7385 - f1_m: 0.7451 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7654 - val_precision_m: 0.6710 - val_f1_m: 0.6903\n",
      "Epoch 407/500\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7951 - precision_m: 0.7378 - f1_m: 0.7425 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7772 - val_precision_m: 0.6976 - val_f1_m: 0.7062\n",
      "Epoch 408/500\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7940 - precision_m: 0.7335 - f1_m: 0.7429 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7704 - val_precision_m: 0.6729 - val_f1_m: 0.6951\n",
      "Epoch 409/500\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7953 - precision_m: 0.7390 - f1_m: 0.7449 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7707 - val_precision_m: 0.6838 - val_f1_m: 0.7010\n",
      "Epoch 410/500\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7970 - precision_m: 0.7360 - f1_m: 0.7429 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7697 - val_precision_m: 0.6830 - val_f1_m: 0.7004\n",
      "Epoch 411/500\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7924 - precision_m: 0.7369 - f1_m: 0.7413 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7623 - val_precision_m: 0.6752 - val_f1_m: 0.6963\n",
      "Epoch 412/500\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7352 - f1_m: 0.7391 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7794 - val_precision_m: 0.6837 - val_f1_m: 0.7007\n",
      "Epoch 413/500\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7922 - precision_m: 0.7324 - f1_m: 0.7417 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7864 - val_precision_m: 0.6879 - val_f1_m: 0.7100\n",
      "Epoch 414/500\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7970 - precision_m: 0.7360 - f1_m: 0.7415 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7827 - val_precision_m: 0.6868 - val_f1_m: 0.7011\n",
      "Epoch 415/500\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7949 - precision_m: 0.7346 - f1_m: 0.7420 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7657 - val_precision_m: 0.6857 - val_f1_m: 0.6980\n",
      "Epoch 416/500\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7996 - precision_m: 0.7354 - f1_m: 0.7432 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7807 - val_precision_m: 0.6753 - val_f1_m: 0.6939\n",
      "Epoch 417/500\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7936 - precision_m: 0.7351 - f1_m: 0.7399 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7690 - val_precision_m: 0.6638 - val_f1_m: 0.6879\n",
      "Epoch 418/500\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7993 - precision_m: 0.7363 - f1_m: 0.7441 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7847 - val_precision_m: 0.6901 - val_f1_m: 0.7087\n",
      "Epoch 419/500\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7969 - precision_m: 0.7332 - f1_m: 0.7400 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7759 - val_precision_m: 0.6874 - val_f1_m: 0.6998\n",
      "Epoch 420/500\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7983 - precision_m: 0.7412 - f1_m: 0.7454 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7778 - val_precision_m: 0.6849 - val_f1_m: 0.7034\n",
      "Epoch 421/500\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7963 - precision_m: 0.7349 - f1_m: 0.7428 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7681 - val_precision_m: 0.6748 - val_f1_m: 0.6959\n",
      "Epoch 422/500\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7987 - precision_m: 0.7346 - f1_m: 0.7440 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7800 - val_precision_m: 0.6902 - val_f1_m: 0.7037\n",
      "Epoch 423/500\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7993 - precision_m: 0.7367 - f1_m: 0.7431 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7763 - val_precision_m: 0.6788 - val_f1_m: 0.6980\n",
      "Epoch 424/500\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7971 - precision_m: 0.7349 - f1_m: 0.7407 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7752 - val_precision_m: 0.6818 - val_f1_m: 0.7009\n",
      "Epoch 425/500\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7871 - precision_m: 0.7263 - f1_m: 0.7354 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7823 - val_precision_m: 0.6865 - val_f1_m: 0.7019\n",
      "Epoch 426/500\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8007 - precision_m: 0.7397 - f1_m: 0.7466 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7755 - val_precision_m: 0.6861 - val_f1_m: 0.7005\n",
      "Epoch 427/500\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7946 - precision_m: 0.7362 - f1_m: 0.7420 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7820 - val_precision_m: 0.6809 - val_f1_m: 0.7014\n",
      "Epoch 428/500\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7986 - precision_m: 0.7372 - f1_m: 0.7451 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7650 - val_precision_m: 0.6878 - val_f1_m: 0.6908\n",
      "Epoch 429/500\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7934 - precision_m: 0.7347 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7774 - val_precision_m: 0.6831 - val_f1_m: 0.7050\n",
      "Epoch 430/500\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7960 - precision_m: 0.7335 - f1_m: 0.7401 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7753 - val_precision_m: 0.6854 - val_f1_m: 0.7046\n",
      "Epoch 431/500\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7965 - precision_m: 0.7348 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7605 - val_precision_m: 0.6763 - val_f1_m: 0.6947\n",
      "Epoch 432/500\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7951 - precision_m: 0.7353 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7731 - val_precision_m: 0.6850 - val_f1_m: 0.6990\n",
      "Epoch 433/500\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00433: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7982 - precision_m: 0.7387 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7628 - val_precision_m: 0.6811 - val_f1_m: 0.6971\n",
      "Epoch 434/500\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7399 - f1_m: 0.7458 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7768 - val_precision_m: 0.6842 - val_f1_m: 0.7019\n",
      "Epoch 435/500\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8024 - precision_m: 0.7384 - f1_m: 0.7460 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7856 - val_precision_m: 0.6894 - val_f1_m: 0.7034\n",
      "Epoch 436/500\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7941 - precision_m: 0.7366 - f1_m: 0.7425 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7614 - val_precision_m: 0.6766 - val_f1_m: 0.6938\n",
      "Epoch 437/500\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7938 - precision_m: 0.7355 - f1_m: 0.7416 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7623 - val_precision_m: 0.6823 - val_f1_m: 0.6930\n",
      "Epoch 438/500\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7936 - precision_m: 0.7373 - f1_m: 0.7400 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7670 - val_precision_m: 0.6856 - val_f1_m: 0.6988\n",
      "Epoch 439/500\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7969 - precision_m: 0.7360 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7713 - val_precision_m: 0.6808 - val_f1_m: 0.7028\n",
      "Epoch 440/500\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7989 - precision_m: 0.7324 - f1_m: 0.7429 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7701 - val_precision_m: 0.6830 - val_f1_m: 0.6941\n",
      "Epoch 441/500\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7998 - precision_m: 0.7391 - f1_m: 0.7444 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7809 - val_precision_m: 0.6817 - val_f1_m: 0.6965\n",
      "Epoch 442/500\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7950 - precision_m: 0.7321 - f1_m: 0.7400 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7486 - val_precision_m: 0.6701 - val_f1_m: 0.6838\n",
      "Epoch 443/500\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7347 - f1_m: 0.7421 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7599 - val_precision_m: 0.6872 - val_f1_m: 0.6936\n",
      "Epoch 444/500\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7969 - precision_m: 0.7326 - f1_m: 0.7427 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7887 - val_precision_m: 0.6959 - val_f1_m: 0.7115\n",
      "Epoch 445/500\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7964 - precision_m: 0.7358 - f1_m: 0.7423 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7793 - val_precision_m: 0.6819 - val_f1_m: 0.7007\n",
      "Epoch 446/500\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7935 - precision_m: 0.7383 - f1_m: 0.7421 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7750 - val_precision_m: 0.6761 - val_f1_m: 0.6992\n",
      "Epoch 447/500\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7953 - precision_m: 0.7374 - f1_m: 0.7437 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7774 - val_precision_m: 0.6912 - val_f1_m: 0.7028\n",
      "Epoch 448/500\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8007 - precision_m: 0.7371 - f1_m: 0.7462 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7695 - val_precision_m: 0.6810 - val_f1_m: 0.6978\n",
      "Epoch 449/500\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7996 - precision_m: 0.7371 - f1_m: 0.7438 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7815 - val_precision_m: 0.6916 - val_f1_m: 0.7070\n",
      "Epoch 450/500\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7953 - precision_m: 0.7330 - f1_m: 0.7404 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7806 - val_precision_m: 0.6779 - val_f1_m: 0.7029\n",
      "Epoch 451/500\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7917 - precision_m: 0.7304 - f1_m: 0.7376 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7661 - val_precision_m: 0.6768 - val_f1_m: 0.6971\n",
      "Epoch 452/500\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8012 - precision_m: 0.7355 - f1_m: 0.7428 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7710 - val_precision_m: 0.6839 - val_f1_m: 0.7025\n",
      "Epoch 453/500\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00453: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7997 - precision_m: 0.7352 - f1_m: 0.7430 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7735 - val_precision_m: 0.6798 - val_f1_m: 0.7021\n",
      "Epoch 454/500\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7360 - f1_m: 0.7446 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7810 - val_precision_m: 0.6929 - val_f1_m: 0.7062\n",
      "Epoch 455/500\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7976 - precision_m: 0.7357 - f1_m: 0.7409 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7739 - val_precision_m: 0.6893 - val_f1_m: 0.7025\n",
      "Epoch 456/500\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7340 - f1_m: 0.7419 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7726 - val_precision_m: 0.6785 - val_f1_m: 0.6977\n",
      "Epoch 457/500\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7951 - precision_m: 0.7358 - f1_m: 0.7436 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7655 - val_precision_m: 0.6894 - val_f1_m: 0.7007\n",
      "Epoch 458/500\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7924 - precision_m: 0.7309 - f1_m: 0.7394 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7901 - val_precision_m: 0.6793 - val_f1_m: 0.7023\n",
      "Epoch 459/500\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7978 - precision_m: 0.7405 - f1_m: 0.7448 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7832 - val_precision_m: 0.6795 - val_f1_m: 0.6987\n",
      "Epoch 460/500\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7947 - precision_m: 0.7330 - f1_m: 0.7404 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7783 - val_precision_m: 0.6903 - val_f1_m: 0.7046\n",
      "Epoch 461/500\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8007 - precision_m: 0.7316 - f1_m: 0.7415 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7857 - val_precision_m: 0.6856 - val_f1_m: 0.7045\n",
      "Epoch 462/500\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8013 - precision_m: 0.7401 - f1_m: 0.7443 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7743 - val_precision_m: 0.6945 - val_f1_m: 0.7100\n",
      "Epoch 463/500\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7986 - precision_m: 0.7370 - f1_m: 0.7433 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7777 - val_precision_m: 0.6912 - val_f1_m: 0.7038\n",
      "Epoch 464/500\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8042 - precision_m: 0.7416 - f1_m: 0.7461 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7788 - val_precision_m: 0.6868 - val_f1_m: 0.7049\n",
      "Epoch 465/500\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7945 - precision_m: 0.7383 - f1_m: 0.7435 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7773 - val_precision_m: 0.6848 - val_f1_m: 0.7001\n",
      "Epoch 466/500\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7946 - precision_m: 0.7328 - f1_m: 0.7405 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7738 - val_precision_m: 0.6787 - val_f1_m: 0.6991\n",
      "Epoch 467/500\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7954 - precision_m: 0.7332 - f1_m: 0.7389 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7735 - val_precision_m: 0.6901 - val_f1_m: 0.7028\n",
      "Epoch 468/500\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7932 - precision_m: 0.7352 - f1_m: 0.7408 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7801 - val_precision_m: 0.6894 - val_f1_m: 0.7071\n",
      "Epoch 469/500\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7929 - precision_m: 0.7319 - f1_m: 0.7408 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7694 - val_precision_m: 0.6811 - val_f1_m: 0.7006\n",
      "Epoch 470/500\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7985 - precision_m: 0.7333 - f1_m: 0.7413 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7749 - val_precision_m: 0.6925 - val_f1_m: 0.7053\n",
      "Epoch 471/500\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8006 - precision_m: 0.7361 - f1_m: 0.7446 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7724 - val_precision_m: 0.6768 - val_f1_m: 0.6947\n",
      "Epoch 472/500\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7951 - precision_m: 0.7366 - f1_m: 0.7396 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7746 - val_precision_m: 0.6890 - val_f1_m: 0.7056\n",
      "Epoch 473/500\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00473: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7388 - f1_m: 0.7442 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7594 - val_precision_m: 0.6730 - val_f1_m: 0.6922\n",
      "Epoch 474/500\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8041 - precision_m: 0.7401 - f1_m: 0.7495 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7570 - val_precision_m: 0.6819 - val_f1_m: 0.6947\n",
      "Epoch 475/500\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7961 - precision_m: 0.7356 - f1_m: 0.7413 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7802 - val_precision_m: 0.6871 - val_f1_m: 0.7060\n",
      "Epoch 476/500\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8010 - precision_m: 0.7378 - f1_m: 0.7451 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7812 - val_precision_m: 0.6844 - val_f1_m: 0.7035\n",
      "Epoch 477/500\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8016 - precision_m: 0.7376 - f1_m: 0.7443 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7804 - val_precision_m: 0.6850 - val_f1_m: 0.6997\n",
      "Epoch 478/500\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7963 - precision_m: 0.7368 - f1_m: 0.7431 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7833 - val_precision_m: 0.6894 - val_f1_m: 0.7012\n",
      "Epoch 479/500\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8021 - precision_m: 0.7391 - f1_m: 0.7464 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7710 - val_precision_m: 0.6782 - val_f1_m: 0.6962\n",
      "Epoch 480/500\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7963 - precision_m: 0.7311 - f1_m: 0.7401 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7699 - val_precision_m: 0.6841 - val_f1_m: 0.6983\n",
      "Epoch 481/500\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7975 - precision_m: 0.7370 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7703 - val_precision_m: 0.6810 - val_f1_m: 0.6972\n",
      "Epoch 482/500\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8000 - precision_m: 0.7335 - f1_m: 0.7420 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7774 - val_precision_m: 0.6939 - val_f1_m: 0.7084\n",
      "Epoch 483/500\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8064 - precision_m: 0.7431 - f1_m: 0.7495 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7879 - val_precision_m: 0.6965 - val_f1_m: 0.7093\n",
      "Epoch 484/500\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7959 - precision_m: 0.7352 - f1_m: 0.7430 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7785 - val_precision_m: 0.6908 - val_f1_m: 0.7102\n",
      "Epoch 485/500\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7947 - precision_m: 0.7378 - f1_m: 0.7407 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7734 - val_precision_m: 0.6920 - val_f1_m: 0.7030\n",
      "Epoch 486/500\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8010 - precision_m: 0.7404 - f1_m: 0.7456 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7557 - val_precision_m: 0.6837 - val_f1_m: 0.6952\n",
      "Epoch 487/500\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7981 - precision_m: 0.7378 - f1_m: 0.7430 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7767 - val_precision_m: 0.6934 - val_f1_m: 0.7068\n",
      "Epoch 488/500\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7956 - precision_m: 0.7378 - f1_m: 0.7419 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7806 - val_precision_m: 0.6894 - val_f1_m: 0.7049\n",
      "Epoch 489/500\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7395 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7809 - val_precision_m: 0.6886 - val_f1_m: 0.7026\n",
      "Epoch 490/500\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7946 - precision_m: 0.7370 - f1_m: 0.7405 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7781 - val_precision_m: 0.6742 - val_f1_m: 0.6946\n",
      "Epoch 491/500\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.8005 - precision_m: 0.7402 - f1_m: 0.7456 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7781 - val_precision_m: 0.6845 - val_f1_m: 0.7020\n",
      "Epoch 492/500\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.53742\n",
      "6694/6694 - 2s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7988 - precision_m: 0.7326 - f1_m: 0.7403 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7690 - val_precision_m: 0.6827 - val_f1_m: 0.7019\n",
      "Epoch 493/500\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.53742\n",
      "\n",
      "Epoch 00493: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7972 - precision_m: 0.7394 - f1_m: 0.7458 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7870 - val_precision_m: 0.6834 - val_f1_m: 0.7092\n",
      "Epoch 494/500\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7984 - precision_m: 0.7407 - f1_m: 0.7453 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7792 - val_precision_m: 0.6894 - val_f1_m: 0.7035\n",
      "Epoch 495/500\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7958 - precision_m: 0.7353 - f1_m: 0.7424 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7699 - val_precision_m: 0.6822 - val_f1_m: 0.6963\n",
      "Epoch 496/500\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7943 - precision_m: 0.7352 - f1_m: 0.7416 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7828 - val_precision_m: 0.6867 - val_f1_m: 0.7034\n",
      "Epoch 497/500\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7934 - precision_m: 0.7367 - f1_m: 0.7410 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7731 - val_precision_m: 0.6885 - val_f1_m: 0.6970\n",
      "Epoch 498/500\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7979 - precision_m: 0.7390 - f1_m: 0.7447 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7792 - val_precision_m: 0.6851 - val_f1_m: 0.7050\n",
      "Epoch 499/500\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7949 - precision_m: 0.7351 - f1_m: 0.7428 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7699 - val_precision_m: 0.6909 - val_f1_m: 0.7023\n",
      "Epoch 500/500\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.53742\n",
      "6694/6694 - 1s - loss: 0.5209 - acc: 0.7423 - auc_32: 0.8183 - recall_m: 0.7942 - precision_m: 0.7335 - f1_m: 0.7390 - val_loss: 0.5509 - val_acc: 0.7180 - val_auc_32: 0.8015 - val_recall_m: 0.7783 - val_precision_m: 0.6803 - val_f1_m: 0.7021\n",
      "2615/2615 [==============================] - 0s 50us/sample - loss: 0.5397 - acc: 0.7281 - auc_32: 0.8024 - recall_m: 0.7897 - precision_m: 0.7280 - f1_m: 0.7531\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"FF_ori\"\n",
    "EPOCHS = 200\n",
    "PATIENCE = 200\n",
    "BATCH_SIZE = 8\n",
    "HIDDEN_LAYERS = [10]\n",
    "ACTIVATION = 'relu'\n",
    "L_RATE = 0.001\n",
    "model_name = '{}_ep{}_pa{}_bs{}_hs{}_lr_{}_{}'.format(base_model_name,EPOCHS,PATIENCE,BATCH_SIZE,HIDDEN_LAYERS,L_RATE,ACTIVATION)\n",
    "model_name\n",
    "model = get_FFNN_model(X_train, y_onehot, HIDDEN_LAYERS)\n",
    "\n",
    "model_path = os.path.join(RESULT_PATH, model_name)\n",
    "\n",
    "forge_gen = True\n",
    "\n",
    "if not os.path.exists(model_path) or forge_gen:\n",
    "    history = net_train(model, model_path, X_train, y_train, X_test, y_test, EPOCHS, save_model=True, VERBOSE=2)    \n",
    "    \n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    plt.figure(figsize=(14,6))\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.history[key], label=key)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(alpha=.2)\n",
    "    plt.title(f'batch_size = {BATCH_SIZE}, epochs = {EPOCHS}')\n",
    "    plt.draw()\n",
    "else:\n",
    "    print('Model loaded.')\n",
    "    model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: \n",
      "acc: 73.75%\n",
      "Test Set: \n",
      "acc: 72.81%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 808,  416],\n",
       "       [ 295, 1096]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores = model.evaluate(X_onehot_train.values, y_onehot_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# scores = model.evaluate(X_onehot_test.values, y_onehot_test)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "confusion_matrix(y_test, model.predict_classes(X_test), sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x00000183886EF288>, <tensorflow.python.keras.layers.core.Dense object at 0x000001838C4EC288>]\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 38us/sample - loss: 0.5592 - acc: 0.7247 - auc_34: 0.7910 - recall_m: 0.7631 - precision_m: 0.6984 - f1_m: 0.7196\n",
      "2\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x000001838C4E8F48>, <tensorflow.python.keras.layers.core.Dense object at 0x000001838F7A5DC8>]\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 43us/sample - loss: 0.5719 - acc: 0.7132 - auc_36: 0.7775 - recall_m: 0.7225 - precision_m: 0.6703 - f1_m: 0.6862\n",
      "3\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x0000018381BD3D48>, <tensorflow.python.keras.layers.core.Dense object at 0x000001838F9AD608>]\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 34us/sample - loss: 0.5555 - acc: 0.7199 - auc_38: 0.7917 - recall_m: 0.7338 - precision_m: 0.6936 - f1_m: 0.7023\n",
      "4\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x000001838C4E8988>, <tensorflow.python.keras.layers.core.Dense object at 0x000001838FA1E1C8>]\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 63us/sample - loss: 0.5660 - acc: 0.7137 - auc_40: 0.7800 - recall_m: 0.7588 - precision_m: 0.6839 - f1_m: 0.7083\n",
      "5\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x000001838C28FF48>, <tensorflow.python.keras.layers.core.Dense object at 0x0000018390BAB5C8>]\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2091/2091 [==============================] - 0s 46us/sample - loss: 0.5667 - acc: 0.7207 - auc_42: 0.7863 - recall_m: 0.7536 - precision_m: 0.6827 - f1_m: 0.7083\n",
      "\u001b[1m\n",
      "Mean Accuracy=  0.7184 , Sd=  0.0044\n",
      "Mean AUC=  0.7853 , Sd=  0.0057\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run_kf = True\n",
    "if run_kf:\n",
    "    n_folds = 5\n",
    "    kf = KFold(n_splits = n_folds, random_state = 1, shuffle = True)\n",
    "    \n",
    "    fold = 0\n",
    "    result_metrics_list = []\n",
    "    for train_idx, val_idx in kf.split(X1):\n",
    "        fold += 1\n",
    "        print(fold)\n",
    "        X_train = X1.iloc[train_idx]\n",
    "        y_train = y_onehot.iloc[train_idx]\n",
    "        X_val = X1.iloc[val_idx]\n",
    "        y_val = y_onehot.iloc[val_idx]\n",
    "\n",
    "        model = get_FFNN_model(X_train, y_train, HIDDEN_LAYERS)\n",
    "        history = net_train(model, model_path, X_train, y_train, X_val, y_val, EPOCHS, save_model=False, VERBOSE=False)    \n",
    "        score = model.evaluate(X_val, y_val)\n",
    "      \n",
    "        result_metrics_list.append([score])\n",
    "        \n",
    "    print(\"\\033[1m\")\n",
    "    print(\"Mean Accuracy= \",\"{:.4}\".format(np.mean(result_metrics_list,axis=0)[0][1]),\", Sd= \",\"{:.2}\".format(np.std(result_metrics_list,axis=0)[0][1]))\n",
    "    print(\"Mean AUC= \",\"{:.4}\".format(np.mean(result_metrics_list,axis=0)[0][2]),\", Sd= \",\"{:.2}\".format(np.std(result_metrics_list, axis=0)[0][2]))\n",
    "    print(\"\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepped data (WoE from Rudin)\n",
    "- Normal Scaling of numeric variables: f_load_data(1)\n",
    "- Binning (following Rudin) and one hot encoding: f_load_data(2)\n",
    "- Binning and applying WOE, calculating WOE on Rudin's bins: f_load_data(3)\n",
    "- Binning and applying WOE, following Rudin: f_load_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning and applying WOE, following Rudin (prep_option = 4)\n",
      "Target: Bad (y=1)\n",
      "Bad     5459\n",
      "Good    5000\n",
      "Name: RiskPerformance, dtype: int64\n",
      "[[   0 5000]\n",
      " [   1 5459]]\n",
      "X shape: (10459, 23)\n",
      "(7844, 23) (2615, 23) (7844, 1) (2615, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExternalRiskEstimate_bin_WOE</th>\n",
       "      <th>MSinceOldestTradeOpen_bin_WOE</th>\n",
       "      <th>MSinceMostRecentTradeOpen_bin_WOE</th>\n",
       "      <th>AverageMInFile_bin_WOE</th>\n",
       "      <th>NumSatisfactoryTrades_bin_WOE</th>\n",
       "      <th>NumTrades60Ever2DerogPubRec_bin_WOE</th>\n",
       "      <th>NumTrades90Ever2DerogPubRec_bin_WOE</th>\n",
       "      <th>NumTotalTrades_bin_WOE</th>\n",
       "      <th>NumTradesOpeninLast12M_bin_WOE</th>\n",
       "      <th>PercentTradesNeverDelq_bin_WOE</th>\n",
       "      <th>...</th>\n",
       "      <th>PercentInstallTrades_bin_WOE</th>\n",
       "      <th>NetFractionInstallBurden_bin_WOE</th>\n",
       "      <th>NumInstallTradesWBalance_bin_WOE</th>\n",
       "      <th>MSinceMostRecentInqexcl7days_bin_WOE</th>\n",
       "      <th>NumInqLast6M_bin_WOE</th>\n",
       "      <th>NumInqLast6Mexcl7days_bin_WOE</th>\n",
       "      <th>NetFractionRevolvingBurden_bin_WOE</th>\n",
       "      <th>NumRevolvingTradesWBalance_bin_WOE</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization_bin_WOE</th>\n",
       "      <th>PercentTradesWBalance_bin_WOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.799</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.242</td>\n",
       "      <td>1.223</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.799</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.999</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.223</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.601</td>\n",
       "      <td>-0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.017</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.238</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.242</td>\n",
       "      <td>1.223</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.313</td>\n",
       "      <td>1.223</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.094</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.242</td>\n",
       "      <td>1.223</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExternalRiskEstimate_bin_WOE  MSinceOldestTradeOpen_bin_WOE  \\\n",
       "0                         1.799                          0.086   \n",
       "1                         1.799                          0.549   \n",
       "2                         1.017                          0.549   \n",
       "3                         1.017                          0.086   \n",
       "4                        -1.094                         -0.148   \n",
       "\n",
       "   MSinceMostRecentTradeOpen_bin_WOE  AverageMInFile_bin_WOE  \\\n",
       "0                              0.083                   0.269   \n",
       "1                              0.083                   1.238   \n",
       "2                              0.083                   1.238   \n",
       "3                              0.083                   0.269   \n",
       "4                              0.000                   0.000   \n",
       "\n",
       "   NumSatisfactoryTrades_bin_WOE  NumTrades60Ever2DerogPubRec_bin_WOE  \\\n",
       "0                          0.166                                0.952   \n",
       "1                          1.999                                0.952   \n",
       "2                          0.539                               -0.021   \n",
       "3                         -0.086                               -0.021   \n",
       "4                          0.539                               -0.021   \n",
       "\n",
       "   NumTrades90Ever2DerogPubRec_bin_WOE  NumTotalTrades_bin_WOE  \\\n",
       "0                               -0.021                  -0.097   \n",
       "1                               -0.053                   0.535   \n",
       "2                               -0.021                   0.535   \n",
       "3                               -0.021                  -0.377   \n",
       "4                               -0.021                   0.116   \n",
       "\n",
       "   NumTradesOpeninLast12M_bin_WOE  PercentTradesNeverDelq_bin_WOE  ...  \\\n",
       "0                          -0.021                           1.012  ...   \n",
       "1                          -0.021                          -0.147  ...   \n",
       "2                           0.428                          -0.147  ...   \n",
       "3                           0.287                           0.366  ...   \n",
       "4                          -0.021                          -0.147  ...   \n",
       "\n",
       "   PercentInstallTrades_bin_WOE  NetFractionInstallBurden_bin_WOE  \\\n",
       "0                        -0.503                             0.047   \n",
       "1                         0.161                             0.047   \n",
       "2                        -0.503                             0.147   \n",
       "3                        -0.145                             0.363   \n",
       "4                        -0.620                             0.363   \n",
       "\n",
       "   NumInstallTradesWBalance_bin_WOE  MSinceMostRecentInqexcl7days_bin_WOE  \\\n",
       "0                             0.242                                 1.223   \n",
       "1                             0.256                                 1.223   \n",
       "2                             0.242                                 1.223   \n",
       "3                             0.313                                 1.223   \n",
       "4                             0.242                                 1.223   \n",
       "\n",
       "   NumInqLast6M_bin_WOE  NumInqLast6Mexcl7days_bin_WOE  \\\n",
       "0                -0.047                         -0.051   \n",
       "1                -0.047                         -0.051   \n",
       "2                 0.170                          0.021   \n",
       "3                 0.471                          0.021   \n",
       "4                -0.047                         -0.051   \n",
       "\n",
       "   NetFractionRevolvingBurden_bin_WOE  NumRevolvingTradesWBalance_bin_WOE  \\\n",
       "0                              -0.088                               0.034   \n",
       "1                              -0.739                              -0.188   \n",
       "2                               0.633                              -0.263   \n",
       "3                               0.633                              -0.150   \n",
       "4                               0.633                              -0.188   \n",
       "\n",
       "   NumBank2NatlTradesWHighUtilization_bin_WOE  PercentTradesWBalance_bin_WOE  \n",
       "0                                      -0.601                         -0.130  \n",
       "1                                       0.601                         -0.982  \n",
       "2                                      -0.601                          0.203  \n",
       "3                                       0.541                          0.772  \n",
       "4                                      -0.601                          0.203  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, X1, y, y_onehot = f_load_data(4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y_onehot, test_size = .25, random_state = 2020, shuffle = True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build same model and assess impact of woe binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Dense object at 0x0000018390BAA788>, <tensorflow.python.keras.layers.core.Dense object at 0x000001838E62DE88>]\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6275 samples, validate on 1569 samples\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56404, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 4s - loss: 0.5892 - acc: 0.6872 - auc_46: 0.7531 - recall_m: 0.7429 - precision_m: 0.6546 - f1_m: 0.6678 - val_loss: 0.5640 - val_acc: 0.7004 - val_auc_46: 0.7871 - val_recall_m: 0.8009 - val_precision_m: 0.6736 - val_f1_m: 0.7081\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56404 to 0.55162, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5496 - acc: 0.7273 - auc_46: 0.7957 - recall_m: 0.8071 - precision_m: 0.7098 - f1_m: 0.7332 - val_loss: 0.5516 - val_acc: 0.7189 - val_auc_46: 0.7959 - val_recall_m: 0.7873 - val_precision_m: 0.6847 - val_f1_m: 0.7113\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55162 to 0.54551, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5432 - acc: 0.7337 - auc_46: 0.8006 - recall_m: 0.7958 - precision_m: 0.7135 - f1_m: 0.7296 - val_loss: 0.5455 - val_acc: 0.7189 - val_auc_46: 0.8001 - val_recall_m: 0.7724 - val_precision_m: 0.6955 - val_f1_m: 0.7069\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54551 to 0.54293, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5397 - acc: 0.7345 - auc_46: 0.8031 - recall_m: 0.7961 - precision_m: 0.7277 - f1_m: 0.7345 - val_loss: 0.5429 - val_acc: 0.7221 - val_auc_46: 0.8030 - val_recall_m: 0.7982 - val_precision_m: 0.6889 - val_f1_m: 0.7166\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54293 to 0.54290, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5380 - acc: 0.7350 - auc_46: 0.8047 - recall_m: 0.8008 - precision_m: 0.7202 - f1_m: 0.7317 - val_loss: 0.5429 - val_acc: 0.7221 - val_auc_46: 0.8042 - val_recall_m: 0.8080 - val_precision_m: 0.6915 - val_f1_m: 0.7186\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54290 to 0.54079, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5367 - acc: 0.7372 - auc_46: 0.8059 - recall_m: 0.7971 - precision_m: 0.7242 - f1_m: 0.7358 - val_loss: 0.5408 - val_acc: 0.7202 - val_auc_46: 0.8049 - val_recall_m: 0.8015 - val_precision_m: 0.6895 - val_f1_m: 0.7161\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.54079\n",
      "6275/6275 - 2s - loss: 0.5354 - acc: 0.7374 - auc_46: 0.8068 - recall_m: 0.7941 - precision_m: 0.7292 - f1_m: 0.7350 - val_loss: 0.5444 - val_acc: 0.7177 - val_auc_46: 0.8063 - val_recall_m: 0.8223 - val_precision_m: 0.6819 - val_f1_m: 0.7200\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.54079 to 0.53921, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5351 - acc: 0.7366 - auc_46: 0.8073 - recall_m: 0.8007 - precision_m: 0.7188 - f1_m: 0.7356 - val_loss: 0.5392 - val_acc: 0.7189 - val_auc_46: 0.8050 - val_recall_m: 0.7800 - val_precision_m: 0.6958 - val_f1_m: 0.7130\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53921\n",
      "6275/6275 - 2s - loss: 0.5335 - acc: 0.7359 - auc_46: 0.8086 - recall_m: 0.7909 - precision_m: 0.7285 - f1_m: 0.7361 - val_loss: 0.5416 - val_acc: 0.7183 - val_auc_46: 0.8048 - val_recall_m: 0.8010 - val_precision_m: 0.6778 - val_f1_m: 0.7128\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.53921 to 0.53872, saving model to ./results\\FF_WOE_ep200_pa200_bs8_hs[10]_lr_0.001_relu\n",
      "6275/6275 - 2s - loss: 0.5339 - acc: 0.7396 - auc_46: 0.8085 - recall_m: 0.8026 - precision_m: 0.7313 - f1_m: 0.7407 - val_loss: 0.5387 - val_acc: 0.7189 - val_auc_46: 0.8053 - val_recall_m: 0.7787 - val_precision_m: 0.6849 - val_f1_m: 0.7098\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5336 - acc: 0.7382 - auc_46: 0.8084 - recall_m: 0.7954 - precision_m: 0.7229 - f1_m: 0.7366 - val_loss: 0.5397 - val_acc: 0.7196 - val_auc_46: 0.8053 - val_recall_m: 0.7856 - val_precision_m: 0.6949 - val_f1_m: 0.7142\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5330 - acc: 0.7393 - auc_46: 0.8089 - recall_m: 0.7957 - precision_m: 0.7285 - f1_m: 0.7382 - val_loss: 0.5393 - val_acc: 0.7208 - val_auc_46: 0.8047 - val_recall_m: 0.7855 - val_precision_m: 0.6867 - val_f1_m: 0.7024\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5324 - acc: 0.7399 - auc_46: 0.8093 - recall_m: 0.7933 - precision_m: 0.7282 - f1_m: 0.7377 - val_loss: 0.5433 - val_acc: 0.7215 - val_auc_46: 0.8045 - val_recall_m: 0.8013 - val_precision_m: 0.6875 - val_f1_m: 0.7183\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5323 - acc: 0.7390 - auc_46: 0.8094 - recall_m: 0.7961 - precision_m: 0.7262 - f1_m: 0.7361 - val_loss: 0.5409 - val_acc: 0.7234 - val_auc_46: 0.8040 - val_recall_m: 0.7677 - val_precision_m: 0.7010 - val_f1_m: 0.7042\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5321 - acc: 0.7380 - auc_46: 0.8092 - recall_m: 0.7930 - precision_m: 0.7260 - f1_m: 0.7368 - val_loss: 0.5401 - val_acc: 0.7189 - val_auc_46: 0.8047 - val_recall_m: 0.7947 - val_precision_m: 0.7040 - val_f1_m: 0.7225\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5317 - acc: 0.7390 - auc_46: 0.8097 - recall_m: 0.7972 - precision_m: 0.7215 - f1_m: 0.7358 - val_loss: 0.5416 - val_acc: 0.7221 - val_auc_46: 0.8035 - val_recall_m: 0.7690 - val_precision_m: 0.7105 - val_f1_m: 0.7134\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5314 - acc: 0.7402 - auc_46: 0.8101 - recall_m: 0.8027 - precision_m: 0.7321 - f1_m: 0.7399 - val_loss: 0.5397 - val_acc: 0.7247 - val_auc_46: 0.8042 - val_recall_m: 0.7740 - val_precision_m: 0.7067 - val_f1_m: 0.7142\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5310 - acc: 0.7396 - auc_46: 0.8104 - recall_m: 0.7974 - precision_m: 0.7296 - f1_m: 0.7394 - val_loss: 0.5434 - val_acc: 0.7208 - val_auc_46: 0.8039 - val_recall_m: 0.7923 - val_precision_m: 0.6883 - val_f1_m: 0.7133\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5307 - acc: 0.7398 - auc_46: 0.8106 - recall_m: 0.8024 - precision_m: 0.7309 - f1_m: 0.7408 - val_loss: 0.5445 - val_acc: 0.7196 - val_auc_46: 0.8033 - val_recall_m: 0.7987 - val_precision_m: 0.7008 - val_f1_m: 0.7211\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5298 - acc: 0.7385 - auc_46: 0.8111 - recall_m: 0.7997 - precision_m: 0.7303 - f1_m: 0.7403 - val_loss: 0.5458 - val_acc: 0.7189 - val_auc_46: 0.8038 - val_recall_m: 0.8274 - val_precision_m: 0.6944 - val_f1_m: 0.7309\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5303 - acc: 0.7383 - auc_46: 0.8109 - recall_m: 0.7965 - precision_m: 0.7234 - f1_m: 0.7348 - val_loss: 0.5434 - val_acc: 0.7177 - val_auc_46: 0.8027 - val_recall_m: 0.7712 - val_precision_m: 0.6911 - val_f1_m: 0.7031\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5298 - acc: 0.7382 - auc_46: 0.8112 - recall_m: 0.7905 - precision_m: 0.7284 - f1_m: 0.7341 - val_loss: 0.5416 - val_acc: 0.7221 - val_auc_46: 0.8030 - val_recall_m: 0.7695 - val_precision_m: 0.6941 - val_f1_m: 0.7099\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5290 - acc: 0.7398 - auc_46: 0.8118 - recall_m: 0.7932 - precision_m: 0.7254 - f1_m: 0.7335 - val_loss: 0.5427 - val_acc: 0.7196 - val_auc_46: 0.8035 - val_recall_m: 0.7952 - val_precision_m: 0.6958 - val_f1_m: 0.7144\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5292 - acc: 0.7372 - auc_46: 0.8118 - recall_m: 0.7920 - precision_m: 0.7248 - f1_m: 0.7349 - val_loss: 0.5425 - val_acc: 0.7228 - val_auc_46: 0.8027 - val_recall_m: 0.7610 - val_precision_m: 0.6981 - val_f1_m: 0.7042\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5290 - acc: 0.7402 - auc_46: 0.8116 - recall_m: 0.7982 - precision_m: 0.7280 - f1_m: 0.7364 - val_loss: 0.5434 - val_acc: 0.7183 - val_auc_46: 0.8029 - val_recall_m: 0.7881 - val_precision_m: 0.7008 - val_f1_m: 0.7153\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5288 - acc: 0.7390 - auc_46: 0.8120 - recall_m: 0.7959 - precision_m: 0.7270 - f1_m: 0.7363 - val_loss: 0.5433 - val_acc: 0.7183 - val_auc_46: 0.8018 - val_recall_m: 0.7764 - val_precision_m: 0.7020 - val_f1_m: 0.7119\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5283 - acc: 0.7386 - auc_46: 0.8123 - recall_m: 0.7946 - precision_m: 0.7288 - f1_m: 0.7363 - val_loss: 0.5415 - val_acc: 0.7221 - val_auc_46: 0.8029 - val_recall_m: 0.7625 - val_precision_m: 0.6912 - val_f1_m: 0.7021\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5285 - acc: 0.7396 - auc_46: 0.8122 - recall_m: 0.7966 - precision_m: 0.7311 - f1_m: 0.7393 - val_loss: 0.5421 - val_acc: 0.7202 - val_auc_46: 0.8021 - val_recall_m: 0.7662 - val_precision_m: 0.7019 - val_f1_m: 0.7043\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5279 - acc: 0.7383 - auc_46: 0.8127 - recall_m: 0.7829 - precision_m: 0.7195 - f1_m: 0.7264 - val_loss: 0.5440 - val_acc: 0.7196 - val_auc_46: 0.8016 - val_recall_m: 0.7787 - val_precision_m: 0.7134 - val_f1_m: 0.7130\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5277 - acc: 0.7382 - auc_46: 0.8125 - recall_m: 0.7972 - precision_m: 0.7274 - f1_m: 0.7365 - val_loss: 0.5437 - val_acc: 0.7215 - val_auc_46: 0.8022 - val_recall_m: 0.7863 - val_precision_m: 0.7021 - val_f1_m: 0.7172\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5271 - acc: 0.7390 - auc_46: 0.8136 - recall_m: 0.7911 - precision_m: 0.7291 - f1_m: 0.7341 - val_loss: 0.5438 - val_acc: 0.7208 - val_auc_46: 0.8030 - val_recall_m: 0.8019 - val_precision_m: 0.6923 - val_f1_m: 0.7170\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5268 - acc: 0.7383 - auc_46: 0.8136 - recall_m: 0.7973 - precision_m: 0.7291 - f1_m: 0.7388 - val_loss: 0.5476 - val_acc: 0.7170 - val_auc_46: 0.8017 - val_recall_m: 0.7989 - val_precision_m: 0.6815 - val_f1_m: 0.7156\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5272 - acc: 0.7388 - auc_46: 0.8132 - recall_m: 0.7987 - precision_m: 0.7262 - f1_m: 0.7386 - val_loss: 0.5423 - val_acc: 0.7215 - val_auc_46: 0.8022 - val_recall_m: 0.7836 - val_precision_m: 0.7004 - val_f1_m: 0.7182\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5273 - acc: 0.7359 - auc_46: 0.8130 - recall_m: 0.7924 - precision_m: 0.7272 - f1_m: 0.7351 - val_loss: 0.5442 - val_acc: 0.7196 - val_auc_46: 0.8015 - val_recall_m: 0.7762 - val_precision_m: 0.7114 - val_f1_m: 0.7133\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5271 - acc: 0.7383 - auc_46: 0.8135 - recall_m: 0.7951 - precision_m: 0.7307 - f1_m: 0.7372 - val_loss: 0.5427 - val_acc: 0.7215 - val_auc_46: 0.8016 - val_recall_m: 0.7684 - val_precision_m: 0.6992 - val_f1_m: 0.7072\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5271 - acc: 0.7374 - auc_46: 0.8135 - recall_m: 0.7911 - precision_m: 0.7288 - f1_m: 0.7339 - val_loss: 0.5448 - val_acc: 0.7202 - val_auc_46: 0.8005 - val_recall_m: 0.7605 - val_precision_m: 0.6938 - val_f1_m: 0.7041\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5269 - acc: 0.7406 - auc_46: 0.8134 - recall_m: 0.7991 - precision_m: 0.7305 - f1_m: 0.7375 - val_loss: 0.5436 - val_acc: 0.7215 - val_auc_46: 0.8012 - val_recall_m: 0.7800 - val_precision_m: 0.6986 - val_f1_m: 0.7116\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5266 - acc: 0.7371 - auc_46: 0.8138 - recall_m: 0.7990 - precision_m: 0.7289 - f1_m: 0.7391 - val_loss: 0.5445 - val_acc: 0.7189 - val_auc_46: 0.8007 - val_recall_m: 0.7552 - val_precision_m: 0.7076 - val_f1_m: 0.7053\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5264 - acc: 0.7390 - auc_46: 0.8139 - recall_m: 0.7909 - precision_m: 0.7268 - f1_m: 0.7339 - val_loss: 0.5456 - val_acc: 0.7234 - val_auc_46: 0.8014 - val_recall_m: 0.7845 - val_precision_m: 0.6859 - val_f1_m: 0.7127\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5261 - acc: 0.7393 - auc_46: 0.8143 - recall_m: 0.7923 - precision_m: 0.7227 - f1_m: 0.7353 - val_loss: 0.5440 - val_acc: 0.7221 - val_auc_46: 0.8015 - val_recall_m: 0.7802 - val_precision_m: 0.6915 - val_f1_m: 0.7122\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5256 - acc: 0.7401 - auc_46: 0.8145 - recall_m: 0.7920 - precision_m: 0.7302 - f1_m: 0.7380 - val_loss: 0.5465 - val_acc: 0.7202 - val_auc_46: 0.8012 - val_recall_m: 0.8085 - val_precision_m: 0.6961 - val_f1_m: 0.7238\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5261 - acc: 0.7359 - auc_46: 0.8140 - recall_m: 0.7868 - precision_m: 0.7219 - f1_m: 0.7303 - val_loss: 0.5463 - val_acc: 0.7221 - val_auc_46: 0.8011 - val_recall_m: 0.7973 - val_precision_m: 0.6955 - val_f1_m: 0.7150\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5262 - acc: 0.7380 - auc_46: 0.8140 - recall_m: 0.7983 - precision_m: 0.7284 - f1_m: 0.7393 - val_loss: 0.5455 - val_acc: 0.7196 - val_auc_46: 0.7998 - val_recall_m: 0.7674 - val_precision_m: 0.7018 - val_f1_m: 0.7096\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5256 - acc: 0.7367 - auc_46: 0.8142 - recall_m: 0.7930 - precision_m: 0.7286 - f1_m: 0.7340 - val_loss: 0.5468 - val_acc: 0.7208 - val_auc_46: 0.8008 - val_recall_m: 0.7920 - val_precision_m: 0.7028 - val_f1_m: 0.7191\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5257 - acc: 0.7385 - auc_46: 0.8145 - recall_m: 0.7980 - precision_m: 0.7287 - f1_m: 0.7365 - val_loss: 0.5449 - val_acc: 0.7208 - val_auc_46: 0.8004 - val_recall_m: 0.7584 - val_precision_m: 0.7132 - val_f1_m: 0.7091\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5257 - acc: 0.7394 - auc_46: 0.8143 - recall_m: 0.7888 - precision_m: 0.7327 - f1_m: 0.7366 - val_loss: 0.5451 - val_acc: 0.7183 - val_auc_46: 0.8003 - val_recall_m: 0.7508 - val_precision_m: 0.6911 - val_f1_m: 0.6983\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5254 - acc: 0.7367 - auc_46: 0.8148 - recall_m: 0.7925 - precision_m: 0.7310 - f1_m: 0.7346 - val_loss: 0.5450 - val_acc: 0.7240 - val_auc_46: 0.8010 - val_recall_m: 0.7903 - val_precision_m: 0.6985 - val_f1_m: 0.7178\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5248 - acc: 0.7410 - auc_46: 0.8150 - recall_m: 0.7886 - precision_m: 0.7322 - f1_m: 0.7370 - val_loss: 0.5494 - val_acc: 0.7196 - val_auc_46: 0.7991 - val_recall_m: 0.8039 - val_precision_m: 0.6898 - val_f1_m: 0.7191\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5254 - acc: 0.7404 - auc_46: 0.8146 - recall_m: 0.7963 - precision_m: 0.7361 - f1_m: 0.7403 - val_loss: 0.5456 - val_acc: 0.7215 - val_auc_46: 0.7998 - val_recall_m: 0.7871 - val_precision_m: 0.6943 - val_f1_m: 0.7091\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5250 - acc: 0.7410 - auc_46: 0.8150 - recall_m: 0.7957 - precision_m: 0.7278 - f1_m: 0.7383 - val_loss: 0.5477 - val_acc: 0.7183 - val_auc_46: 0.7995 - val_recall_m: 0.7626 - val_precision_m: 0.6988 - val_f1_m: 0.7040\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5247 - acc: 0.7388 - auc_46: 0.8153 - recall_m: 0.7902 - precision_m: 0.7356 - f1_m: 0.7384 - val_loss: 0.5447 - val_acc: 0.7202 - val_auc_46: 0.7999 - val_recall_m: 0.7533 - val_precision_m: 0.6934 - val_f1_m: 0.6968\n",
      "Epoch 52/200\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5245 - acc: 0.7378 - auc_46: 0.8153 - recall_m: 0.7891 - precision_m: 0.7253 - f1_m: 0.7312 - val_loss: 0.5487 - val_acc: 0.7196 - val_auc_46: 0.8001 - val_recall_m: 0.7947 - val_precision_m: 0.6962 - val_f1_m: 0.7193\n",
      "Epoch 53/200\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5248 - acc: 0.7383 - auc_46: 0.8147 - recall_m: 0.8000 - precision_m: 0.7294 - f1_m: 0.7403 - val_loss: 0.5454 - val_acc: 0.7170 - val_auc_46: 0.7992 - val_recall_m: 0.7473 - val_precision_m: 0.6946 - val_f1_m: 0.6935\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5249 - acc: 0.7399 - auc_46: 0.8151 - recall_m: 0.7920 - precision_m: 0.7271 - f1_m: 0.7348 - val_loss: 0.5480 - val_acc: 0.7202 - val_auc_46: 0.7997 - val_recall_m: 0.7803 - val_precision_m: 0.7053 - val_f1_m: 0.7170\n",
      "Epoch 55/200\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5251 - acc: 0.7399 - auc_46: 0.8149 - recall_m: 0.7892 - precision_m: 0.7291 - f1_m: 0.7330 - val_loss: 0.5453 - val_acc: 0.7183 - val_auc_46: 0.7997 - val_recall_m: 0.7575 - val_precision_m: 0.6973 - val_f1_m: 0.7015\n",
      "Epoch 56/200\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.53872\n",
      "6275/6275 - 3s - loss: 0.5251 - acc: 0.7402 - auc_46: 0.8148 - recall_m: 0.7882 - precision_m: 0.7272 - f1_m: 0.7333 - val_loss: 0.5479 - val_acc: 0.7170 - val_auc_46: 0.7991 - val_recall_m: 0.7622 - val_precision_m: 0.6956 - val_f1_m: 0.7085\n",
      "Epoch 57/200\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5247 - acc: 0.7402 - auc_46: 0.8151 - recall_m: 0.7894 - precision_m: 0.7263 - f1_m: 0.7337 - val_loss: 0.5457 - val_acc: 0.7234 - val_auc_46: 0.7990 - val_recall_m: 0.7818 - val_precision_m: 0.6985 - val_f1_m: 0.7123\n",
      "Epoch 58/200\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5245 - acc: 0.7409 - auc_46: 0.8154 - recall_m: 0.7939 - precision_m: 0.7272 - f1_m: 0.7333 - val_loss: 0.5484 - val_acc: 0.7183 - val_auc_46: 0.7988 - val_recall_m: 0.7706 - val_precision_m: 0.7023 - val_f1_m: 0.7129\n",
      "Epoch 59/200\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5246 - acc: 0.7402 - auc_46: 0.8151 - recall_m: 0.7955 - precision_m: 0.7389 - f1_m: 0.7430 - val_loss: 0.5484 - val_acc: 0.7215 - val_auc_46: 0.7989 - val_recall_m: 0.8024 - val_precision_m: 0.6997 - val_f1_m: 0.7183\n",
      "Epoch 60/200\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5246 - acc: 0.7394 - auc_46: 0.8149 - recall_m: 0.7977 - precision_m: 0.7332 - f1_m: 0.7413 - val_loss: 0.5462 - val_acc: 0.7240 - val_auc_46: 0.7990 - val_recall_m: 0.7875 - val_precision_m: 0.7007 - val_f1_m: 0.7182\n",
      "Epoch 61/200\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5244 - acc: 0.7422 - auc_46: 0.8156 - recall_m: 0.7915 - precision_m: 0.7349 - f1_m: 0.7368 - val_loss: 0.5489 - val_acc: 0.7202 - val_auc_46: 0.7989 - val_recall_m: 0.7552 - val_precision_m: 0.6920 - val_f1_m: 0.6994\n",
      "Epoch 62/200\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5247 - acc: 0.7406 - auc_46: 0.8152 - recall_m: 0.7931 - precision_m: 0.7297 - f1_m: 0.7365 - val_loss: 0.5479 - val_acc: 0.7183 - val_auc_46: 0.7981 - val_recall_m: 0.7593 - val_precision_m: 0.7013 - val_f1_m: 0.7043\n",
      "Epoch 63/200\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5249 - acc: 0.7398 - auc_46: 0.8151 - recall_m: 0.7927 - precision_m: 0.7283 - f1_m: 0.7374 - val_loss: 0.5469 - val_acc: 0.7208 - val_auc_46: 0.7993 - val_recall_m: 0.7963 - val_precision_m: 0.7088 - val_f1_m: 0.7246\n",
      "Epoch 64/200\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5240 - acc: 0.7401 - auc_46: 0.8158 - recall_m: 0.7871 - precision_m: 0.7305 - f1_m: 0.7353 - val_loss: 0.5485 - val_acc: 0.7189 - val_auc_46: 0.7998 - val_recall_m: 0.7904 - val_precision_m: 0.6984 - val_f1_m: 0.7201\n",
      "Epoch 65/200\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5243 - acc: 0.7399 - auc_46: 0.8154 - recall_m: 0.7927 - precision_m: 0.7338 - f1_m: 0.7357 - val_loss: 0.5484 - val_acc: 0.7228 - val_auc_46: 0.7990 - val_recall_m: 0.7606 - val_precision_m: 0.6866 - val_f1_m: 0.7048\n",
      "Epoch 66/200\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5241 - acc: 0.7382 - auc_46: 0.8155 - recall_m: 0.7905 - precision_m: 0.7313 - f1_m: 0.7358 - val_loss: 0.5464 - val_acc: 0.7208 - val_auc_46: 0.7984 - val_recall_m: 0.7716 - val_precision_m: 0.6829 - val_f1_m: 0.7014\n",
      "Epoch 67/200\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5242 - acc: 0.7394 - auc_46: 0.8157 - recall_m: 0.7882 - precision_m: 0.7304 - f1_m: 0.7350 - val_loss: 0.5482 - val_acc: 0.7177 - val_auc_46: 0.7981 - val_recall_m: 0.7655 - val_precision_m: 0.7038 - val_f1_m: 0.7093\n",
      "Epoch 68/200\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5244 - acc: 0.7431 - auc_46: 0.8150 - recall_m: 0.7916 - precision_m: 0.7331 - f1_m: 0.7379 - val_loss: 0.5473 - val_acc: 0.7202 - val_auc_46: 0.7981 - val_recall_m: 0.7599 - val_precision_m: 0.6919 - val_f1_m: 0.7014\n",
      "Epoch 69/200\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5239 - acc: 0.7398 - auc_46: 0.8159 - recall_m: 0.7908 - precision_m: 0.7334 - f1_m: 0.7393 - val_loss: 0.5487 - val_acc: 0.7208 - val_auc_46: 0.7982 - val_recall_m: 0.7840 - val_precision_m: 0.6845 - val_f1_m: 0.7104\n",
      "Epoch 70/200\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5245 - acc: 0.7409 - auc_46: 0.8153 - recall_m: 0.7904 - precision_m: 0.7235 - f1_m: 0.7316 - val_loss: 0.5464 - val_acc: 0.7228 - val_auc_46: 0.7987 - val_recall_m: 0.7737 - val_precision_m: 0.6862 - val_f1_m: 0.7002\n",
      "Epoch 71/200\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5240 - acc: 0.7407 - auc_46: 0.8158 - recall_m: 0.7891 - precision_m: 0.7350 - f1_m: 0.7356 - val_loss: 0.5493 - val_acc: 0.7189 - val_auc_46: 0.7991 - val_recall_m: 0.7907 - val_precision_m: 0.6922 - val_f1_m: 0.7132\n",
      "Epoch 72/200\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5234 - acc: 0.7398 - auc_46: 0.8164 - recall_m: 0.7932 - precision_m: 0.7265 - f1_m: 0.7348 - val_loss: 0.5472 - val_acc: 0.7196 - val_auc_46: 0.7986 - val_recall_m: 0.7535 - val_precision_m: 0.7067 - val_f1_m: 0.7038\n",
      "Epoch 73/200\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5237 - acc: 0.7398 - auc_46: 0.8159 - recall_m: 0.7905 - precision_m: 0.7337 - f1_m: 0.7367 - val_loss: 0.5502 - val_acc: 0.7215 - val_auc_46: 0.7985 - val_recall_m: 0.7899 - val_precision_m: 0.6959 - val_f1_m: 0.7171\n",
      "Epoch 74/200\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5241 - acc: 0.7422 - auc_46: 0.8154 - recall_m: 0.7919 - precision_m: 0.7345 - f1_m: 0.7388 - val_loss: 0.5485 - val_acc: 0.7215 - val_auc_46: 0.7987 - val_recall_m: 0.7825 - val_precision_m: 0.6805 - val_f1_m: 0.7050\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5236 - acc: 0.7410 - auc_46: 0.8162 - recall_m: 0.7911 - precision_m: 0.7338 - f1_m: 0.7399 - val_loss: 0.5484 - val_acc: 0.7215 - val_auc_46: 0.7981 - val_recall_m: 0.7712 - val_precision_m: 0.6941 - val_f1_m: 0.7060\n",
      "Epoch 76/200\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5240 - acc: 0.7414 - auc_46: 0.8157 - recall_m: 0.7894 - precision_m: 0.7286 - f1_m: 0.7348 - val_loss: 0.5478 - val_acc: 0.7208 - val_auc_46: 0.7983 - val_recall_m: 0.7914 - val_precision_m: 0.6933 - val_f1_m: 0.7138\n",
      "Epoch 77/200\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5237 - acc: 0.7404 - auc_46: 0.8163 - recall_m: 0.7903 - precision_m: 0.7304 - f1_m: 0.7341 - val_loss: 0.5470 - val_acc: 0.7247 - val_auc_46: 0.7983 - val_recall_m: 0.7720 - val_precision_m: 0.6991 - val_f1_m: 0.7098\n",
      "Epoch 78/200\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5235 - acc: 0.7415 - auc_46: 0.8161 - recall_m: 0.7959 - precision_m: 0.7309 - f1_m: 0.7404 - val_loss: 0.5490 - val_acc: 0.7208 - val_auc_46: 0.7974 - val_recall_m: 0.7628 - val_precision_m: 0.7124 - val_f1_m: 0.7102\n",
      "Epoch 79/200\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5238 - acc: 0.7412 - auc_46: 0.8156 - recall_m: 0.8004 - precision_m: 0.7372 - f1_m: 0.7410 - val_loss: 0.5501 - val_acc: 0.7240 - val_auc_46: 0.7981 - val_recall_m: 0.7907 - val_precision_m: 0.7030 - val_f1_m: 0.7172\n",
      "Epoch 80/200\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5238 - acc: 0.7428 - auc_46: 0.8160 - recall_m: 0.7914 - precision_m: 0.7337 - f1_m: 0.7376 - val_loss: 0.5472 - val_acc: 0.7259 - val_auc_46: 0.7978 - val_recall_m: 0.7804 - val_precision_m: 0.7068 - val_f1_m: 0.7178\n",
      "Epoch 81/200\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5234 - acc: 0.7402 - auc_46: 0.8164 - recall_m: 0.7906 - precision_m: 0.7363 - f1_m: 0.7388 - val_loss: 0.5487 - val_acc: 0.7240 - val_auc_46: 0.7984 - val_recall_m: 0.7826 - val_precision_m: 0.6973 - val_f1_m: 0.7126\n",
      "Epoch 82/200\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5237 - acc: 0.7404 - auc_46: 0.8163 - recall_m: 0.7948 - precision_m: 0.7310 - f1_m: 0.7366 - val_loss: 0.5486 - val_acc: 0.7221 - val_auc_46: 0.7985 - val_recall_m: 0.7776 - val_precision_m: 0.6978 - val_f1_m: 0.7116\n",
      "Epoch 83/200\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5233 - acc: 0.7423 - auc_46: 0.8163 - recall_m: 0.7900 - precision_m: 0.7327 - f1_m: 0.7365 - val_loss: 0.5475 - val_acc: 0.7234 - val_auc_46: 0.7978 - val_recall_m: 0.7425 - val_precision_m: 0.7047 - val_f1_m: 0.7017\n",
      "Epoch 84/200\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5232 - acc: 0.7415 - auc_46: 0.8166 - recall_m: 0.7934 - precision_m: 0.7303 - f1_m: 0.7384 - val_loss: 0.5478 - val_acc: 0.7215 - val_auc_46: 0.7984 - val_recall_m: 0.7694 - val_precision_m: 0.7138 - val_f1_m: 0.7100\n",
      "Epoch 85/200\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5232 - acc: 0.7415 - auc_46: 0.8166 - recall_m: 0.7937 - precision_m: 0.7327 - f1_m: 0.7400 - val_loss: 0.5482 - val_acc: 0.7247 - val_auc_46: 0.7986 - val_recall_m: 0.7645 - val_precision_m: 0.6906 - val_f1_m: 0.7036\n",
      "Epoch 86/200\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5237 - acc: 0.7410 - auc_46: 0.8162 - recall_m: 0.7900 - precision_m: 0.7291 - f1_m: 0.7351 - val_loss: 0.5477 - val_acc: 0.7253 - val_auc_46: 0.7986 - val_recall_m: 0.7819 - val_precision_m: 0.7059 - val_f1_m: 0.7157\n",
      "Epoch 87/200\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5229 - acc: 0.7393 - auc_46: 0.8165 - recall_m: 0.7842 - precision_m: 0.7315 - f1_m: 0.7338 - val_loss: 0.5484 - val_acc: 0.7221 - val_auc_46: 0.7986 - val_recall_m: 0.7753 - val_precision_m: 0.6919 - val_f1_m: 0.7056\n",
      "Epoch 88/200\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5228 - acc: 0.7433 - auc_46: 0.8169 - recall_m: 0.7879 - precision_m: 0.7359 - f1_m: 0.7370 - val_loss: 0.5471 - val_acc: 0.7228 - val_auc_46: 0.7981 - val_recall_m: 0.7730 - val_precision_m: 0.7119 - val_f1_m: 0.7153\n",
      "Epoch 89/200\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5236 - acc: 0.7402 - auc_46: 0.8159 - recall_m: 0.7913 - precision_m: 0.7360 - f1_m: 0.7407 - val_loss: 0.5475 - val_acc: 0.7247 - val_auc_46: 0.7978 - val_recall_m: 0.7767 - val_precision_m: 0.7155 - val_f1_m: 0.7192\n",
      "Epoch 90/200\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5234 - acc: 0.7407 - auc_46: 0.8164 - recall_m: 0.7931 - precision_m: 0.7310 - f1_m: 0.7379 - val_loss: 0.5469 - val_acc: 0.7202 - val_auc_46: 0.7985 - val_recall_m: 0.7761 - val_precision_m: 0.6896 - val_f1_m: 0.7087\n",
      "Epoch 91/200\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5228 - acc: 0.7414 - auc_46: 0.8166 - recall_m: 0.7894 - precision_m: 0.7328 - f1_m: 0.7354 - val_loss: 0.5457 - val_acc: 0.7228 - val_auc_46: 0.7988 - val_recall_m: 0.7539 - val_precision_m: 0.6982 - val_f1_m: 0.7048\n",
      "Epoch 92/200\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5229 - acc: 0.7431 - auc_46: 0.8169 - recall_m: 0.7930 - precision_m: 0.7369 - f1_m: 0.7397 - val_loss: 0.5472 - val_acc: 0.7253 - val_auc_46: 0.7979 - val_recall_m: 0.7781 - val_precision_m: 0.7006 - val_f1_m: 0.7118\n",
      "Epoch 93/200\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5229 - acc: 0.7410 - auc_46: 0.8167 - recall_m: 0.7924 - precision_m: 0.7304 - f1_m: 0.7380 - val_loss: 0.5483 - val_acc: 0.7208 - val_auc_46: 0.7977 - val_recall_m: 0.7615 - val_precision_m: 0.7009 - val_f1_m: 0.7050\n",
      "Epoch 94/200\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5229 - acc: 0.7404 - auc_46: 0.8169 - recall_m: 0.7816 - precision_m: 0.7290 - f1_m: 0.7314 - val_loss: 0.5518 - val_acc: 0.7208 - val_auc_46: 0.7986 - val_recall_m: 0.7898 - val_precision_m: 0.6823 - val_f1_m: 0.7126\n",
      "Epoch 95/200\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5228 - acc: 0.7434 - auc_46: 0.8169 - recall_m: 0.7909 - precision_m: 0.7359 - f1_m: 0.7392 - val_loss: 0.5462 - val_acc: 0.7234 - val_auc_46: 0.7983 - val_recall_m: 0.7875 - val_precision_m: 0.7048 - val_f1_m: 0.7203\n",
      "Epoch 96/200\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5222 - acc: 0.7420 - auc_46: 0.8174 - recall_m: 0.7923 - precision_m: 0.7368 - f1_m: 0.7385 - val_loss: 0.5493 - val_acc: 0.7247 - val_auc_46: 0.7982 - val_recall_m: 0.7895 - val_precision_m: 0.6954 - val_f1_m: 0.7185\n",
      "Epoch 97/200\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5227 - acc: 0.7445 - auc_46: 0.8167 - recall_m: 0.7950 - precision_m: 0.7404 - f1_m: 0.7429 - val_loss: 0.5481 - val_acc: 0.7259 - val_auc_46: 0.7979 - val_recall_m: 0.7727 - val_precision_m: 0.6849 - val_f1_m: 0.7049\n",
      "Epoch 98/200\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5231 - acc: 0.7418 - auc_46: 0.8165 - recall_m: 0.7916 - precision_m: 0.7274 - f1_m: 0.7351 - val_loss: 0.5484 - val_acc: 0.7234 - val_auc_46: 0.7980 - val_recall_m: 0.7775 - val_precision_m: 0.6978 - val_f1_m: 0.7131\n",
      "Epoch 99/200\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5223 - acc: 0.7450 - auc_46: 0.8170 - recall_m: 0.7947 - precision_m: 0.7344 - f1_m: 0.7404 - val_loss: 0.5495 - val_acc: 0.7266 - val_auc_46: 0.7979 - val_recall_m: 0.7976 - val_precision_m: 0.6997 - val_f1_m: 0.7232\n",
      "Epoch 100/200\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5226 - acc: 0.7429 - auc_46: 0.8169 - recall_m: 0.7928 - precision_m: 0.7367 - f1_m: 0.7401 - val_loss: 0.5499 - val_acc: 0.7189 - val_auc_46: 0.7967 - val_recall_m: 0.7450 - val_precision_m: 0.7133 - val_f1_m: 0.7003\n",
      "Epoch 101/200\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5229 - acc: 0.7428 - auc_46: 0.8166 - recall_m: 0.7896 - precision_m: 0.7383 - f1_m: 0.7385 - val_loss: 0.5498 - val_acc: 0.7240 - val_auc_46: 0.7976 - val_recall_m: 0.7855 - val_precision_m: 0.6971 - val_f1_m: 0.7141\n",
      "Epoch 102/200\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5224 - acc: 0.7417 - auc_46: 0.8172 - recall_m: 0.7989 - precision_m: 0.7319 - f1_m: 0.7398 - val_loss: 0.5507 - val_acc: 0.7228 - val_auc_46: 0.7976 - val_recall_m: 0.7765 - val_precision_m: 0.7080 - val_f1_m: 0.7136\n",
      "Epoch 103/200\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5221 - acc: 0.7441 - auc_46: 0.8177 - recall_m: 0.7969 - precision_m: 0.7391 - f1_m: 0.7438 - val_loss: 0.5487 - val_acc: 0.7202 - val_auc_46: 0.7971 - val_recall_m: 0.7504 - val_precision_m: 0.7076 - val_f1_m: 0.7034\n",
      "Epoch 104/200\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5225 - acc: 0.7406 - auc_46: 0.8169 - recall_m: 0.7915 - precision_m: 0.7324 - f1_m: 0.7366 - val_loss: 0.5498 - val_acc: 0.7240 - val_auc_46: 0.7969 - val_recall_m: 0.7661 - val_precision_m: 0.6935 - val_f1_m: 0.6995\n",
      "Epoch 105/200\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5227 - acc: 0.7425 - auc_46: 0.8169 - recall_m: 0.7937 - precision_m: 0.7355 - f1_m: 0.7391 - val_loss: 0.5481 - val_acc: 0.7266 - val_auc_46: 0.7977 - val_recall_m: 0.7898 - val_precision_m: 0.7030 - val_f1_m: 0.7226\n",
      "Epoch 106/200\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5225 - acc: 0.7410 - auc_46: 0.8172 - recall_m: 0.7850 - precision_m: 0.7326 - f1_m: 0.7353 - val_loss: 0.5493 - val_acc: 0.7259 - val_auc_46: 0.7974 - val_recall_m: 0.7762 - val_precision_m: 0.7022 - val_f1_m: 0.7159\n",
      "Epoch 107/200\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5225 - acc: 0.7447 - auc_46: 0.8173 - recall_m: 0.7923 - precision_m: 0.7390 - f1_m: 0.7433 - val_loss: 0.5489 - val_acc: 0.7221 - val_auc_46: 0.7976 - val_recall_m: 0.7849 - val_precision_m: 0.6974 - val_f1_m: 0.7186\n",
      "Epoch 108/200\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5214 - acc: 0.7437 - auc_46: 0.8179 - recall_m: 0.7988 - precision_m: 0.7374 - f1_m: 0.7432 - val_loss: 0.5497 - val_acc: 0.7228 - val_auc_46: 0.7966 - val_recall_m: 0.7621 - val_precision_m: 0.6988 - val_f1_m: 0.7096\n",
      "Epoch 109/200\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5220 - acc: 0.7423 - auc_46: 0.8173 - recall_m: 0.7920 - precision_m: 0.7368 - f1_m: 0.7401 - val_loss: 0.5492 - val_acc: 0.7228 - val_auc_46: 0.7968 - val_recall_m: 0.7773 - val_precision_m: 0.7016 - val_f1_m: 0.7122\n",
      "Epoch 110/200\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5224 - acc: 0.7422 - auc_46: 0.8174 - recall_m: 0.7913 - precision_m: 0.7327 - f1_m: 0.7385 - val_loss: 0.5497 - val_acc: 0.7228 - val_auc_46: 0.7966 - val_recall_m: 0.7791 - val_precision_m: 0.6967 - val_f1_m: 0.7108\n",
      "Epoch 111/200\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5221 - acc: 0.7447 - auc_46: 0.8174 - recall_m: 0.7969 - precision_m: 0.7378 - f1_m: 0.7425 - val_loss: 0.5489 - val_acc: 0.7259 - val_auc_46: 0.7971 - val_recall_m: 0.7870 - val_precision_m: 0.7127 - val_f1_m: 0.7200\n",
      "Epoch 112/200\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5220 - acc: 0.7429 - auc_46: 0.8177 - recall_m: 0.7938 - precision_m: 0.7271 - f1_m: 0.7376 - val_loss: 0.5491 - val_acc: 0.7253 - val_auc_46: 0.7970 - val_recall_m: 0.7795 - val_precision_m: 0.6925 - val_f1_m: 0.7114\n",
      "Epoch 113/200\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5224 - acc: 0.7431 - auc_46: 0.8170 - recall_m: 0.7954 - precision_m: 0.7354 - f1_m: 0.7377 - val_loss: 0.5498 - val_acc: 0.7221 - val_auc_46: 0.7971 - val_recall_m: 0.7935 - val_precision_m: 0.7029 - val_f1_m: 0.7156\n",
      "Epoch 114/200\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5216 - acc: 0.7433 - auc_46: 0.8177 - recall_m: 0.7968 - precision_m: 0.7347 - f1_m: 0.7402 - val_loss: 0.5499 - val_acc: 0.7253 - val_auc_46: 0.7973 - val_recall_m: 0.7785 - val_precision_m: 0.7018 - val_f1_m: 0.7107\n",
      "Epoch 115/200\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5222 - acc: 0.7436 - auc_46: 0.8175 - recall_m: 0.7904 - precision_m: 0.7258 - f1_m: 0.7343 - val_loss: 0.5498 - val_acc: 0.7215 - val_auc_46: 0.7977 - val_recall_m: 0.7775 - val_precision_m: 0.6806 - val_f1_m: 0.7005\n",
      "Epoch 116/200\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5210 - acc: 0.7444 - auc_46: 0.8183 - recall_m: 0.8015 - precision_m: 0.7363 - f1_m: 0.7434 - val_loss: 0.5518 - val_acc: 0.7234 - val_auc_46: 0.7954 - val_recall_m: 0.7488 - val_precision_m: 0.7000 - val_f1_m: 0.7011\n",
      "Epoch 117/200\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5218 - acc: 0.7444 - auc_46: 0.8177 - recall_m: 0.7948 - precision_m: 0.7421 - f1_m: 0.7443 - val_loss: 0.5516 - val_acc: 0.7234 - val_auc_46: 0.7965 - val_recall_m: 0.7812 - val_precision_m: 0.6942 - val_f1_m: 0.7125\n",
      "Epoch 118/200\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5218 - acc: 0.7429 - auc_46: 0.8179 - recall_m: 0.7970 - precision_m: 0.7354 - f1_m: 0.7407 - val_loss: 0.5488 - val_acc: 0.7228 - val_auc_46: 0.7971 - val_recall_m: 0.7855 - val_precision_m: 0.6894 - val_f1_m: 0.7083\n",
      "Epoch 119/200\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5218 - acc: 0.7437 - auc_46: 0.8178 - recall_m: 0.7926 - precision_m: 0.7354 - f1_m: 0.7409 - val_loss: 0.5488 - val_acc: 0.7215 - val_auc_46: 0.7967 - val_recall_m: 0.7806 - val_precision_m: 0.6956 - val_f1_m: 0.7115\n",
      "Epoch 120/200\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5216 - acc: 0.7398 - auc_46: 0.8180 - recall_m: 0.7935 - precision_m: 0.7301 - f1_m: 0.7373 - val_loss: 0.5503 - val_acc: 0.7247 - val_auc_46: 0.7965 - val_recall_m: 0.7578 - val_precision_m: 0.6996 - val_f1_m: 0.7023\n",
      "Epoch 121/200\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5213 - acc: 0.7426 - auc_46: 0.8182 - recall_m: 0.7864 - precision_m: 0.7321 - f1_m: 0.7351 - val_loss: 0.5547 - val_acc: 0.7177 - val_auc_46: 0.7976 - val_recall_m: 0.7968 - val_precision_m: 0.6977 - val_f1_m: 0.7201\n",
      "Epoch 122/200\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5214 - acc: 0.7450 - auc_46: 0.8180 - recall_m: 0.8069 - precision_m: 0.7341 - f1_m: 0.7434 - val_loss: 0.5481 - val_acc: 0.7240 - val_auc_46: 0.7973 - val_recall_m: 0.7739 - val_precision_m: 0.7019 - val_f1_m: 0.7133\n",
      "Epoch 123/200\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5214 - acc: 0.7433 - auc_46: 0.8178 - recall_m: 0.7938 - precision_m: 0.7289 - f1_m: 0.7385 - val_loss: 0.5500 - val_acc: 0.7221 - val_auc_46: 0.7958 - val_recall_m: 0.7428 - val_precision_m: 0.7089 - val_f1_m: 0.7027\n",
      "Epoch 124/200\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5213 - acc: 0.7436 - auc_46: 0.8182 - recall_m: 0.7928 - precision_m: 0.7369 - f1_m: 0.7406 - val_loss: 0.5478 - val_acc: 0.7215 - val_auc_46: 0.7974 - val_recall_m: 0.7802 - val_precision_m: 0.7109 - val_f1_m: 0.7149\n",
      "Epoch 125/200\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5214 - acc: 0.7439 - auc_46: 0.8182 - recall_m: 0.7897 - precision_m: 0.7350 - f1_m: 0.7384 - val_loss: 0.5478 - val_acc: 0.7208 - val_auc_46: 0.7974 - val_recall_m: 0.7757 - val_precision_m: 0.6918 - val_f1_m: 0.7104\n",
      "Epoch 126/200\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5215 - acc: 0.7415 - auc_46: 0.8180 - recall_m: 0.7848 - precision_m: 0.7294 - f1_m: 0.7308 - val_loss: 0.5522 - val_acc: 0.7177 - val_auc_46: 0.7978 - val_recall_m: 0.7899 - val_precision_m: 0.6886 - val_f1_m: 0.7132\n",
      "Epoch 127/200\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5212 - acc: 0.7433 - auc_46: 0.8182 - recall_m: 0.7934 - precision_m: 0.7263 - f1_m: 0.7360 - val_loss: 0.5499 - val_acc: 0.7202 - val_auc_46: 0.7960 - val_recall_m: 0.7621 - val_precision_m: 0.7137 - val_f1_m: 0.7089\n",
      "Epoch 128/200\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5216 - acc: 0.7431 - auc_46: 0.8181 - recall_m: 0.7997 - precision_m: 0.7358 - f1_m: 0.7432 - val_loss: 0.5510 - val_acc: 0.7240 - val_auc_46: 0.7956 - val_recall_m: 0.7767 - val_precision_m: 0.7052 - val_f1_m: 0.7139\n",
      "Epoch 129/200\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5208 - acc: 0.7447 - auc_46: 0.8187 - recall_m: 0.7979 - precision_m: 0.7360 - f1_m: 0.7419 - val_loss: 0.5495 - val_acc: 0.7208 - val_auc_46: 0.7972 - val_recall_m: 0.7789 - val_precision_m: 0.6935 - val_f1_m: 0.7103\n",
      "Epoch 130/200\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5213 - acc: 0.7444 - auc_46: 0.8182 - recall_m: 0.7954 - precision_m: 0.7330 - f1_m: 0.7389 - val_loss: 0.5504 - val_acc: 0.7189 - val_auc_46: 0.7967 - val_recall_m: 0.7826 - val_precision_m: 0.6870 - val_f1_m: 0.7076\n",
      "Epoch 131/200\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5209 - acc: 0.7466 - auc_46: 0.8187 - recall_m: 0.7994 - precision_m: 0.7370 - f1_m: 0.7420 - val_loss: 0.5493 - val_acc: 0.7240 - val_auc_46: 0.7968 - val_recall_m: 0.7815 - val_precision_m: 0.7071 - val_f1_m: 0.7146\n",
      "Epoch 132/200\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5211 - acc: 0.7461 - auc_46: 0.8184 - recall_m: 0.7931 - precision_m: 0.7414 - f1_m: 0.7447 - val_loss: 0.5493 - val_acc: 0.7247 - val_auc_46: 0.7968 - val_recall_m: 0.7666 - val_precision_m: 0.6957 - val_f1_m: 0.7061\n",
      "Epoch 133/200\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5209 - acc: 0.7445 - auc_46: 0.8184 - recall_m: 0.7940 - precision_m: 0.7311 - f1_m: 0.7370 - val_loss: 0.5511 - val_acc: 0.7208 - val_auc_46: 0.7968 - val_recall_m: 0.7839 - val_precision_m: 0.6950 - val_f1_m: 0.7148\n",
      "Epoch 134/200\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5209 - acc: 0.7422 - auc_46: 0.8184 - recall_m: 0.7946 - precision_m: 0.7323 - f1_m: 0.7373 - val_loss: 0.5491 - val_acc: 0.7202 - val_auc_46: 0.7973 - val_recall_m: 0.7820 - val_precision_m: 0.6926 - val_f1_m: 0.7149\n",
      "Epoch 135/200\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5209 - acc: 0.7437 - auc_46: 0.8186 - recall_m: 0.7943 - precision_m: 0.7363 - f1_m: 0.7391 - val_loss: 0.5496 - val_acc: 0.7259 - val_auc_46: 0.7967 - val_recall_m: 0.7820 - val_precision_m: 0.7138 - val_f1_m: 0.7181\n",
      "Epoch 136/200\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5203 - acc: 0.7434 - auc_46: 0.8190 - recall_m: 0.7866 - precision_m: 0.7233 - f1_m: 0.7327 - val_loss: 0.5504 - val_acc: 0.7240 - val_auc_46: 0.7960 - val_recall_m: 0.7732 - val_precision_m: 0.6973 - val_f1_m: 0.7112\n",
      "Epoch 137/200\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5205 - acc: 0.7434 - auc_46: 0.8188 - recall_m: 0.7917 - precision_m: 0.7287 - f1_m: 0.7367 - val_loss: 0.5503 - val_acc: 0.7247 - val_auc_46: 0.7969 - val_recall_m: 0.7790 - val_precision_m: 0.7011 - val_f1_m: 0.7136\n",
      "Epoch 138/200\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5208 - acc: 0.7453 - auc_46: 0.8189 - recall_m: 0.7982 - precision_m: 0.7385 - f1_m: 0.7436 - val_loss: 0.5480 - val_acc: 0.7240 - val_auc_46: 0.7973 - val_recall_m: 0.7892 - val_precision_m: 0.7065 - val_f1_m: 0.7170\n",
      "Epoch 139/200\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5197 - acc: 0.7468 - auc_46: 0.8194 - recall_m: 0.8028 - precision_m: 0.7413 - f1_m: 0.7469 - val_loss: 0.5513 - val_acc: 0.7221 - val_auc_46: 0.7962 - val_recall_m: 0.7495 - val_precision_m: 0.7091 - val_f1_m: 0.6960\n",
      "Epoch 140/200\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5212 - acc: 0.7425 - auc_46: 0.8182 - recall_m: 0.7959 - precision_m: 0.7418 - f1_m: 0.7417 - val_loss: 0.5498 - val_acc: 0.7240 - val_auc_46: 0.7974 - val_recall_m: 0.7745 - val_precision_m: 0.6858 - val_f1_m: 0.7037\n",
      "Epoch 141/200\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5204 - acc: 0.7425 - auc_46: 0.8187 - recall_m: 0.7945 - precision_m: 0.7359 - f1_m: 0.7406 - val_loss: 0.5491 - val_acc: 0.7221 - val_auc_46: 0.7976 - val_recall_m: 0.7783 - val_precision_m: 0.6961 - val_f1_m: 0.7117\n",
      "Epoch 142/200\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5210 - acc: 0.7439 - auc_46: 0.8186 - recall_m: 0.7914 - precision_m: 0.7285 - f1_m: 0.7357 - val_loss: 0.5476 - val_acc: 0.7215 - val_auc_46: 0.7980 - val_recall_m: 0.7723 - val_precision_m: 0.6953 - val_f1_m: 0.7061\n",
      "Epoch 143/200\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5208 - acc: 0.7428 - auc_46: 0.8185 - recall_m: 0.7958 - precision_m: 0.7355 - f1_m: 0.7389 - val_loss: 0.5489 - val_acc: 0.7228 - val_auc_46: 0.7980 - val_recall_m: 0.7623 - val_precision_m: 0.6803 - val_f1_m: 0.6986\n",
      "Epoch 144/200\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5201 - acc: 0.7450 - auc_46: 0.8191 - recall_m: 0.7969 - precision_m: 0.7404 - f1_m: 0.7438 - val_loss: 0.5515 - val_acc: 0.7240 - val_auc_46: 0.7970 - val_recall_m: 0.7532 - val_precision_m: 0.6976 - val_f1_m: 0.7040\n",
      "Epoch 145/200\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5205 - acc: 0.7445 - auc_46: 0.8184 - recall_m: 0.7876 - precision_m: 0.7336 - f1_m: 0.7379 - val_loss: 0.5478 - val_acc: 0.7228 - val_auc_46: 0.7977 - val_recall_m: 0.7552 - val_precision_m: 0.6944 - val_f1_m: 0.6959\n",
      "Epoch 146/200\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5204 - acc: 0.7436 - auc_46: 0.8190 - recall_m: 0.7934 - precision_m: 0.7361 - f1_m: 0.7398 - val_loss: 0.5479 - val_acc: 0.7240 - val_auc_46: 0.7972 - val_recall_m: 0.7613 - val_precision_m: 0.7059 - val_f1_m: 0.7107\n",
      "Epoch 147/200\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5200 - acc: 0.7428 - auc_46: 0.8193 - recall_m: 0.7980 - precision_m: 0.7377 - f1_m: 0.7442 - val_loss: 0.5505 - val_acc: 0.7234 - val_auc_46: 0.7974 - val_recall_m: 0.7776 - val_precision_m: 0.6934 - val_f1_m: 0.7059\n",
      "Epoch 148/200\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5201 - acc: 0.7452 - auc_46: 0.8192 - recall_m: 0.8008 - precision_m: 0.7337 - f1_m: 0.7426 - val_loss: 0.5488 - val_acc: 0.7240 - val_auc_46: 0.7970 - val_recall_m: 0.7795 - val_precision_m: 0.7054 - val_f1_m: 0.7165\n",
      "Epoch 149/200\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5196 - acc: 0.7428 - auc_46: 0.8195 - recall_m: 0.7962 - precision_m: 0.7325 - f1_m: 0.7402 - val_loss: 0.5489 - val_acc: 0.7253 - val_auc_46: 0.7974 - val_recall_m: 0.7792 - val_precision_m: 0.7014 - val_f1_m: 0.7130\n",
      "Epoch 150/200\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5202 - acc: 0.7463 - auc_46: 0.8190 - recall_m: 0.7987 - precision_m: 0.7347 - f1_m: 0.7426 - val_loss: 0.5509 - val_acc: 0.7247 - val_auc_46: 0.7964 - val_recall_m: 0.7694 - val_precision_m: 0.6915 - val_f1_m: 0.7082\n",
      "Epoch 151/200\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5194 - acc: 0.7450 - auc_46: 0.8200 - recall_m: 0.7919 - precision_m: 0.7403 - f1_m: 0.7391 - val_loss: 0.5509 - val_acc: 0.7247 - val_auc_46: 0.7968 - val_recall_m: 0.7977 - val_precision_m: 0.7033 - val_f1_m: 0.7200\n",
      "Epoch 152/200\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5198 - acc: 0.7439 - auc_46: 0.8192 - recall_m: 0.7948 - precision_m: 0.7345 - f1_m: 0.7410 - val_loss: 0.5514 - val_acc: 0.7228 - val_auc_46: 0.7960 - val_recall_m: 0.7670 - val_precision_m: 0.6940 - val_f1_m: 0.7075\n",
      "Epoch 153/200\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5201 - acc: 0.7468 - auc_46: 0.8191 - recall_m: 0.7938 - precision_m: 0.7336 - f1_m: 0.7407 - val_loss: 0.5500 - val_acc: 0.7259 - val_auc_46: 0.7977 - val_recall_m: 0.7804 - val_precision_m: 0.6994 - val_f1_m: 0.7157\n",
      "Epoch 154/200\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5201 - acc: 0.7453 - auc_46: 0.8193 - recall_m: 0.7955 - precision_m: 0.7355 - f1_m: 0.7404 - val_loss: 0.5498 - val_acc: 0.7221 - val_auc_46: 0.7964 - val_recall_m: 0.7601 - val_precision_m: 0.6991 - val_f1_m: 0.7016\n",
      "Epoch 155/200\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5197 - acc: 0.7466 - auc_46: 0.8191 - recall_m: 0.7976 - precision_m: 0.7375 - f1_m: 0.7417 - val_loss: 0.5501 - val_acc: 0.7240 - val_auc_46: 0.7969 - val_recall_m: 0.7741 - val_precision_m: 0.6933 - val_f1_m: 0.7090\n",
      "Epoch 156/200\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5195 - acc: 0.7458 - auc_46: 0.8197 - recall_m: 0.7946 - precision_m: 0.7348 - f1_m: 0.7395 - val_loss: 0.5497 - val_acc: 0.7253 - val_auc_46: 0.7962 - val_recall_m: 0.7583 - val_precision_m: 0.7103 - val_f1_m: 0.7147\n",
      "Epoch 157/200\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5195 - acc: 0.7484 - auc_46: 0.8196 - recall_m: 0.7935 - precision_m: 0.7396 - f1_m: 0.7430 - val_loss: 0.5500 - val_acc: 0.7253 - val_auc_46: 0.7965 - val_recall_m: 0.7724 - val_precision_m: 0.7061 - val_f1_m: 0.7160\n",
      "Epoch 158/200\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5197 - acc: 0.7442 - auc_46: 0.8196 - recall_m: 0.7939 - precision_m: 0.7368 - f1_m: 0.7427 - val_loss: 0.5507 - val_acc: 0.7202 - val_auc_46: 0.7970 - val_recall_m: 0.7925 - val_precision_m: 0.7046 - val_f1_m: 0.7193\n",
      "Epoch 159/200\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5195 - acc: 0.7452 - auc_46: 0.8193 - recall_m: 0.7906 - precision_m: 0.7333 - f1_m: 0.7399 - val_loss: 0.5525 - val_acc: 0.7208 - val_auc_46: 0.7962 - val_recall_m: 0.7592 - val_precision_m: 0.7119 - val_f1_m: 0.7095\n",
      "Epoch 160/200\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5194 - acc: 0.7442 - auc_46: 0.8197 - recall_m: 0.7845 - precision_m: 0.7347 - f1_m: 0.7372 - val_loss: 0.5519 - val_acc: 0.7228 - val_auc_46: 0.7975 - val_recall_m: 0.7766 - val_precision_m: 0.6893 - val_f1_m: 0.7041\n",
      "Epoch 161/200\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5197 - acc: 0.7457 - auc_46: 0.8196 - recall_m: 0.8013 - precision_m: 0.7377 - f1_m: 0.7441 - val_loss: 0.5485 - val_acc: 0.7228 - val_auc_46: 0.7966 - val_recall_m: 0.7591 - val_precision_m: 0.7142 - val_f1_m: 0.7115\n",
      "Epoch 162/200\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5194 - acc: 0.7437 - auc_46: 0.8197 - recall_m: 0.7943 - precision_m: 0.7336 - f1_m: 0.7384 - val_loss: 0.5487 - val_acc: 0.7221 - val_auc_46: 0.7965 - val_recall_m: 0.7857 - val_precision_m: 0.7138 - val_f1_m: 0.7182\n",
      "Epoch 163/200\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5194 - acc: 0.7457 - auc_46: 0.8198 - recall_m: 0.7983 - precision_m: 0.7393 - f1_m: 0.7442 - val_loss: 0.5507 - val_acc: 0.7240 - val_auc_46: 0.7969 - val_recall_m: 0.7890 - val_precision_m: 0.6975 - val_f1_m: 0.7175\n",
      "Epoch 164/200\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5191 - acc: 0.7450 - auc_46: 0.8197 - recall_m: 0.7904 - precision_m: 0.7345 - f1_m: 0.7380 - val_loss: 0.5513 - val_acc: 0.7247 - val_auc_46: 0.7957 - val_recall_m: 0.7789 - val_precision_m: 0.7027 - val_f1_m: 0.7145\n",
      "Epoch 165/200\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5186 - acc: 0.7457 - auc_46: 0.8204 - recall_m: 0.7989 - precision_m: 0.7404 - f1_m: 0.7454 - val_loss: 0.5481 - val_acc: 0.7228 - val_auc_46: 0.7965 - val_recall_m: 0.7596 - val_precision_m: 0.7004 - val_f1_m: 0.7100\n",
      "Epoch 166/200\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5193 - acc: 0.7458 - auc_46: 0.8198 - recall_m: 0.8055 - precision_m: 0.7388 - f1_m: 0.7461 - val_loss: 0.5490 - val_acc: 0.7247 - val_auc_46: 0.7963 - val_recall_m: 0.7672 - val_precision_m: 0.7143 - val_f1_m: 0.7170\n",
      "Epoch 167/200\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5191 - acc: 0.7458 - auc_46: 0.8198 - recall_m: 0.7914 - precision_m: 0.7274 - f1_m: 0.7360 - val_loss: 0.5490 - val_acc: 0.7228 - val_auc_46: 0.7968 - val_recall_m: 0.7714 - val_precision_m: 0.7142 - val_f1_m: 0.7114\n",
      "Epoch 168/200\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5191 - acc: 0.7474 - auc_46: 0.8198 - recall_m: 0.7962 - precision_m: 0.7404 - f1_m: 0.7449 - val_loss: 0.5489 - val_acc: 0.7234 - val_auc_46: 0.7963 - val_recall_m: 0.7423 - val_precision_m: 0.6979 - val_f1_m: 0.6972\n",
      "Epoch 169/200\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5195 - acc: 0.7468 - auc_46: 0.8195 - recall_m: 0.7916 - precision_m: 0.7338 - f1_m: 0.7398 - val_loss: 0.5514 - val_acc: 0.7259 - val_auc_46: 0.7962 - val_recall_m: 0.7735 - val_precision_m: 0.6942 - val_f1_m: 0.7116\n",
      "Epoch 170/200\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5189 - acc: 0.7444 - auc_46: 0.8201 - recall_m: 0.7885 - precision_m: 0.7354 - f1_m: 0.7381 - val_loss: 0.5518 - val_acc: 0.7221 - val_auc_46: 0.7981 - val_recall_m: 0.7948 - val_precision_m: 0.6946 - val_f1_m: 0.7199\n",
      "Epoch 171/200\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5189 - acc: 0.7436 - auc_46: 0.8203 - recall_m: 0.7989 - precision_m: 0.7334 - f1_m: 0.7416 - val_loss: 0.5532 - val_acc: 0.7228 - val_auc_46: 0.7940 - val_recall_m: 0.7456 - val_precision_m: 0.7140 - val_f1_m: 0.7044\n",
      "Epoch 172/200\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5190 - acc: 0.7465 - auc_46: 0.8200 - recall_m: 0.7933 - precision_m: 0.7389 - f1_m: 0.7427 - val_loss: 0.5525 - val_acc: 0.7221 - val_auc_46: 0.7969 - val_recall_m: 0.7725 - val_precision_m: 0.6940 - val_f1_m: 0.7070\n",
      "Epoch 173/200\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5187 - acc: 0.7452 - auc_46: 0.8203 - recall_m: 0.7945 - precision_m: 0.7359 - f1_m: 0.7404 - val_loss: 0.5530 - val_acc: 0.7247 - val_auc_46: 0.7971 - val_recall_m: 0.7776 - val_precision_m: 0.6833 - val_f1_m: 0.7071\n",
      "Epoch 174/200\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5182 - acc: 0.7455 - auc_46: 0.8204 - recall_m: 0.7958 - precision_m: 0.7315 - f1_m: 0.7389 - val_loss: 0.5525 - val_acc: 0.7221 - val_auc_46: 0.7957 - val_recall_m: 0.7581 - val_precision_m: 0.6970 - val_f1_m: 0.7073\n",
      "Epoch 175/200\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5189 - acc: 0.7463 - auc_46: 0.8202 - recall_m: 0.7937 - precision_m: 0.7386 - f1_m: 0.7406 - val_loss: 0.5525 - val_acc: 0.7228 - val_auc_46: 0.7985 - val_recall_m: 0.8021 - val_precision_m: 0.6992 - val_f1_m: 0.7236\n",
      "Epoch 176/200\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5184 - acc: 0.7468 - auc_46: 0.8206 - recall_m: 0.8032 - precision_m: 0.7388 - f1_m: 0.7470 - val_loss: 0.5511 - val_acc: 0.7240 - val_auc_46: 0.7971 - val_recall_m: 0.7957 - val_precision_m: 0.7035 - val_f1_m: 0.7226\n",
      "Epoch 177/200\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5190 - acc: 0.7455 - auc_46: 0.8201 - recall_m: 0.7943 - precision_m: 0.7385 - f1_m: 0.7429 - val_loss: 0.5501 - val_acc: 0.7221 - val_auc_46: 0.7970 - val_recall_m: 0.7897 - val_precision_m: 0.7055 - val_f1_m: 0.7198\n",
      "Epoch 178/200\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5190 - acc: 0.7480 - auc_46: 0.8200 - recall_m: 0.7959 - precision_m: 0.7360 - f1_m: 0.7406 - val_loss: 0.5516 - val_acc: 0.7151 - val_auc_46: 0.7978 - val_recall_m: 0.7868 - val_precision_m: 0.6966 - val_f1_m: 0.7113\n",
      "Epoch 179/200\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5189 - acc: 0.7461 - auc_46: 0.8203 - recall_m: 0.7955 - precision_m: 0.7353 - f1_m: 0.7412 - val_loss: 0.5509 - val_acc: 0.7202 - val_auc_46: 0.7979 - val_recall_m: 0.7911 - val_precision_m: 0.6969 - val_f1_m: 0.7148\n",
      "Epoch 180/200\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5187 - acc: 0.7437 - auc_46: 0.8205 - recall_m: 0.7958 - precision_m: 0.7333 - f1_m: 0.7398 - val_loss: 0.5503 - val_acc: 0.7228 - val_auc_46: 0.7970 - val_recall_m: 0.7893 - val_precision_m: 0.6953 - val_f1_m: 0.7151\n",
      "Epoch 181/200\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5182 - acc: 0.7449 - auc_46: 0.8209 - recall_m: 0.7937 - precision_m: 0.7360 - f1_m: 0.7393 - val_loss: 0.5526 - val_acc: 0.7215 - val_auc_46: 0.7967 - val_recall_m: 0.7729 - val_precision_m: 0.7063 - val_f1_m: 0.7120\n",
      "Epoch 182/200\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5186 - acc: 0.7473 - auc_46: 0.8204 - recall_m: 0.8013 - precision_m: 0.7398 - f1_m: 0.7466 - val_loss: 0.5512 - val_acc: 0.7215 - val_auc_46: 0.7960 - val_recall_m: 0.7749 - val_precision_m: 0.6968 - val_f1_m: 0.7119\n",
      "Epoch 183/200\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5186 - acc: 0.7460 - auc_46: 0.8205 - recall_m: 0.7908 - precision_m: 0.7387 - f1_m: 0.7396 - val_loss: 0.5509 - val_acc: 0.7170 - val_auc_46: 0.7974 - val_recall_m: 0.7806 - val_precision_m: 0.6869 - val_f1_m: 0.7106\n",
      "Epoch 184/200\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5183 - acc: 0.7436 - auc_46: 0.8207 - recall_m: 0.7917 - precision_m: 0.7345 - f1_m: 0.7389 - val_loss: 0.5519 - val_acc: 0.7189 - val_auc_46: 0.7967 - val_recall_m: 0.7816 - val_precision_m: 0.6837 - val_f1_m: 0.7100\n",
      "Epoch 185/200\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5186 - acc: 0.7458 - auc_46: 0.8207 - recall_m: 0.8036 - precision_m: 0.7320 - f1_m: 0.7422 - val_loss: 0.5497 - val_acc: 0.7221 - val_auc_46: 0.7960 - val_recall_m: 0.7782 - val_precision_m: 0.7065 - val_f1_m: 0.7170\n",
      "Epoch 186/200\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5184 - acc: 0.7444 - auc_46: 0.8205 - recall_m: 0.7936 - precision_m: 0.7290 - f1_m: 0.7376 - val_loss: 0.5487 - val_acc: 0.7228 - val_auc_46: 0.7965 - val_recall_m: 0.7630 - val_precision_m: 0.6972 - val_f1_m: 0.7038\n",
      "Epoch 187/200\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5178 - acc: 0.7463 - auc_46: 0.8211 - recall_m: 0.7921 - precision_m: 0.7382 - f1_m: 0.7405 - val_loss: 0.5489 - val_acc: 0.7228 - val_auc_46: 0.7955 - val_recall_m: 0.7903 - val_precision_m: 0.7124 - val_f1_m: 0.7238\n",
      "Epoch 188/200\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5181 - acc: 0.7457 - auc_46: 0.8208 - recall_m: 0.7940 - precision_m: 0.7406 - f1_m: 0.7430 - val_loss: 0.5491 - val_acc: 0.7228 - val_auc_46: 0.7962 - val_recall_m: 0.7578 - val_precision_m: 0.6975 - val_f1_m: 0.7055\n",
      "Epoch 189/200\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5183 - acc: 0.7469 - auc_46: 0.8202 - recall_m: 0.7991 - precision_m: 0.7378 - f1_m: 0.7436 - val_loss: 0.5504 - val_acc: 0.7183 - val_auc_46: 0.7960 - val_recall_m: 0.7715 - val_precision_m: 0.6924 - val_f1_m: 0.7054\n",
      "Epoch 190/200\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5185 - acc: 0.7453 - auc_46: 0.8205 - recall_m: 0.7931 - precision_m: 0.7400 - f1_m: 0.7412 - val_loss: 0.5527 - val_acc: 0.7202 - val_auc_46: 0.7960 - val_recall_m: 0.7741 - val_precision_m: 0.6892 - val_f1_m: 0.7072\n",
      "Epoch 191/200\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5182 - acc: 0.7463 - auc_46: 0.8208 - recall_m: 0.7969 - precision_m: 0.7438 - f1_m: 0.7464 - val_loss: 0.5515 - val_acc: 0.7215 - val_auc_46: 0.7958 - val_recall_m: 0.7601 - val_precision_m: 0.6868 - val_f1_m: 0.7000\n",
      "Epoch 192/200\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5179 - acc: 0.7485 - auc_46: 0.8209 - recall_m: 0.8011 - precision_m: 0.7417 - f1_m: 0.7450 - val_loss: 0.5516 - val_acc: 0.7208 - val_auc_46: 0.7967 - val_recall_m: 0.7729 - val_precision_m: 0.6893 - val_f1_m: 0.7098\n",
      "Epoch 193/200\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5175 - acc: 0.7482 - auc_46: 0.8213 - recall_m: 0.7948 - precision_m: 0.7428 - f1_m: 0.7438 - val_loss: 0.5515 - val_acc: 0.7221 - val_auc_46: 0.7965 - val_recall_m: 0.7718 - val_precision_m: 0.7055 - val_f1_m: 0.7102\n",
      "Epoch 194/200\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5179 - acc: 0.7479 - auc_46: 0.8213 - recall_m: 0.7901 - precision_m: 0.7378 - f1_m: 0.7416 - val_loss: 0.5543 - val_acc: 0.7228 - val_auc_46: 0.7960 - val_recall_m: 0.7882 - val_precision_m: 0.6974 - val_f1_m: 0.7163\n",
      "Epoch 195/200\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5180 - acc: 0.7468 - auc_46: 0.8207 - recall_m: 0.7998 - precision_m: 0.7408 - f1_m: 0.7455 - val_loss: 0.5559 - val_acc: 0.7215 - val_auc_46: 0.7975 - val_recall_m: 0.8166 - val_precision_m: 0.6916 - val_f1_m: 0.7249\n",
      "Epoch 196/200\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5179 - acc: 0.7473 - auc_46: 0.8211 - recall_m: 0.7990 - precision_m: 0.7419 - f1_m: 0.7442 - val_loss: 0.5558 - val_acc: 0.7221 - val_auc_46: 0.7969 - val_recall_m: 0.8033 - val_precision_m: 0.6872 - val_f1_m: 0.7164\n",
      "Epoch 197/200\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5179 - acc: 0.7476 - auc_46: 0.8207 - recall_m: 0.8033 - precision_m: 0.7416 - f1_m: 0.7481 - val_loss: 0.5510 - val_acc: 0.7215 - val_auc_46: 0.7948 - val_recall_m: 0.7682 - val_precision_m: 0.7055 - val_f1_m: 0.7103\n",
      "Epoch 198/200\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.53872\n",
      "6275/6275 - 1s - loss: 0.5176 - acc: 0.7479 - auc_46: 0.8211 - recall_m: 0.7901 - precision_m: 0.7420 - f1_m: 0.7419 - val_loss: 0.5520 - val_acc: 0.7196 - val_auc_46: 0.7954 - val_recall_m: 0.7824 - val_precision_m: 0.7017 - val_f1_m: 0.7127\n",
      "Epoch 199/200\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5176 - acc: 0.7487 - auc_46: 0.8212 - recall_m: 0.7957 - precision_m: 0.7346 - f1_m: 0.7417 - val_loss: 0.5510 - val_acc: 0.7183 - val_auc_46: 0.7971 - val_recall_m: 0.7936 - val_precision_m: 0.6976 - val_f1_m: 0.7178\n",
      "Epoch 200/200\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.53872\n",
      "6275/6275 - 2s - loss: 0.5172 - acc: 0.7477 - auc_46: 0.8215 - recall_m: 0.7899 - precision_m: 0.7385 - f1_m: 0.7420 - val_loss: 0.5543 - val_acc: 0.7202 - val_auc_46: 0.7974 - val_recall_m: 0.7959 - val_precision_m: 0.6976 - val_f1_m: 0.7165\n",
      "2615/2615 [==============================] - 0s 41us/sample - loss: 0.5619 - acc: 0.7163 - auc_46: 0.7869 - recall_m: 0.7863 - precision_m: 0.7138 - f1_m: 0.7418\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzIAAAF1CAYAAAAz99/QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOydd5wcZd3Av8/M9nZ7t9dLLr0SkhB6i3SkN1GqqDQLShFBQLEiiigiSBGlK6L0Ji2hhQTSe8/lei/b68zz/jG7m7vcXQokQHzne5/97N7UZ5555nl+9RkhpcTExMTExMTExMTExGRvQvm8C2BiYmJiYmJiYmJiYrKrmIqMiYmJiYmJiYmJicleh6nImJiYmJiYmJiYmJjsdZiKjImJiYmJiYmJiYnJXoepyJiYmJiYmJiYmJiY7HWYioyJiYmJiYmJiYmJyV6HqciYmJiY7CRCiC1CiGM/g/P8TAjxxG483k1CiId21/H+PyGEeEcIcennXQ4TExMTk8GYioyJiYnJZ8DnKRBLKW+TUn4hhHEhRJEQ4l9CiK7s50khhO/zLtcXESFEqRDin0KIFiFEUAgxVwhx0DbbnC+EqBdCRIUQzwshivqtswsh/i6ECAkh2oQQ1372V2FiYmKy5zAVGRMTExOTz5JfAYXAaGAMUAb87PMs0BcYD7AAmAkUAY8CrwghPABCiCnAA8BFGPUYA/7Sb/+fAeOAWuAo4EdCiBM/q8KbmJiY7GlMRcbExMRk1zhACLFaCNErhHhYCOEAEEIUCiFeFkJ0Zte9LISozq77NXAEcI8QIiKEuCe7fIoQ4k0hRI8Qol0IcVO/89iEEI8JIcJCiFVCiP13VDAhxA1CiObsPuuEEMdkl+dD1YQQuTLkPhkhxM+y6yqFEM9kr6FOCPH93VlxWUYBz0spQ1LKIPAcMGVndhRCKEKIG4UQm4QQ3UKIp3MeCCHESCGEFEJcnvVgtAohruu3r10IcVd2XUv2t73f+tOFEEuz3otN2wj8tVlvSFgI8YYQoji7j0MI8US2LH1CiAVCiLLdUUkAUsrNUso/SClbpZSalPJBwAZMyG5yAfCSlPI9KWUE+AlwlhDCm11/MfBLKWWvlHIN8Ffgkt1VPhMTE5PPG1ORMTExMdk1LgBOwPAmjAduyS5XgIcxrN8jgDhwD4CU8mbgfeB7UkqPlPJ7WWHzLeC/QCUwFni733lOA54C/MCLuWMNhxBiAvA94AAppTdbxi3bbielzJXBAxwO9AIvCCEU4CVgGVAFHANcLYQ4YZjz3ZgV3of8bKeo9wKnZBW/QuBs4LXtXVs/vg+cAczCqLPe7PH6cxSGF+J44MZ+OU03AwcD04FpwIFk750Q4kDgMeB6jPo+koF1dz7wDaAUQ5H4YXb514ECoAYIAFdi3PdBZBXb4err5Z25eCHE9Oz5N2YXTcG4XwBIKTcBKWB8tm4r+6/P/t4ppdHExMRkb8BUZExMTEx2jXuklI1Syh7g18B5AFLKbinlM1LKmJQynF03azvHOQVok1LeKaVMSCnDUsqP+q3/QEr5qpRSAx7HEL63hwbYgclCCKuUcktWsB0SIUQJ8DxwlZRyCXAAUCKl/IWUMiWl3Ixhwf/aUPtLKW+XUvqH+2ynnIsxhPHu7EdjYDjU9rgCuFlK2SSlTGKETp0jhLD02+bnUsqolHIFhmJ5Xnb5BcAvpJQdUspO4OcYIVkA3wL+LqV8U0qpSymbpZRr+x3zYSnleillHHgaQxkCSGMoMGOzHpNFUsrQUAWXUp6ynfo6ZUcXns0jejx7fcHsYg8Q3GbTIODNrmOb9bl1JiYmJv8TmIqMiYmJya7R2O93PYbVGyGESwjxQDbxOgS8B/iFEOowx6kBhlU0gLZ+v2OAYxuBfQBSyo3A1RjCfYcQ4ikhROVQ2wohrMB/gH9IKZ/KLq4FKrfxqtyEkXuxO/k3sB5DoPZh1MHOztBWCzzXr3xrMBSh/mUc8v5kv+uHWber9yKnJDwOvA48lQ1X+122bncrQggnhrdsvpTyN/1WRTDqsD8+IJxdxzbrc+tMTExM/icwFRkTExOTXaOm3+8RQEv293UYuQsHSSl9GOFJACL7Lbc5TiNGeNpuQ0r5Dynl4RgCvwR+O8ymf8YQaG/pt6wRqNvGU+CVUp401AGEMaVzZLjPdoo5DXgg6zWJAPcDQ55jCBqBL29TRoeUsrnfNsPdnxaMehlq3Se6F1LKtJTy51LKycChGF62i4faVgjx2nbqa9jQumwez/NAM4ZHqj+r6OepE0KMxvDKrZdS9gKtDPTkTcvuY2JiYvI/ganImJiYmOwa3xVCVGeTzG8C/pVd7sXIj+jLrrt1m/3aMWbqyvEyUC6EuDqbiO4V20ytuysIISYIIY7OCr6JbFm0Iba7AiPk7Xwppd5v1cdASBgTBjiFEKoQYh8hxAFDnS87pbNnuM92iroAuDR7DidwOf3yOITxrp5Lhtn3fuDXQoja7LYlQojTt9nmJ1nv2BSMvJbc/fkncEt2n2Lgp2z1BP0N+IYQ4hhhTChQJYSYuJ1ryJX1KCHE1KzXLYQRajaozgGklF/eTn19eZjj5zxnceDibe4XwJPAqUKII4QQbuAXwLPZ0EYw8n5uyeYjTQQuAx7Z0XWZmJiY7C2YioyJiYnJrvEP4A1gc/bzq+zyuwAn0AXMx0ji78+fMPI5eoUQd2eFzeOAUzFClzZgJKp/UuzA7dnzt2Ekpt80xHbnYShULf08Ajdlc3FOxcj/qMse5yGMZPbdyTeBkUAThpdhNNmZtIQQNoyck/nD7PsnjIkP3hBChLPbbav8vYuRDP828Hsp5RvZ5b8CFgLLgRUYuTq/ApBSfoyh9PwRI4/kXQZ6b4ajHEPRCGGEub3LzofJ7Qw5L8/xGApy7n4dkS33KowJBp4EOjCU6e/02/9WjJC5+mzZ7pBSbtsuTUxMTPZahJTbRjuYmJiYmJh89gghDge+K6U8b4cbD953JIYCZpVSZnZ32UxMTExMvniYioyJiYmJyV6PqciYmJiY/P9j2BlwTExMTEy+WAghRgCrh1k9WUrZ8FmWx8TExMTE5PPE9MiYmJiYmJiYmJiYmOx1mMn+JiYmJiYmJiYmJiZ7HaYiY2JiYmJiYmJiYmKy1/G55cgUFxfLkSNHfl6nH4Su6yiKqdftScw63vOYdbznMev4s8Gs5z2PWcd7HrOO9zxmHe95Pu86XrRoUZeUsmSodZ+bIjNy5EgWLlz4eZ1+EOFwGK/X+3kX438as473PGYd73nMOv5sMOt5z2PW8Z7HrOM9j1nHe57Pu46FEPXDrTNVWBMTExMTExMTExOTvQ5TkTExMTExMTExMTEx2eswFRkTExMTExMTExMTk70OU5ExMTExMTExMTExMdnrMBUZExMTExMTExMTE5O9DlORMTExMTExMTExMTHZ6zAVGRMTExMTExMTExOTvQ5TkTExMTExMTExMTEx2eswFRkTExMTExMTExMTk70OU5ExMTExMTExMTExMdnrMBUZExMTExMTExMTE5O9DlORMRnEmkgcKeXnXQwTExMTExMTExOTYTEVGZMBzOkOcdSCdczti3zeRTExMTExMTExMTEZFsvnXYD/VepiSTpTaQ70ez7vouwSz7T3ArA0FOPwQu/nXBoTExMTExMTk72TjJ5BFSpCiE91HCklGZkhpaVIaSl0qefXKULBbXVjU22D99EzWBTLkOdP62nSWpqMzKDpGhk9Y3yk8e2yuChzl32qcn8WmIrMHkBKyeWrttCYSLH68H1QPmUD/qyIaTqvdQUBWBtNfM6lMTExMTH5vJBSEsvECCVDRNNRXFYXHpsHj9WDQBDPxImmo0TTUYQQqELFolhQhYqqqPn/pZRoUkOXev6T+z+pJYln4sTSMZJaEgCBQAjjo6DkBbCkliSWjuXPV+GuoNJdSbm7HATE0jEi6QiJTAIhBBZhQREKFsX4zgmTkVSEcCpMMBUECT67D5/Nh8fmIZlJEkqFiKQjxNIx0nqalJ4iraUBUIWKIoxAloSWIJlJktSSWBRLvm5sqo2eRA8dsQ7ao+0kU0lKvaUUOgoptBcOECpF9o+siJD7XwiBpmuEUiFCqRDBZBBd6qiKikVYBtTvtvUtEFvrNRPLl12I7Lmyv3PkhNm0bnxSWmrAd269RbHgsXrw2rx4bJ78sYbCqlixqTZsqg1FKCQyCeKZeP47nokT1+KktTRW1YpdsWO32BEIMnqGtJ4e8J3RM0hk/rgWxUJKSxHLxIhn4qQzabx2r9FGrR6sijXfJoG88J/UjPuV0lIk9WR+We5bIHBZXbitbtwWN4rSL2hJ9v85MPS+fyi+RJLIJPL3Lndcu2rHptpwWpx4bV58Nh9emxdd6qT0VL6MA35v8/+25x2q3r02L4pQ8vWsSx2BwGFx4LQ4sQhLfl1GZrZ7vJNHn8ztR9y+3W2+CJiKzB5gdk+YFZE4AOuiCSZ5nJ9ziXaOt7pDRDWdIqvKmmj88y6OyV6MlJJ4xmhDuYFne9uFUiEsigWH6sBusWMRlkFCT0Zm0HUdRVHwWD15gQJA0zV6k72EU2E8Vg8+uw+7agcgraUJp8N5ASb3W5MaHqsHt9WNx+rBYzN+uywuhBCEkiF6kj30JfpQhILT4sRldZGKpejQOoxjpcKGxU0xBBwFBUVR8gJP/28hRH7wTWQSpPQUMFB46S8c5K5bkxqarg2oC4fFgcviwmlxIoQgmUmS0BIkMon8YB3PxFGEQrGzmGJnMQFHwNhWSxrn11KGMNZvcO8vvChCyQuDwFahpp/gkxM2+gtCLquLIkcRfrsfr82LVbFiUSx54SOajhJJR4in4yiKcY7c+rxgJlSCsSBpkSaajhLLxIikIkQzUeLpOA6LA7/dj9/ux2PzDBCWB333q7v+AkY0HcVpceKz+SiwF+CwOPLbZ2Qm/1uTWv4e5I5pV+14bB58Nh8O1UE4HSaUNI6b1tNYhAWrakURiiE0J4P5dbk257a6kcgBdYc0BKGcwCJl9r+sZTW3nUBgVa3581gUC1bFilWxIpHE0rG8kJcTZHLtKyc4b9vuBgjX2TY1nKCjCGWARdhkaLw2LyoqwVRwh0Lo9sj1Ibn2tyvk+94h2hYY/XN/BSHXjnLLrYoVq2olradpCDcQSUeIpqKDrifXd0mMtprUkvlt+gvS/T9WxWooOFmlMKes5MqR6xMcFgdg9EGRVIS0nsam2nBZXBQ7itE1nTRGX9Ed7yajZ/LPfO4a7ao9/3FZXXnFIrfMptqQUuaV82gmOihXeIDyto0e13+dQ3XkFWS31Y0mtXwfG01HCafChFIhOmIdCJFVchSb4VVRjDJZVWu+fDbFZvzfb11OSQNjrMgp8q1JnaQuqbRpOC1OHBYHKS2VVyQzMpOvf4fqwKba8kpw/z7Yolio8lTtUlv7vDAVmT3A3fXt+C0qfRmNj4PRvUaReaGjl1KbhbPKCvl7UxdpXWJVPn9vki51ehI9tMfa6Yh2kNJT+cFWEUr+4c5ZgHK/rYqVWCZmDOpZi9+Qgo7UBgtC+sD1/S03CS2R/z+jZ3BYHHkB2KpakVIOsD7q6HlBpL+FJWcttCgWFJS8IJrr1OOa0fGk9TQO1ZEXfoQQxnbZbfPWLi1BWksPEEycFmdeULcq1nz5E5kEEjnAmpf7bREW45qzlsj+ZU7raXSpDxjg+g98EkkwEaQv2ZcX1IH8fep/j1Jair5knyHA7SICkbdqJbQEPYmeQQN8TpHJWXp3BVNQGxqBGCjg9GsDubYcS8fySuX2cKiOrQrqMHVtERbcNsM6mvv22DzEM3HW966nL9lHJB0ZUnHsr0Dm/ndYHBTYC6jyVOG2uoln4gSTQZoiTSQyifwAntt3wPOhqNiEMegntAQtkRbWp9YTz8Tx2DwU2Arw2X1YFWveiqxJjUpPJZOKJuG3+7Eolrwilyt3rh5zlvptreYCo5/rvx0wUJHsp0wCuK3uvLAihBhkMc4pSMlUEpvVNmBZ7rfD4sBn2yqMxTPxvCFA07W8B8JpMca3/speTpDM6Jl8P5379L83OQu1y+rCoToGlE+X+oBy5ZR3l9WFruu0RltpibbQGmlFCJFXEJ0W51YDQM4Iki2PLnW8Nm++7wDyim04Fc5byz1WDy6rK99n5eo8dwww+heHxRAEM3qGaCpKOB0mqSUpchRR4izBZXURDodxuV0EU0a/qOnaIGWi/3Xm/leFmi+n2+rOGxT6Gzdydb3t/7m6clgcAww+nyW5MU+TGnbV/qlDq7ZHOBzG6zVD4QGOX7iOTbEkb+wznjEux+ddnM8EU5HZzczvi/BRMMqvxlXx5/p2Pg5G+XpV8edaJk3X8lbX/p98fKSeoSsZ5/UuD4e7Q4RCW0jJav6y+gVq7IY1L+9u1lNEUsYgHElF8ha/nLDe/3dOQch1/slMEg0tb/ntP7BpUstbQuKZeD40QFXU/GD9edPfPZz7tiiWfGhELBPLD3I54aO/EKUIxbCmZIX+3ACbc5s7VAcOiwO7asdpceKxegg4AlgVKwktQTQdpSPWgS71vKXF7/DjVI3fDosDPaNjtVoB8hboXL0mtSR+hz/v9VBQBliec78zemaQ4pErs1013P/bWuf7h1/sE9gHv91Pgb0ARSh5pS+tpwe48W2qjQJ7Qd5yn9Ezec+CJrVhBVNNZkMushZwp8VJwBmg2FmM1+YlmormhROByAtcOQHFY/Pk3e85K1YulCSSihBNR8nIDIX2wnw4CGAoxZkYwWiQEm9J/rg55XUoD0D/75wlP3fvbIoRz9xfeOxPXpjOenty3pGctby/xd1usQ9oP7l7rEud7ng3nfFOuuJdgKFA5ISw3LYDDABZS79E5tsFgE2xoSoqO0vOepqPu9YzWFVrXunvf6z+bTAndKbjaQIFgT0qAP1/Z28WAGt8NZ93EQZQ5Cgadp2qqBQ5ira7zc6SG0usivVTH2tPIoThNbTyxS7n/xIbogmWh41IiMtXbeHl/cbjVP/35/QyFZlPQX3csPTWOu35ZX+qb6fYauGCigAf9UWZ3xdBlzqxdIzWaCuN4Uaawk10J7rzwu62H2CAcNw/TCCeiQ9wm24rOG0bjpLQEmT07cdBAiTch5MJXMHSjX9kmUxBxW3cs+YVHLH5g7ZVhJIXDJ0WZ77c/a8nF9+cV1YUFbfFjcvmyisAOeFNkxqqUA0Bx2qEy+QS2zJ6BqtipcxVRpm7jDJXGXbVPsBq1z+GtL+gnNbTeY9ELhFuOMvtIGuhMnC9Q3UMSphL6jovdPRxaokfp6rky5O7/s+DvVkw2VvY2+q40lNJpadyl/cTCBRV+cSCiFWxUugo3KltFaEMOlc4FTaVGBMTE5Od5LmOXgRw54Qarl3XyK0bm/ndhC+Wwr8n2ClFRghxIvAnQAUeklLevs36AuAJYET2mL+XUj68m8v6mRB67TU6/3Q3NX99EFvN8A1gQTDKecs2kdR1zikMc6CyjNXhEHOSJzFLe4W/vXUJCTGLZutFfOP5I0mkekhI0CVkpDBiQIWOFYlV6Cj94k11ICMtSNWOUFxYVBdW1Y3d6sbtKERVrKjC0k/QFtiFjk1k0IULFEc+bMmu2vPW2nyMqMWe9wzkwkF+1eSgOSV45ZS/YFGd7PdxPV/b9wa+U2XEcfcPJ8mFK+wqe5sAuCMeb+nmlg3NvN4V5MEpI1H7JReamJiY7GmSm+to+eEPKfvxjbgOOODzLo7J/wP0RILInDl4jjoKxfH/I3Rpb0BKyXPtvRxe6OH8ygCb40nuaejgUL+HM8p2zqC0t7JDRUYIoQL3AscBTcACIcSLUsrV/Tb7LrBaSnmqEKIEWCeEeFJKmRrikF84+od0ROfNJ7VlC42XXkbtU//EUmg0gJbQFpbU/5Pu3nlsTPl4VPkuPvqYxBb+2XMI82QFTvy4iHKh8hRC0RBiA28CYwvGcCitu1iqFBADeodYp6AqThTFDkjS6SCG+mNgsfhwOKqwWgrIaGHS0SDpRC9CUbFYPSiqC1V1oqouVNVBX8zB4sSlnG1fSPO619H1JFXialZ1NxO3bcKiekjpCTQtjqYn0LQYupZA0+OAxGotxGYNYLUVIVDQZQo9mx9ht5XhcFRgt1cQj4dJpcMkk22kUz2oqguLxYfF4sVqLcj+9mGxeNC0GOl0kHSmj0w6SDrdRzrdR28qgsfmw+eswukcgc1WjKYl0LQImhZFCAtWqx+LxY/F4sne3wxS6iiKFfEpFY1cWxFC8Fx7Lx5V4ZXOILdubOaXY6t2uwV5WTjGHXVt/G58NZUO2453+IxZGooxwe34f+G+NjH5otF1330kVq+m6dprGf3cc1iKP98w5s+C+LJlZLp78Bz1JdNj9xkTW7yY1h/fRKq+Hv+551Lxi59/LuXoSKYpslqwKIL40qWE3nsPz5VXImyf/RgZX7mK3qf+Sel11+Xlxc+DZeE4dfEUV40wpku+YVQFHwejXLeukRk+FzVSI/jii+iRCEXf+tb/1LOzMx6ZA4GNUsrNAEKIp4DTgf6KjAS8wqgZD9AD7Die6QtAZyrNt1Zu4fJSL6d4vaQ2b8ZSXk66tZWN3/0m8670ocWXUKVGcSjQLafwiPI9Cunj5uY/UhbPsGhsjL+qR7JFt/KdSisnjV2AqjrI6JI/fLCCPvc1jJztxnXEgdjGjeKDkODFXhu312pkVm6g81e/Q7E5KPne9/AceSRSamhajEwmQkaLoGsxND3JprjkJ+21/Cywgiq1N6tICKxWP1aLH4vFSzrdQzzRQiLRTCYTRI1akWuiKK1xUATWcQGs42uQNp10uJt4+1reVA9GL1A4qO4/aNYwFn8JIxwtrE1WUVf3p3xdCaGiKE5U1ZH/BkinF5NK9dBfmdoTdFPEjfwREExjCTN5nGkswUVsp/YXQsVuL8dhr8RmL0XXE6RTPaTTfWjpGKriwqJ6UFUP0iLJZAwFKpMJI2UaKTWkzACCTlHFIv7EBcp/CCqFPNR0DJm2hznbuQSHowqnoxq7vYyMFiWV7CSZ6kTToijCilBsKIoVRdgQihUlmythKGy9pDNBrNZChHtfvtl2GM1pCzevXcPva0KkM31IPYOiOlAVB4piM5TLTBRNixKLBenptSD1DBINi8WH3VaCGrOQXteI48B90WQcLRNFlymQEuPxFVgsnrxiqSj2rNKXDZMTCoLcXPgKQii0JHVOWtTAaSUe7plYnq3lbfI8FCfKNjOWaVqCRKKZVLoHLWMooJqewKJmFVqrH6ulAKvVj6I4PlWHK6VE11PouvEMKcKSvTYbimLbY525nkgQfPFFhKpScNZZX+hBQ0qJlGmEsCA+p8TgHSE1DaHuXm+nlPIzuy9S12m9+RYSK1dQ/vNf4Npvxqc+Zqq+ntArr+A97lgi739A8w+vZ8TfHtot9ZRYvx6tpxf7hPHbFc6klKS2bMFWVbVHhUgpJdH336f7rw8RW7AAAPdhh1Fx221Yy0r32HkHlCGVIrZkKdEP3ifd2ob/7LNwHXzwF/rZ7o8WDtN4xZW4DjyAku98Z5fulx6P03nXn+h57DGslZV4v3wifU8/jedLX8J79FGfuEyf5LnuTKU5cP5qxroc/CrRg/+q7yATCbRly6n6059QPe5PXJ4csQULaPvNbwhccgkFp5027Hbp5mYar7gCrbubxIqVjHjk4V1SZmQqBVbrdttQqr6e3n/8g8T69RRfcQXugw8ecrvn2nuxCcGx8SDBlz5E9RfyR38hR2g6f3/mZc6/+3fooRAAittN4Xnn7XQ5v+iIbRNMB20gxDnAiVLKS7P/XwQcJKX8Xr9tvMCLwETAC3xVSvnKEMe6HLgcoKamZuaqVat213V8YhK6zjlrmulIZXh5Sg2ZU08hdcwE1u2zgSJ3C9IFYd2J7phM2ns6N/RMpjwc5M7bbqYoEgJVhWSS6MTJvPuV8zl36ngKRtYaM8XoOl+fu4yO3iAP/fJHCLudwj/+gXOcZWxIpLnLBdO/cymWygqEw0FqxUpcp56K/4fXobhcA8qpS8n561pYFEnw3YpCrq4qGuAd6I+UktTKlYQf+huJDz9ELSvDd9mlpDduIvLMM6Ao2Pfdl+TChawbP4lfXnkddlXlyVf+Serjj9F7e3niy2fyt9PO5d36RQSOPBhroCIr6Az9wEmpk9FCICUCC/GX/kt89myYVI6YXI6s9ZJ2OPF6R2CzlmK1FqLrScPr0rYZzZpGugSaFiajRVAVJxZLASKkIxu7ce4/i2ubFOaG05xYaOPdYIJeTeDREvx5zYNUNtQhW3qwjKjGftYJ4LeQ0SKIrNCNUNG0KKlUO6lUK6lUh+GR0l1oK7Ygu4NIh0R3gnSA6vThGD0Vi6MIVfUghOHNEcIQyh8P1fL36ESeLHqZAH38OnIY76dG8SPHixyozyGVbEFmdXlV9WK1lqCqbqTMoMfDaJFecNnBKgyFArBYCrCoPlRLAalUJ79PnMpHHML+fMTH4lBukrcyhZW7tf1/Gl7nyzwmLgXgGvlb9ufjIbYSqKoPq7UQRXGSSrWTyfSgoSCQA0Iqh0IIGxZLAYriyCpFdhRhRaJDdlYjpNbvW0PPeg91PYGuJ9iegi2ENavYWAGZ9d7l7psHRXFl739u5icNTcugKEabl1JDVV1YrcVYrcWoGTvJjStJtm1Es6WQFrAUlWEbMRqh2ND1JJoWRdejaFoc0JFSBySK4sCielEtPhTFga7H855GXU9mr1fPKtQaoOX3zdW1EEpWSbNn68tQeIViR1HsRt1kQmS0EJoWydZREpAIYcFiKcJqDWC1FmXbvAUhLEg9RTrdRTrTQzrdm33PR269NevtND6Gsm7PKoqWbJ0aZTam/lWJ4OKV9Ewu8DThdlRgt1UiFAvpdDfpdDeZdA+pdAKLgMTHH6O1tmNxFaD6S7AEyrGPmYTqNtoFQCYTJJPpI5PpQ2br0mgrNqRMo8sUUk8jFDs2tRhtwXpSL8/FcfhhuE45ESxGLSrZ6xHCkm1HUdLhDtKdTVjKKxDZiTQQgtwExpKsshztI9PbCR47uCyGV1pqOJ1j4YVVpP/+Jqq3AC0UwvX1c3BccDKamkBL9JJo3ICeDGMbPR7F4szWp61f24R0upNUqo3meAiFJO4F88ms30LB176O2Bwked+z+E+6hIJvXUoi0UAisYVEogFd9psoRWpoehxdi2WfDT++gkm4nONxOkdCLEPwL/cR/c9/kOhoAdDG+2B8EdaqWmwjJ2KvGYtIQ2L+fOIfvI/W0Y5aUYHnvK9hHVlLbvoKY75f3WjzetQ4p0yjqm6jn1O9WCxbvxXFSSbTl28DmhZG15OkmuuIvfM2cksnVgrxHnEaqmKj74VH0UpVrKcdgTqqIv/sDvjo2/yPxKK7sSSdKFEVS1EpssBCJhNE08IIYTPGBcWFUGxIPU26tZHkmuVo9c0QzaCkFYTFjp6Jo1SVYt1/Kqrdh6jrRV/VBPW9uM44GftRhzEnAomUzqllfiyWQlTVQzLZRCy+gXh8I5oWwW6rwm6vxm6vRKZSJLesJVm/Dj0SxDFuOs5J+2N1BADQ9Xi//s34aHo8++z6sVgKUBUP6XQXyVQzqWQLmhbHai0k9dbHpF6fh0iDdUQtvsuuwFJRgZYMEV/6EYnlC7GVj8Z/2jdwOKtRFDtS6iSbN9D5qx+TaWvAecwJ+C68CGGx0nXzj8jEevDfeiPC60ZVjY8i7WCx5WfOzGhhYrH1xGLriMc34nSMpqT0HDJPv0vwgQfxnHMO3m99nZioJ5VqHXCvbNZS7I4a7LYKdD1OKPQRr3Q08YvILJwyQRIrZ7W8wcU0oMyZg6W0DO/5F6A7IZPuIZ3pIZMJ5scIKTVUxZnt4wJYrEX5fkIoNhThJPX6B8T++jRKQqB5NFw3XIKcXEwm05cdn71Y1AKUtJXQT3+H3tiN/xtX0PvgPaijKij4+Y+xFhRjtZaiqltnrDWManF0mUJrbiXyyOPE33wb+4yZ+K/9IbZRo/s9phrJjz4m/J+niK2Yh1YgoNQDXUGcBx+J78JLsBSUZvt5Bzowa0UzEzNd/OjVq9FFChEXKHG4/thfomdUHpn/Dt6vfpXww4+QWLCA0r//DdvEiYa8mGolHt9EMtmcHxM0PYlwTKCm5AQAotEobvenVxI/KT6fb5GUcv+h1u2MIvMV4IRtFJkDpZRX9dvmHOAw4FpgDPAmME1KGRruuPvvv79cuHDhrl7LHmF9NMEJC9exn8vOdc+cTvz4DJqEdFeA6keD2JrskNG44/xvMXvmofzjthsZc9KJFH3jEhS3m9B//0vw+ReIL1oEgLV2BN4vfYnEuvXcX1jBI6d+haUBlegttzDbF+CWS3+ATcD4hi3c99c/MPLpf2EpLqbz3nvpfuBB1OIAqq8AmUyiJxNYikt49eQz+dWYqXgEjNBSPPHW80Q/+AA9mcRzxBG4jz6KZ8dM5vC1K7E+/iiJVatQfD6Kr7iCwgsvQLEbExKkmprpuuceuhYu4onLruKJ0hpKbVb+MrmWQws9SF0nsWo1L3+0mKvG7Muf7/gpU9uaKfnudym6+KKtAzkwry/CW90hfjJmayJxYu1aWm+9lcSy5dhqa0m3tyMTxss1Fb8f24gR2KqrUQMBUps2El+1Gj0YxFJSwqgXnsdStHVWFz2VYss5XyG5fj3zzjyXm44/k5+OqeTb5X46/v4w77z+Njdd+gPGdbZx/9zXsZeXE3rjDWQsRuDKKwhcdplhRfvoI6IfzkNYLBScfRaO8eMBiC9dStNV30eLRin53vdQ/X6QOumWVroeeABbTQ3Vf7kX+6hRA9qLlJIjP15LwGrh+f3GGdet6ZyxZCMdqTTzJ1bQcP75JEPNiFAaS2EJJd/5DvYJE+l64H6i775nHEhVqbzt1xScfvqgNvmP1m6uXdvINZVwrreeczZX49Az3H//j6GxBWmVSLuK4nfjm3UcRWefj9VXTDyWwev1I4SFp9qCHGqNk7z1KhLddTiPPpjYWx9gD1RR/sObsVeOIOdxMRTRCJlMmEwmvFVwljo5YVuio0UjpOq3kOnq4BrPSXQpLmypOD2OQv7y+jV4MzEUuwPPUV/CMXUfNC1GKt1DOt2DpkUNj5ijih92zGBTysEN1YJTAi4sFieZTLRfKGHvgNBCTYuhZTtYXU8ZAjsqCNHvt4IQKqriRFWdKKrxrSqurBfRjpRa1kOT3PotjW/D46Tmww+N+jAUCaQOQkUIBS2jY7Has+dVyGhRkvE2EsEGMkRR4mDBjd1fg94bIt3RilJSgFpZhmpxYVHdqBY3quJECBU9liDd2AheGxS7jPrXYqgWt+EhVFyQFghdgg4CBbWgCKFky9vv/Q1I3RgotXg2/DOBng0J1fUEiuLEavUZSrPFa3j1snWja3GSqS5SqU7SqZ5svWSQMo2i2LDZirHZSrBZjWdUl2mknh7wnatTLRokE+5BTydRvQWongJE1jMntRQPRI7iZXEkN+q3M1UsGNT+VdWDwIIeiUA6g3Da0MkgVR2GcRoJYcWqFiAUFU1PZgW9VD+lwJb1RO76dNzbI4UVG/2UhTQoih2Lw4tEJ53uMcqnqdhd5SRjbUhV+8Tnu0n8ARWdXyZ/CEMZ1aUAMdy4rmRDil2oioNEsh3Zvz40EClQVSeaLZ03xnzh0UDInNfYgmJzoljsWaXaAmkdvSeEFgyiuTV0H0bGbxZFsWGx+ND1NJoWzRsz+h+fXXR06ShcxYNoKNzLpajbGFQEKgp2tJ2MKPik5IwJu4rF4iOTibC7Ii2EsPGR7UwqUguokZuxrRF42sqIeztITpboru3IolttNfxTfoP/ihO5b8O3+cfI85ljO4py2cIl/JWpLB+wjxJTUSISIRWy05eg2ySaK410fPL3+uwsqurBZi0io0XJZEJIuaPZVxWELiCjgy6RO5mCtIp9uE38nKvknRzMhxidpHHfnuMcnuGrPKBcRZWvFrtSSmjuW0gnWCaPIJ5sMto8UMcY1jKZdUxinZjELGcHDx18DvD55zgLIT6VInMI8DMp5QnZ/38MIKX8Tb9tXgFul1K+n/1/NnCjlHIoEy3wxVJkAP62qZ6bG3o5Vz7JtLZXOfGkf1Pln0zf88+TXL+BuMPB0ZMP5YRkiD8fOn1I92G6uZnwu+8SeecdYvM/Qlit1N1yK5f4a3hi39HMIs0Jb8yj12LjKysXcveXTuIZv8phM6bmjxH96GN6n3gCFAXFYUfY7LR0d3PuKRcwvqGO/Vcv569nnsd/bruRkftMQnE4ibz7LkuKSvjBdT/jtPfe5IYF71J0wQX4Tj1tSDfrpliC85ZtpiGR4uLKALeMqcRnGdhLNyZSHDBvNb8usHL8X+8lMmcOtrFjKLvhRqSWIfrhh1w0Ygorqmp56r7fMspuRfF6ibz7LmpBAWU33oDv1FMhkyGxdi3xJUuIrFkL7W2kGpvIdHVhHz0ax5Qp2EaOpPOuu3AfdhjVf7k37/Vpv+MOev72dyyXXsbp42cS6O3hH3XLSS1cQGrjJrzHH8+c71zN9a1Bfju+mq9XFZPp6qL9N7cTeuUV1OJitN5e0DSE0wmZDDKdxjl9Oq4D9qfnkUexlJdTfc89OCaMH3D9sQULaPr+D5CZDGU33wQSUvVbSDc0sNbp4YJjz+KmtYv5WqwX/znnYKut5d9tPVy1poG/vvQk4956gxGPGPNddNz5B1a0d7GloooT1q+i6BvfoODMM2m58QZi8+ZTdtOPKbr4YmQ6TeT9D1j27vtceMTJ7Oe08u9Dp6IKwTMvvc53PWVc9d/n+PaUMchUCi0SIbVpM+E330QNBCi56irUE47HV1hIfTzJQfPXcMHqJVx67++pvufPeI8+muiHH9J8zbVIoOS738Vz5BFYa2t3GB6R3LyZnkceJfjCC8hkkpDLzVl3PMBFq5dwkg3OHz+T04o8/MEpafvZz4kvXozrgANwTp9Oaksdybo6Mq1tCIuFaIGfU274NVZdkrBYONTv4dfjqpjkcZLp7qbrL/eR3LQJ57774pw+HeeMoZ83LRQi8s476IkElkAAtbAItdCP4nKhOBwIpxPRz20f13Rs0QjB51+g96mn0Lq7cR1yCJ7DD8N18CHIZIJUfQOphnq0vj5UXwGq349a6MdWU4Nt5EhSisKHbV0cVWmEs8hMhr7//IfOP9+D1t2N75RTKP72ldjHjEGTEqSk7+FH6LjjDlwHH0zRRRcaZQ0ESDc10fPEk0TmzAHdGHRsY8dQfMUVeI89lui8+YRee43I22+jxwYKO9aqKgpOP52CM07HNmLEdu8dgEynic7/iMTKFSTWriO5bh1aMIj32GMpOPNMnDOmg6YRnf8RoZdeNBR/ux3F50X1ePHMOpKib35zsPc3nSa+YgWpLfWk6utJ1dURW7gQrScrvNvtyGQS1e/He9yxaOEIDUuW8rWbfkvKZuPyZ5/kq3NfQiu3Yp84noL9j6Zw1imoTi9bvvFN0ps2UfW73+I76SQAdF0nsX4tnffdTXjuO6gVAbwnHI+2sZXEwpXoXd3YJ0yg5oH7sZaXby2nptH1wAN03ncfSqmXwh9dimX/CSRWrqL3rw+jdQfxHHkEanERwudECp3Iq2+jN3bgnnog/hNPI754KZG5H5BpbzdehqcIXj3uTP4y60zuWTuXg/0F2KprCT37POE338Q+aRLe446l/fG7Uc7cF/X0KaQzvdhtpdASJ/7KXKzCi7N2Eu6J0xCaSt9zzxBbvQw8dtQiH5lYCF1LgKoQOOGrqOd+m5mLjXzLu+/6FWfcdzdKqY94vJFocAMtf/8Nmd5uLB1g6bbioAzPtAPwHH0M7sMOGzQehEJ9KHTQ/NhvCG6Yi1IZwHXkQYhCNxaLF7drLG73aByOGtI9nUSXzSeyahGoEs+XjsI+0jDy6PEkff96mvDrrxvhqrmIVQkiLVASIJIgMqA7jY90SaTPiu+CM7DtNxFNi2Kx+rFZi9FWNdL7l0fR6lspPO1sSr53NZotRTLZSjLZjq4nsNsrsFtKiL80l9TytaQaGkg1NKB1d+efJe/Rx5DcuJHI7NkImw3fySfjmDQJtbwE6bfQcc9dpFfWU3PbHfhOPBGA6KJFtP/mV8Q3rsFWWkXRxZdQeNbZCKdjqzdEplEVO0LaiM39CF0mUfepJmONkkp1E/twIe+8t4Yfn3YjALe/+iv26VuO9KkonRJrk8TSLhCaQHdKGF+EmFiMtWYEzlETcY3dB9XlJbziI6IrPyJatwI9HEGkQKSEUZcpUJLwwowTEeicGVuH4+B9sO47Flf1ZJyOGhyOSoSws+WKi4i3rKPs/t+huO2ke7voeexREmvX4p6yHwVHn4hr2gH0vfUinS/+HX2EC+uMsSTnL8civJScdxn28pq8Z1WioypOYnM+JPjoUzgmTSZWtxZcAvsB+5Jsqkfr7sYSCOA55EiKDziDdv9UZi3cyAnJXr773yuIH2sl40pgVfw41tmwvNODpUUgDGez0X+M9iPH+NCqbAhdYvkozPcP/y4Af5vzEjUP3M/7yRQ/WttIQ0pyojXJN+79GcV1TdhLRuAYORprZSUynUaPJ2iRgrjVSm06iepQ0Cxx4nUbSDZsRpJBelS855+K7ZCpZDJBLJqb0B//AcvbqLrpNqRLIdnbRGTFR4QXf4DvojOwHTAFLRNDVZ1kNrfS97fH0UUaWeaAag+63wK9cWRbCBGRKLqKY+YM3AcfgHA50aJhInPfJ7F+jaF/KALLiCrs48bgHDUFu7MMmy2AxeJD6ikSjZvp+fc/SLbWoxR5cRyyH3cWHs/sTDXPPP1zJv3yPhzlI9H1BJlMiIW93Zy9JsUthQs5KPMqyWQ7StqKtqEZq7sYl2cU6bdW85dRF/DK9OMAqA71cXBZgJPG1HBSiR/Y+xUZC7AeOAZoBhYA50spV/Xb5j6gXUr5MyFEGbAYwyPTNdxxv0iKTDodZPGSy7g9ciQfyUM4I/gSfznrZwO2+WdrN9esbeTFGWM50O/Z4TFzgkfC7mD8+8v5Tk0pRxZ5OWfpJq6f/TJHvfQMX/vD3ziytJCH9hm13WNdtnILb3QFedWjE62r47Ti0fxuXBUXV5cAxiD9g/nLeTol8CBZdsS+uC3Dm4/OW7aJxaEYD+8zikMLh74WKSXj31/B2eVF3D6+mvDsObTfdhvppiYAGkaM5Os/NnTZH65cwDnz3yXT0YH7sEMpveYa1IICohltQDm29yD0PPY47bfdRtktt1B04QVEP/6Yhq9fgv/cc/nD+d/iyZZuHl/8DpUPPYi1ooKyn/4E75e+hJSSr2av590DJ1KVTYiPvPcevU/9C/v4cbgPPRTX9Olo0SjB51+g7+mnSdXV4T70UKr+cKfhiRmCVFMzTd/7Hsm1a40Fqoq1spL7jjuNp/Y7hOfvuAVPSzPoOgVnnoHtsiuYsaGD0+f8l9sOm5EXvqSUfPmdxayUCiv2G0Oh33gRm55K0XLdDwm/+Saeo48mvnw5WlcX37vxVzQFSnjoVzdSM3IE1qoqgq++yk23/IZVNaP48JDJlNi2esbiy5fT/tvfEV+0CKWwEFtNDa8fcBg/2/9I9l2/hqeLbfjPPnvrdTU20nzNtSRWGmFq1qoqXAcfhK26GktpKZbSMqSWId3SQqalhcSatUTnzkXYbBScfjr+c87mJX8p39/czmszxzPD5+KOulbu3NLOo1NHcXyRl77//IeOO/+AHo0aSsBoY0BByzDbG+Da6Ydx572/pamknL+fdT4Ri5UnGldT+ac/oCeT2MePI7lhI6QNC5Zt5EicM2bgnDEdxeki9N//En3vPWR6+xYuxeXCWl3NkpkH8f3DT+TuP9/G5LWrcE6bhm3UKKIffkisp5fbv34lB65axgnz3zP8G0Jk84e2IqxW/n7RZTx2wBH8+dWn2W/FEjIdHeixGM79Z1J2ww04p241SlyztoGP+qL8Z/oY3G/8l5abb8lfTw61sBD/uedSeO5XiC1dSvf9D5DcsAEUBXQdpaAA73HH4txnH4TDgeJwoEdjhF59leiHH4KUuA8/nLIbfoR93LgBx5ZSkli2jOCLLxF67TVDqQesI0bgmDABYbMRnj0bGY9jq61Fi0XROrtQvF48s2YhVAUtFCbd3kZy9RpKrr4ax6WX8v01DRTbLMy0Cqpv+yWOBR+zoWYkG2pHUz9uAl+J9nLQlAm4DzkUtdBP9IMPCL3yKuE5c1CcTh68/Af8c8RYvKrKkXaFOzrqSKxcRWTuB6Q2bjLum9eLnkpRc/ef8MyaNeS9jS1cSPsdd5BYthxr7Qhc06dz3wFHUv7aKxy/cTU1D9yPY+JE0m1ttPzwemILF+I7+WTKbrl5gGKsBYO0//Z3hN96Kx9DDmAfP57SG36E57DDBtRpcv0GEFBXUs6Xl9eR0CWjnXbeOmACruykF6E33qD9l78i09mJ66CDqPnrgyg7mZOQWL2a3n89jR6LYSkqQg0ESK5dS+jVV/ngnPP4yTGnoWoZjupu44mvnjJgXy0UIjp/Ppn2DjId7aQam4jNm4cWDCKsVtyHH07gssuwTp/O1Wsb+JJFctDvbyP63vsELv0WJVdfjbB88rcyxJcvJ/L++6heH2qh3zAEFGQNAn4/ituNzGSQySRaXx+tP72V2Pz5FJx9FuU/+QnxJUvovPvPxJcswVZbS8Wvfgn7zeTh5i7OqyiiyLrjsqVbWwm/9Tbht94itmABakEBheefT+H552EJBAbWVzhM45XfJr5kCaXXX09i9WpCL72EpayM0muvwXfyyZ+4Pn6wcA0v9YTRgDO627htVBmumfuBEGS6e8h0dICWwTZ6NKrPt91jSSnRw2HSra2kW1vRursRNjvtLjfHKH5cmsYrf/8j6cWLAfCddBKlN96AtbSU0Guv0XzNtZT/7FYKv/a1gcfNZBAWC82JFP/tCnJAgZtxmzfQ9P0fkGlvxzljBtX33jMgUmLA/rpO4xVXEvv4Y/xfPZfAt76FtawMqWmE33yL7r/+lUQ2heD3P/gxr0zcl8qONp5/61kq77mLlNaJ01kDCKLvvUe6pQVrdTXWqmqsVZX5SJIcSV1n3HvLudgq+cX+k/Pru4JBHuuNc3d9OwqCr5b5ObbEz6F+Dw5F8EFvhIeaO3mjK4QE7IpgnMvBDJ+Lm0dX4NM1EqtXYyksxDZy5IBzZnp6qL/oYlKbNg1YXvStb1J2/fWD6iSxbj3RuXNJ1dWxtjfItUefxt0fvM6E6gockyfhmjkTS0nJoP3iS5eSWLMGzzHHYC3dft6XlJLo3A/pfvBB+hYv5uzf3sfhWzby0NdOHdTGdSnZZ+5Kji7ycc/k2vzy7oceouP3dwLwz8uu4sH9DuXSygAXLZuP+MMf0EIhApdeSum11wB7uSKTPcBJwF0YztW/Syl/LYS4EkBKeb8QohJ4BKjAsFXdLqV8YnvH/KIoMslkB0uWXkwsVodz05F8x3cOibJCPjps5gAvxemLN9CdzvD+gRN3ObnvpEXrsQmBTRGsjSaYN7UWtbmJ39sK+EtDB/MOnpR/F01S15nfFyUjJaqAjbEkt2xo5sejKvjByDKklBw4fw2T3A4e29eIqYxrOlPnrqTSbmN9LMGfJ43gK+VDdzwf9IY5Z+kmfjqmku+M2P7DcuqiDaiCfPiUnkgQevU1rOVl3BGo5qHWHkptVsa7HDw1fcyAfZ9u6+G6tY08PHUUxwaMTnp7D4KUkqYrv0103jxGPPx3Wq7/EVgtND78OOeta+HKmhJ+NraKVFMTlkAAxbk19rQ+nuRLH6/jEL+bJ/cdvcP7I6Uk3dyCtaJ8h4mGejxOfNlyLGWl2KqqkFYrB8xbzSSPkyf2HU2ms5Ouv/6Vvn8+hcxkuPnK69g8aR8WH3cgSrYcqyNxjl6wDoAHp4zktFL/1rJkMrT9/Of0Pfc8ni/NQjvzLA5Wirixws9F89+h7+l/k9q8mcBllxK87EqOXryRc8sLuXPiQCu8lJLwW2/R++abiO4efjHtEF6eOhOnrrHx6P1Qh6iTVEMD0blziXwwl/iiRWh9fYMrwGrFVlmJ75RTBggC31pZx+JQjEWHTEYRgpSuc+LC9XSnMyw4ZDI2RTESGYUYEI4I8OP1TTzV2sOK0UUE77qLxnfe42u/vpvj57/PT9rrKL3+euyjR6EnEiRWrSK+ZAmxJUuJL1mSt/RbSkvxffnL+E4+CUtJCZnuHrTeHrS+PvR4HJlIoMfiZLq7iTc3c97Rp7MlUMo3tqzlpwdOxTllSr7e3ly+lot7jPCaM2xw+4QaCgJF6JEIWl8fWk8PqS1baN+8hROnHELMamNqewsPf/wWlkAx7oMPwnP00QPaXTCdYercVaSkIeQ+N2MsgViEdHMLWk83me4eFIcdz9FHDxispa4TmTOH2Mcf4z70UNyHHDJsUm66rY3g8y/Q/fDDxkw0F15A8Xe/i9bTQ/Cllwm+9BLphgaE3Y7n6KMoOPVU3AcdhNIvzlmLRAm//jqhV15GcbvxnXoqnlmzBpWp5cYbCb34Eh/e/gduLqjApQhi+uCxQxUw2mnn7QMmYFMGxoDJTIaujM6BH63hlFI/4YzGpliS9w+alN8mubmO8Ftv0bBhI9WnnEzprCOHvPb8MaVExmIobnf+ObMC9z3we8ZtWEvgskvpefgR9HSailt/iu+007bbP8hMBi0cRg+HsVZVIVSVf7R283Z3iFvHVDKiXz/95YXraU9l+PW4Kq5cXc8VNSX8fGzV1roNhQi9+hq+U05G9Wzf+BXOaHSlMoxy2YfdJvjSS1y/YjNvTz+Akz58h2ePOYmPDplM9Q5mM5SZDLHFi4m8PZvgiy+i9fby2JVX8/C0gxjf3sIDv/wR5bf+lMJzz93ucfYEUtPovOceuu+7H7WgAC0YxFJeTvGVV+I/60ySqoVLVtTxTm+YG0aVc83I8h0ftB9aOIyw2QYJxP3R43Gavv8Dou+/j7DZKPrmNyi+/PJBeaq7QkLT2ffDlZxQXEAwkWJZLMmSQ6fkx4TdxY/XN/Fws2EvfmHGWPZLRun719N0P/QQwmaj5Krv0f3wI6hFhYz6978HjHcJTefxlm5e7OhjQSgKgEdV+Ne0MUzLJAi//TYFp5++3boDI2FdT6WGbOOG4r+eDe99wImjpuNIJoi63KzefyxF3h0bhLdlYTDKKYs38Ld9RnJy1lMAW2WL+niS2za38kZXiLiu41AEpTYrDYkURVaViyuLGe2ysyYSZ200wfu9Yc4tL+IPE7fv1daCQWILF6IWFmIpLsZSXLxT7eOWDU081NTFtSPL+NGoil2+3p3h4flL+HFc8PjoUo6rHfp9Yd9dXc87PWFWHLa1DUpdp/tvf+PFMZO5Sbj5Snkhd08cgRACra+Pznv/gm3USIrOPx/4Yisy2RlrPvvPzJkz5ReBTCYhly67XDY1vS0XXHKO/Mu5J8uK2UvkNWvq89tsiMZl2ewl8s9b2j7ROW7d0CQr5yyRZbOXyHvq2/PLWxJJWTVnibxlfaOUUsrV4Zg86qM1smz2kgGfL320RiY1Lb/fj9c1ypHvLJWxjLHs2bYeWTZ7iXy/JyQPmrdKnrF4/ZDl0HRdHrdgrdxv7koZz2hDbtOf69c2yPHvLZe6rg9YntJ0OeX9FfIbyzfLn25okjVzlspIJjNgm5MWrpNls5fI0e8uk6vCMSmllKFQaLvnS3d3y/WHHyFXT54iV02aLO+dt0RWz1kqD5u/etDxt+WvjR2ybPYS+WhT5w6va1d4vyckT1iwTt5X3y77Umk5rzcsy2Yvkc+09QzYLtXSIlt/8Uv5t0f/KctmL5EL+yL5dTesa5Qj3lkqx7+3XH5v9ZYhz6MlElJKKV9o75Vls5fIRdn9dV2XmXB40LG6kukhj5Or40PmrZYj3lkqy2Yvkauz9b8jtERCJhsbZXTRIhlbskSm2tulrg1uJ7GMJke+s0zesK5xwPLXOvpk2ewl8t3u7d/nQ+etluct3bj1eEuWyAv/9bKcPHuxzGzT1vqj67pMbtkiY8uWDVmuLbGEvH5tg+xIpgYsf6ChXZbNXiInvb9cHr9g7aD9bs224d9sapEVs5fIQ+atlstD0UHb3b6pRZbNXiKvX7lZls1eIt/sCg5b1iebu2TZ7CXywYYOOerdZfKI+WtkZ7971plMy6Z4ctj9d4V0T49s+emtcvXESXLNjP3k6gkT5eqJk+SWSy6Rvc88O6D9fFL0VEo2XH6FPOnex+T+r8+Xa48/Qb580mnywfc+kn+sa5VvdPbJ9kRKvtFptIF7+/Vz/fnFxmZZMXuJ3BCNy99tbpHls5cMerbXRuKycs4SecmS9TvVT+X44doGWfvOUjlj7kp54PvL5fJzzpWrJ0yUm888SzZs2CRPXbReXrmybqePl9A0ef3aBlk2e4ksn71ETnhvuXy9s09KabSZstlL8v/fsK5Rls9eIj/u99zvDJuiCXnz+kY55t1lsmz2Ennuko1yXu/w9+vg95fJsx97Vi75492ycs4S+YuNzbt0Pi0alW88+bSseGuRnPLs27Js9hK55N0PdukYfam0XB+Jy3B6+32yruvyFxub5c3rG+VTLd1ydTgm05o+YH2O8DvvyLqvfk12P/Z4vi9Mapq8cNkmWTZ7iRz/3nJ5zpINu1TOXUFPJmXPP/8pkw0Nu+V4r3QY/fjsrqB8oq5Zln2CtrEjWhJJWTNnqbx8ZZ2s2qYtJOvqZP03vmn0BRMmyuiiRYP2/1m2DR/98Rp5V12b/Kg3LA+at0qOfXeZXBwc3P99Gn663pCBHl1fv1NjxHDcV2/05W2JgX38trJFPKPJ2V1BefP6Rvm1pRvlP1u6huxLfr5hz9wbKQ05afL7K2TZ7CXymI8Hjzu7g+5UWk56f7k8bdF6qW1n7PxPa7fxrG9zX9/o7JOVc5bIry7ZKFPa8PtLuWP5bU8DLJTD6BOf3If8P4Kq2pm27wOEw2GatvwYb0GMb9eUcG9jJ6eW+Dkq4OOp1h5UAecO4+XYEQcVuLm/sZMCi8rXK7e6/SrsNs4oLeTJ1h6KrBb+uKUdn0Xlvsm11DpsaIAmJVM9zgHWzeMCPv7e3MXcvgjHBnw83dZDld3KoX4P55UH+E1dK3Wx5CDr3osdfSwPx7l70ggcO/Hej0keJ4+1dNOaTA94h8mb3UG60hnOqyjCoSg80NjJB70RTiguAIwcnEWhGJdXl/BSZx8XLd/MqzPHsyP7haWoiMrf3s6a732fP/30N7wZhxOKvfxp4gjcO/CcfLOqmNe7gvxofROb4kluGV2JVdk561c0o9GVzuS9Yv15qKmTlZEYS8MxflvXRpXDilNROCEwMBTAWlFB+U9u4ZyMxs8+WMmLnX3MLHATzWj8p62HU7PWo7e7Q2hSDvKQ5Kxec3vDuFWFfb1GbQkhBli6vl4Z4JHmLp5u6+Hbw3jUOpJpNseTXFgR4InWbpaEY0zyOAdssyoSp8RqodS+1Vui2O3YqquxVVfnlzXEk1y5up4fjizn6Ow1v98bJq7rfDl7v3McWeTFqQj+2xXkyKKhLTdNiRSb4kkurtr6HDinT+crlSN5c9UW5vVFOLxw6H2FENhqa4dcB3DnljaebutlUSjKM9PH4rda6Eyl+f2WNo4q8jLT5+bOLW30pDMDQlTe7QlzkN/NjaMrOLLQy3dW13Pa4o08N2Ms033GfehLZ3ioqZNTSgq4sTrAu6E4v93cyjFF3iEt/P9p72WM086l1cVM9ji4YPlmvrJ0I1M8ThaFotTFUwjg9FI/140sZ5z7k71Y7oZ1jayKxPnt9Tcw+tyv0Pv4E9jHjcN3yslYy8o+0TGHQlitWH53B0sWbuCC156Dvj6OfvABnNOmDdjuOHsBxwZ83LmljbPLCinr1766Uxkebu7ijLJCxroc7ONxIoG1kQQzC7Z6id7rCaNJeK03yvnLN/PI1FGDcvi2JZjO8J+2Xs4sK+Rr5UWcuWQjf7nl19zevJ7WQ4/gK2saaEoYYX3XjEwwfgf13ZZMc+nKOhaGYnxvRCnnVwS4YtUWLl5Rx5mlfp7r6OPrlQGOzz4DPxldwdvdIa5e08BbB0zY4XuVMrrku2vqeaGjD6sQnF7qZ6zLzkNNXZyxZCOH+N38bnzNgHbRmkxRl9b5+qzDmD6ilC+vrOPJlm6uHVk2bP+4NBRjhNOWb+9Rm52bRk2hRkoeDEX4MkX8t3o007dbWkjpOrO7w/y7vYc3u0KkspEcXlVhhNPG7eNrOKBgYP7NCx193NvQgU0IUsNEmR8b8HH/5Fo8s2YNCCHM6JJvr67nze4QvxtfzYZYgidauknqOnZl908RLmy2QWFXwyGlpDejYRECmxDYFTGoD3iuvY+A1cIRhV46VIlNCF7u7BtQR63JFC2J9IC2vyvc29CBjuTm0RX0pDO82bV14h3byJHU/O0hwq+/gR4J49pvvwH7pnXJv9t6+XJxAQ9P3Rra/sz0sZy5ZCNfW7aJf08fkx+HPg296QyPt3ZzZmkhp46s5EdNPSwLx4YdI7bHglCUEQ7bgH5lKByqwlEBH0cFth+yd93IMp7v6OXG9Y28PnMClmFkhqWhGC939tGeStORzNCVTjPe5eC0Uj9HFfmGlKfm9IToTmc4uMDN/GCUpkRqh97TXeU3m1sJZjRuH1+9XW/frCIfIlum3JhWF0tyxep6pridPLTPyJ2Wl76IfDFfGvA5IDMZ3O0h9JoKrh9VwXiXg+vWNdKTzvB0Ww/HBnwDhL5d4cACD3ZFcFl1CZ5tBuQra0qIaTq/rWvj2ICPdw6cyJllhexX4OaAAjcH+z2D8l0O8XtwqQpvdgVpT6Z5tyfMV8qLUITg3IpCFIycnv6kdJ3fbG5lstvB2Tv5ltdJ2UF0dTQxYPk/Wnsot1k5qsjHQX43blXh7e6tseX/aetFAb4zopTHpo6iN6Nx0YrNxLQdz34S2/8Avn/PI8wuKOEnYyp5ZJ9R+HciLloRgif2Hc03q4p5oLGTs5dupDW5c+9j/cHaBo5dsI5IZuBMQqGMxuzuMN+sKuHN/cdzeqmfxkSKM8r8w+Yg+Swqs4q8vNzRh5SS5zv6iGg6X68q5tiAj560xpLQ8LPUfNgX4aAC97Ad6iSPk4MK3Dze0o0+TFjo/KARJnBeRREFFpWl25wvpeucuWQDP1jbMGw5cty5pZ3FoRiXrtqSP85rXUF8FoVD/AMHYJeqcGSRl9e7ggNeMtuf93rCABy5jbJyTMBQgl7q6NthmYaiJ53hxY4+DixwsyGa5Pzlm4lkNG7f3EpM0/nF2CpmFXmRwNzeSH6/9mSaNdEEs7LlObTQw+v7j6fYZuHC5ZupjxshZ39t6iSs6Vw7shyrIrhuVDkrInFe7QoOKktLIsW8vghnlRUihOCwQi+PTB1FYyLFu71hJrqd3DK6gu+NKOWN7hCzPl7L91bX05XatZmFPu6L8GhLN8vCcU5YuI6/uAKU3HYbgW99c0glJq7pxDR92HuTI5TRuGtLG1Ft4PPwciiBriicVVVK7eOPDVJicvxybBVpXfLLTS35ZVJK/tzQTlzTubrWKNs+WSFpZSQ+YP95fRFqHDZ+P6qUBcEoZyzeQFty+7lQ/2rrIa7rfKOqmIP8Hq4fVc5zPRHuHDeN01dsIaVL/rnvaOyK4KGmzkH796YzPNHSzU3rmzhzyQYO/2gNqyIJHphSyy1jKhntsvPSfuO4uDLAcx19jHPZubVfGJnbovLHiTVsiic5a8lGrl/XyJ11bfy7rYf0ECF4HwejvNDRxzeqill0yGTumVzL1SPL+fiQyfxybBVrIgluWN80YJ9cuz08m9d4WXUJfRmNZ9qGemmyEXL75UXrmfnhKm5Y18imWIKbNzTRnEhxz5SRTDvzNA7zOXmmvXdQX5LQdOb1RfhzfTtfX7GZfeeu4pKVdXzUF+XrVQHumTSCW0ZXcG55EX1pjW+v3jKg/4xrOr/c1MIUj4NNR+7LewdO5N5JI7h2ZBnXjizjupFlXFFdwpyeEGcu2Uh7v/u7KZbgguWbeaUzyC/HVnFxVTGH+j3EdTmoL+tPOKPxWHMXP93QnH9udxdvd4e4eX0TZyzewPj3VzD5g5WMf38FI99bTsU7y/je6vr8fQ5nNN7sDnJ6qR+LIvBm+8VXOvvyz144o3HWko2cuWQjLYldf294ezLNEy3dfKW8iBFOO8cHClgfSwy4biEEvhNPwNcvPzLHnJ4QXekMX6sYaJytcth4ZsZYvBaFry7dtNNj6PZ4uLmLmKbz3RGlFFot1DpsLAtvf6a2YDrDCx29pPStMoOUkgXB6CCF+dPgtqj8fGwVqyIJHmkZrGy3JlNctaaeExet54HGTj7sjRDKaJTbbLzbG+YbK7ewz9yVXLe2gaQ+UL75T3svRVaV34w3DIOvDzFWfBoWh6I80dLNpVUlgwyV21JsszDN62J2tzH+ZnTJ99bUYxWCR6aOGiSX7m38v/fI5AhuWY+qg3fcRByqwl2Tajhl0QbOXrKRjlSG8ysCOz7IMARsFj44aBKVQyhC+3hd/GRMJeU2S17w2REOVWFWoZe3ukPUOu3owFfKDeWkwm7j6ICPf7X18KNRFXmB+LGWbuoTKf6x7+gh8yWGYmJWkVkTiefzXFqTKWZ3h7iqtix7bJEvi5TG2wP+3d7DrCIv5XYr5XYr90+u5ZIVddy0pZOHpvmGvca0Lrls5RZa0xr/nj522IkIhsOuKNw2vpoDC9xcu66RYxes5/7JtRyxHcvPynCMlzuNDubZ9l4urtr6Zuz/dgVJScnppX6mel3cNWkEvx5fhW0HLw08tdTPm90hFodiPNrSxUS3g/19Lsa57KgC3uwOsf8QnXFHMs2GWJKv7aCtXVwZ4LtrGpjbGxny2ub3RXAqhldnmtc5aPCf1xcllNGZ0xNmXTTBhGGs05tjSf7d1sM5ZYXMD0a4cPlmXtxvHG90hTimyDcoBwLghOICXu8KsTISZ+oQ1rx3e8OU2iz5tpXDraocGyjglc4gt42v3uk2muNfrT0kdMnt46tpiKf41qo6zlyykZWROJfXlDDObbyg1qMqvN8b5tRsntK7vUbH/qV+9Vhmt/LPaaM5ddEGzlu2mX9MG81fmzo5qbiAyR4n4XCYs8sK+XN9O7+ra+PE4oIB5X2uow8JnNXPYPClIh9rD5+KKga+9+mKmlLubWjnoaYuXKrC7ybU7NT16lLyk43NVNitvLTfOG7b3ModW9p4tauPCyoCHFjgZpLHiSYlc3rCPN221ZJuFQKfRWWU08a/po0ZpJT/vamT2+vaCGv6gKnVn23vZarHySHXXLVtcQYwymXn2yNK+VN9OxdVBghmNO6qNxTis8sK896QaruVAovKqn6KjC4l84OGp/n0gJcan5dvrqzj3KWbeOfACUNaHXUpeaS5m/19rrwF+fu1ZXzQG+HBpk7Guxw8OW00NQ4bZ5UV8u+2Hn48uoLCrIEko0u+tmwTy8Jx3KrCRLeDM8sK+WZV8QABwZG9P6eV+hnltOcT+3McXujl1jGVPNvey2udhtcaICMl523zTL/eHcQmBDePrhggRLhUhctqSkhLyS82tbAyHMsrfB/0Rii0qEzOlunAAjf7epw81NTFRZWBQf3qe71hJHBMwMdTbT082mIYt66pLcsLg6cFvFxf18GCYJSDspPYJDSdkxevZ1XEMGCNcdo5obiAU0v9zCr0DrLcnlFWyGmLN/CLTS359ntfYwfNyTR3TxqBVRGMdzuG9IIdWeTlslVbOHnxev46ZRQvdvTyUFMXDkVwx4RqLqo0+uOD/R4EWUPPNpPtLA/HeKipk5c6gsR1HQV4rKWLq0aU8d0RpTsVfbA95vdFuGD5ZlyqwhS3k7PLixjttKFJSOmS5mSKx1q6iWk690+p5bWuIAldDnj+Ty4p4K3uEMvCcaZ5nVy/rpGGhOGVvbehg1+Prx5wTiklUU0fVsD8S0MHaSn5QdYocFyxj59sbObN7hCXVm9NJL91QzMf9kV4ab9xA+rhX209BKwWji4a7LGocRj9wqyP1/Kn+g5u36Zsu0JU03ioqZNjA778szTN5xrWmBfNaDzU1MV9jR30ZTRuHl3BVdlrbEyk6Ehlhhw7Pw2nlBTwpUIvt29u5dQSPx5VYXkkzrs9YR5o7ESTkqtGlPKD2rIB9yOtSz7si/Bcey9PZvOFbxht5MEE0xle7wpyQUWASR4nY1123ugK8a3qwUn+OZK6TkqXeHdCqdCk5MZ1TZTZrPxw1M7ljR1V5OVP9e30pg3P+KJQjPsn1w6IttlbMT0yWepWfQBAzZRDANjP5+a7I0pZE01QYhv6gd8Vahy2YYWz744o5ezyol2aROC4gI/mZJp7GtqZ6XMxxrV1kLigooj2VIbZPSE6U2l+trGZX21q4XC/h6N2wZ3rt1qotFtZ288j83RrLzqGtT/HsQEfLVnL9ry+CE2J9IDJBo4vLuCGURW80hvhqbaeYc/3i03NzA9GuXPiiF1WYvpzRlkh/505noDVwrnLNvHHLW3Dei9+V9dGgUVlnMvO4y3dA6zVL7T3Ue2wsp9vq0DuVtUdumBPCPiwCcFtm1tZHo7nhQy/1cKBBW7eHMYy82GfYXE9dAez4p1c4qfIqvLoEBYkgI+CEQ4ocGFVBDN8blZH48T7ecNe7wriVAQORfC3IazTOf6wpQ27Irh1bCX/3NeYTviUxUZC/4klBUPuc1zAcGH/d4hr1KXk/d4wRxYOHY51aqmfrnSGeX2RAcs3xhIktuPN06XksZYuDixwM9nj5MSSAu6dVMvKSJyA1cJ12QRhiyI4rNDDu1mvEBhhZcVWS144zDHW5eDRqaNoTqY4dsE6Qhmda0Zu9XKoQvDDUeWsiyZ4rn2gRfzZ9h7287kGhXZahghBKbZZuHVsFccFfLydNQbsDP9u62VZOM7Noyuodtj4y+RaHt5nJMGMxk0bmjl24XomvL+CaXNX8fUVdczvi3JRZYCbR1dwZU0JxwS8LAzFBj2PmpQ83tKNAjzQ2MH67LNfF0uyJBzjzJ305n6/tpRKu5Vzlm7i4hV1dKYy/G58NX+YuFVRE0IwxeNkRXirIrMumqAnrXFI9hmYVeTl9vHVrI8l8s/HtrzXG2ZzPMk3+wkJqhDcP6WWG0aV8+J+Y6nJDtaXVZcQ1yVPtmz1WD/Q1MmybMjthiOm8srM8dwxoWZYK+fhhd787Ijb8u0Rpbx5wARWHr4P9bP2ZZTTNqh9SCl5vSvI4YWeYQXV8yuKcKkKDzVtfcbn9kU4xO/JK3NCCC6tKRm2bt7tCVNpt/LXKSNZeMhkrhtZxoUVAa7tlzB/nN+NU1F4pl8Zf1vXyqpIgt9PqGHVYfsw9+BJ/GnSCI4N+Ibs+w4ocHNlTQmPtXTzbk+Y1mSKP9d3cHJJAYcNEyaa45iAj2enjyWhSb68aD33N3ZyTnkhHx48Ka/EABRaLUz2OAZdZ1cqw2mLN/BqZ5Bzygt5deY4Fh4ymeOLC7hjSxtfWrB2UH+yK6R1yY3rm6h2WFlx2BRemjmO28dXc3lNKd8eUcoPRpbxuwk1/GpcFa92Bbl05Raebu2hxmFjZr9x44TiAlQBr3T28Y/WHp7v6OOGURV8pbyIJ1u76djG4/jzTS3s++EqNmwTDQGGweuxli7OLitkZDYceqTTzjiXnTf69bvLwzEebOpkRSQ+wAvZk87wRleIc8oKhx3LxrgcnF8R4MmWbhp24N2KahrB9NDe5P+09dKT1vhevzDoaV4XjYkU3dt4oJ9v7+XA+Wv4TV0rBxS4ObDAzV8aOghnPX0Ls8rP/r5PH+7WHyEEt42vJqVLjlqwlnHvr+DMJRu5q76dowNe3j9oIjePqRz0rFoVwawiL3dNGmEkyje0szLraXq5M0hSl3k56PhAAR/2Gd6c/qyOGDOtnbt0IxPfX8GB81bTPISHbkU4xuWrtvDDtYan9+YNzSyPxPnZ2MqdUnzAeNZ04O76du7c0sZZZYWcsZP9+RcdU5HJ0rV+KQATpx+dX3bdyHIO8bv5dk3pFy5+8Jish6QnrQ3K3Tk2UECJzcItG5o5cN5qHmzs5NRSP/dM3vH7QrZliscIPThg3mouXL6Zvzd3cqjfk+9AgXzuxNvdIf7d1otHVThxm/yJ79WWcpDXwc0bmtkcG9wx/qeth782dXF5dckAS9YnZbzbwWv7j+OsskJ+W9fGhcs307NNZ7skFOON7hBX1pTwzeoSVkTiLM0KVb3pDO/2hjitZOe8ZP0psFqYVeRlbtYz0l+pOy5QwOpogqYhOqsP+yJ4VIWpO3ATO1SFr5YX8d9saGF/QhmN1ZEEBxUYguAMr4uMJG/1llLyRreRw3J21jq9bb2A8ZLYZ9p7+UZVCSU2K+PchmAf03RsQgyr2JfYrBxQ4OaNrsHvwl0VidOT1oaNjR4qvOzZ9l4O/2gtRy1YO0AB6c97vWHq4iku6edNO6OskH9PH8MT+44ekF9xZKGX+kSK+ngSXUre7Qkzq8g7pKX/QL+HeyfVEtV0Tij2DfIwnVriZ1+Pkx+tb8qHzK2JxFkVSexyGz46a5hYFxssuMztDfNOz1YlJ5rRuG1zCzO8rgHn+XKJnwUHT+ajgydx76QRnF1WyDEBH49PHcXSQ6fw6/HVXFVbxs1jKrl7Ui0zfS4ezFocc7zVHaI5meb28dW4VZWbNzQhpeS5jl4EcEa/Gfe2h1tVuWNCDTN8Lu6eNIIPD5rExVXFg/IbpnqcrInGyWTDcuYNocyfXOLHqyo81Tq0EeTvTV0UWy2cvI1yXWKzcs3I8gGhqZM9Tg73e/h7cxdpXbIpluCOula+XFzAV8oKd+usUnZF4YzSQj7ojdCZ2vqcrosl2BJP5XMKh8JvtXBueRHPtvfSmUpTH0/SmEgNMvCcUuLHqYi8VzmHJiVzeyN5o0GJzcr1oyr4/cSaAWOZW1U4sdjHSx19pHSdj/oi3N/YycWVAS6sDBCw7VzQxo9GVTDWZefatQ3csqEZHclPxww9g9K2TPe5eHnmOL5eGeDVmeP548QRA6aXz3Go38PCYHRACM/TbYYnNqd87udzU+mw8eCUkTw9bQwKgvOWbco/n7vKQ02drI0m+NXY6u3maV5aXcJvxlfzRneID/qFleYoslo43O/l6bYebt7QxKxCL98bUcr3R5SR0iV/aezIbzunO8T9jZ3ENJ3r1zUOMMJJKfnR+kY0CVfXDrTEHxcoYF5flHBGQ0rJTzc0U2S1cGShh7vq2/Nt8Ln2XtJS8tWK7ef8Xl1bhiLgj/XtQ67fHEtyy4Ymps9dxQmL1g9pLHyho4/xLgcH9fOiTPMa49vyfuFlCU3nhvVNVNqtvLrfOB7fdzQ/H1tFb0bLG9sWBKO4VIVJ7u2Pj5+E0S47vxpXxUyfm2tGlvH41FGsOGwKf9tn1JC5s9vyi7FVFFktXLO2MZt/1MNYl53p2Ws9odhHWkpm9wvBf7s7xDEL1nHb5lY6UxnOqwiQkkbIV/8+uTOV5uIVdbzTE+K/XUHu2NLGI81dfKnQy+k72R8DTPe68FtU7mvspMxm5bZxVTveaS/BVGSyJLdsIeK14Alstbo6VIXnZozb4TTFnwdldivTvE5sQgyYzhcMS8GFFQGaEilOKfXzwUGT+POkWso/QY7Pz8dWceOocvb3uWhOpIhoOpdv4x4tt1uZ6nHyUmcfL3X2cWqpf1DYhSoEd4wqwyYE3+kXTwzGlIrXr2vkEL97QCjLp8WtqtwzaQS/HV/NB70RjluwbkBs7u/qWimyqlxWXcLZZYU4FYUnsl6O1zqDZCScXub/ROfOhS6dUeYfIEgf10/p25YP+yIc7PcMmx/Tn4sqi8nIwblQiyIJJHBwNn9lRtZ6lXPlr40maEqkOT5QwKVDWKdz3LmlDaeqDGj7B/o9PDVtDHdPGrFdK9AJxQWsiMQHKWvvDpMfkyMXXvZqVxAtq2T8YE0DM30uBIKvLtvElau2DFLeHm3uJjCEIHt4oTef2Jgjd+73esOsjsTpSmeYtR0v5Smlfv67/3j+PGnwJAOKEDy+72hqHTYuXL6ZVzv7eLa9F1WwSwMMkPeU5mKYc8Q1nUtW1PG1ZZs5cdF63ugK8ueGDtpTGX45rmqQ4C2EoNZp5+zyIn47oYZ7JtdyXHHBkIaYK2tKqc++PyLHI81dVNitnF8R4IZR5bzfG+HF7HUd7HfvUhjCMQEfL+43jnPLi4Y1BE3xOknoks1Zq+/8YJRKu5UR/c7jUhXOKCvklc6+vHU2R0M8yZvdIS6qDOx0EvhlNSW0JNO80tnHdWsbsSsKt4+v3mWDxc5wRlkhOsZEKzlySv7xxdv38l9aXUxKSh5r7mZu38D8mBwuVeHogI/XOoMDBMmVkTi9meGNBv05u7yI3ozGK51BfrC2gRqHbaeVkBxOVeFPE0fQmkzzSmeQK6pLdkoAzDHSaee3WcV3OHJ5Mrm+TErJEy3dHFzgHjI89sgiLy/tN47RTjsXr9jM+7uozLQkUtyxpY3jAj5O2MG9AvhGVTF3TKimwm7lq0NMDHRySQHtqQw+i8o9k0egCMEol52zygp5tLmbrlSGrlSGH6xtYILbwW3jqpgfjA5Q4J9s7eG/XSFuGl3B6G08vsdlheV3esK81BlkfjDKjaPL+c34ahK6zm83twFGWNlUj3OQF3pbKh02Lq4M8HRbzwDjY308yQXLNnPoR2t4tLmb8W4HW+IpFmRzM3N0pTLM74twcknBgGcrZ6jrPxa/0R0imNG4ZUwl+xVsHbuOD/i4r7GTUEZjUTDKfl7XTo2Pn4SLq4p5fN/RXD+qguOKC4ZUpoej0GrhN+OqWRGJc/OGJuYHo5zTT5ndv8BNkVXljey435FM8/01DUx0O1hx2BTmHDiR28ZX8+txVczri/KXBkOxzeiSK1fV05vO8Oz0sXlP74JDJvPI1FG71GdZsh4kgLsnjdip3OO9BVORAdJaGldLD4l+Ft29gZ+MqeSOCTX5WO/+/HBUOasO34c/T6od1OHtCqNddq4eWc59U0Yy58CJbDpy3yHDio4J+FgejhPVdL5SNrSlp8Jm4fcTalgajvGLTc38ramTExeu55TFGyi0Wnhwyu6fOUMIwderinkh+y6c0xZv4F+tPSwIRpnTE+Y7NaV4LCo+i8qZZcZsROGMxgsdfYx02th3B539cJxcXMCZpf4BLnWAsS47I5023txGkWlLptkYS+4wrCzHaJedIws9PN7SPcB6syCSwCoE+/mMwaDMbqXCbmVpdtDIJRzmYpaPLNxqnc6xJhLnxY4+Lq0qpngbi+zBfs8O3dEnZgf9bZMb3+sNM8Ht2K5CfWqpn85UhgcbO/nmyjrGuez8c9oYZh8wgR+OLOfVziCHfbSGu+uNxPHmRIrXu4KcX1G0U4LsWJedSruV93oivJMVbGbtIPxlmtc17KxZZXYrz84Yy1Svk0tXbuHRli6OLPTu0iAIRpLtBLeDOT0D28XrXUHCWeNBb1rj4hV13FXfzlllhZ86VvykkgJGOGzc32BYPLfEk8zpCXNhRQCLYjw3Uz1GPP/GWHK3eEq3JSfUrIzEkVIyLxs+te0AfV55EXFd8sI2k0H8sb4dRcBFlTufw3hswMdIp40frmtkfjDKz8ZW7nAWpE/KBLeDSW4Hz7f35Zf9tyvINK+TCvv2lcKxLgdHF3l5tKWLOd1GCOQE12CB/aTiAtpS6QF5BzkPxBE7EaI7q9BLkVXlmrUN1MdT3DVxxCdK/p1Z4OZHo8qZ6Hbw/drdN2Nejv55MmCE2m2OJ7lwO/c+YLPw7+ljGZVVZj7o3Xll5qcbm9Gl5FfjqnZaYLyospjFh0wecsw9pdTP/j4X908eOaB/+EFtGQld54HGDq5b10BfWuO+ybV8o6qYgwvc/GJTC52pNBtjCX6yoZkjCz1cXjM41+IAnxu/ReXlzj5+samZyW4jPGyMy8E3q0p4srWbZ9p6WB6O79Abk+OqEYbx8c4thhL0RleQ4xeuZ0EowvUjy1l0yGT+NW0MDkXw/DbP5htdQXSMfqY/BVYLo512lvULKX26rYcKu3WQon79qHKCGY0/bmljVTS+WxP9dzenlPo5paSAx7KGwf79pSoExwUKeLs7RFLXuWpNAzFN4/4pA9vCV8uLOLXEz2/rWlkainF7XStz+yL8dnxNPlfOrijUOGyfKPfrptEVPD511LAzg+6tmIoMsLpnNRVdOs7RY3a88ReIwwu9w3ZIqhBDKjh7itxkANUOa94bMBSnlPq5oKKIvzZ1cfOGZtJS52djKnlj/wm7LPztCjN8Ll7ffwIH+Nz8YG0Dl6yoo9hq4RvVW5XXCysDxDSdBxs7+aAvzOmlux5WlsNtUblvysgBuUtgKFbHBXx80BseMItbLqTmsF3IDbq4spjmZDpvvQFYGI4z3esaMP3rDO/W5Mo3ukPM8Lrygttl1SW0JtO8nJ1R552eEFetacCtKsNO77wjxrgcjHPZBygycU3no2B0h0pDLrzs55taKLSq/GPaGHwWFYeq8MNR5bxz4EQO9Xu4bXMrh3+0hhvWNyHZeUFWCMERhV4+6A0zpyfMJLfjUwuxhVYLT08bwxGFXkIZnXM+ocB/dJGXj/qiRPt5Hf6VnVr9Z2MrmXvQJP40cQQnFRfwkzGf/uVqqhBcXlPCglCURcEojzZ3oQq4IFuXqhD8Znw1oYyOVYgBL6DbXYx1ObAJwcpwnE3xJJ2pTD4/pj8zspNlPNXPA/lBb5h/tvbw7ZrSXfIUqUJwaXUJEU3nS4VevvYJp9XfWc4sK2RBKGokKyfTLA7FBoXeDsflNSV0pDK81NnHoYWDFTww+l6rELzSL7zsvV6jbe9Mn2pVBKeXFpLQJZdXl3yq/MSrR5Yz54AJe2QWpEKrhSkeJx9mZ297oqUbv0XdYbvMKTO1TjsXLd88ILxnOJ5v7+XlziBX15btkmcJGHbMKLJaeHnm+EH1O85tTON7b0MHr3eFuHlMBZM9ToQQ3DGhhpimc9P6Zr6zuh6HIrh7Uu2QIZAWRXB0wMcLHX00JdL8YlxVPi/32pFl+C0q31/bgFUIzizduT6q1G7lm9UlPNveyzVrG7h4RR21Dhtv7j+B60aVU2q34rGoHBswwhMz/Qxir3QGqXHY2GcIY+A0rzMfWtaZSjOnx8jZ2TaPeKrXxcklBdzX2Ikm2e2J/rub34yvptCicqjfk395bo4Ti30EMxqXr9rCu71hfjmuepAn0bjn1ZTarFy0YjP3NHRwcWVgpxXPHVHrtHPcTvY9exOmIgOs2DAXbwJKJ834vIuy15ITNL5ZVbLDOPNfjjNcqLMPmMDbB0zkyhGlgyz/e4Jim4Wnpo3h2zUldKczXL3N+xdmeF3s43Hyh/o2NLnr4UE7y3GBAhL6wHjZD/si+CzKkJ3+cHy5pIBTSgr49ebW/DTDK2LJQYrkDJ+LzfEk66MJFodiA0Jajgn4GO20c+eWNk5YtJ6vLdtMVyrDHyeO+FSK8AnFRnJjMJ2hPp7k1o3NJHW5QwuxW1U5tdSYzOCpaWMGeW9Gu+w8tu9o/jN9DEVWC291hzgm4Bs0aGyPWUVeejMac/si2w0r2xXcFpXH9h3Fk/uO3umE+G05JuAjJSUfZJXa3NTq52SnVrcqgq9WFPH3qaN2aM3fWc4rN6bovqu+nX+19XBiccGAOt+/wM0Pasu4rLpkwLt3dhdWRTDR7WBVJJ5X5red1huMAf5rFQEWhmJsiCaIazo/WtdErcM2IHl9Zzm/IsB1I8v446SaPRJS1p9cP/JCe28+tGR7+TH9mVXoZVzWun/4MN7aAquFwws9vNplGCPims7HweiwIZxDcWVNCVfUlHDj6E+vIO/J+jzU72FhKEprMsWrnUG+Ul64w3f2gNH3/3v6GMa4HFy8YvOgCRhytCRSXLZyC1eurmeqx/mJjTm7ytW1ZUiM+31Zv9DtcW4HV9WW8lKn8Q64OyfWbNejfXzWoPjl4oIBVne/1cL1o8rRpBHevLO5TwDfqSnFpSr8s7WHiysDvLjfuEHK3emlhQMmaglnNN7vDXPSNmFlOaZ5XTQn03Sm0jzb3osmGZBL2p8f9nu+Z+7mRP/dTYnNymv7j+f+yYNDkY8s8uJQBK93hTilpIALhlFO/FYLf540gq5UhuleF7/8H8pl2VP87wTJfQoaVs5jJlA0YernXZS9FlUI3j9o0k5t61KV7U5DuCexKIJbx1ZxWXUJFdsMCEIILqoMcMP6Jsa57Pn36OxuDva7qbJbuWpNA3Fd5yvlRcztjXBwgWeXph1WheCBKSP50bpG7qpv56NghIxk0PSkubjzXHjA8f2EKCVrlb9xfROjnDbunFDDOeWFn/qlcycUF3BPQwenL9nIumgCRRiu9p2J2b9jQg0ZXQ77rh4wvJGv7z+et7pDTPXuWvhff2XqS7tJkQHD5Z+bhOOTcECBG1f2nUwnFBcY7/dg69TqewK3ReWiygD3ZL163xgivPbHu0G43R77eJ38tytIwGah1GaEnQzFV8oKuW1zC0+19WAVgs3xJE9PGzMoH29ncKkK14/as9eVo9ZpZz+fi+c7+ii3W6lx2Ha6bxFC8O0RpfxoXeN2le6TS/z8cF0ja6IJulIZkrrcpRcO1jrt/HzsF19gOtTv4cGmTm5c30RKyrz3cGcosRlhoJesqOPbq+vpTme4tLqEjC5ZH0vwVneIu+rb0aXkhlHlfGdE6R55+eZQTPI4eX3/8Yxx2gcZAr9fW8b7vRFm+FyctAPv03HFPr5RVcx3h1DALq4sZmMsOejdMTsiYLPw0JSRJHU57GyVxwR8uFWF5zt6OaLIy9vdxlTvJw+jsE/LjknLwnGebuthutc17EtqJ3mcfLW8iE2xxF6R1zFymP7Lrar5EPzfT9i+AeWwQi+vzDTyuz6rNrg388VvFXsYKSXhDWsBsI0atYOtTf5XGC4U5eyyQn5X18bXKga/l2F3YVMUXp05nitXb+GqNQ3M7g6xOZ7k4l0YlHOoQvD7CTUUWCz8pbEDgfF+if7k3q3xQkcfVXYrk7cZMC6uDDDN62Jfr3OX398yHPv5XNQ6bPSmM1w7sowLKwM77UWwKwr2nei7FSEGKGU7S4nNyiS3g83xZH52ty8CdkXhiEIPc3rCSCl5us2YxnnsEHkRu5NvVRdzf2MHI512DtvJHK3dyRSPk3+09vBGV5BjAsO/Z6rUbuWYIh//aOkmrGl8pXznFOMvAmeWFvKTjc2sjca5pKp4l/qW88qLOC7g226Y2AnFPq5fZ0zvm9SNdwUd/AUPw/kkHOR3I4DXu0IcWOBm4i7OYOWzqPxj39F8Z3U9t2xo5smWburiSRLZkKhjAz5+Pa5ql8PJdgf7DvHeLTD6hRezOZ47wq1ufQHjtlgUY5rhT8JROzDQuLIzlb7SGeQ343Ve6QxSarMMGwo21eNEYExWsyqS2OEMWn/sN2373sw9k2rJyJ17V0wuz9Vkx/y/V2R6k73UBq3oVhVr5e6bMctk78RjUVl0yGRse3i67TK7lX9PG8tv61r5c9Yaviv5Mf0RQvDTsZVUOaw0haODEtN92ffkbIglOb54sKtfEWK7swV9ElQhePfAiViE2GOzzHwarhlZTlMitVNhKZ8lRxf5eL0rxPMdfayNJj7Vy+h2lgq7jT9PqqXCbt3jYVZDkQunjGg6B+9AkfpaRRFvdIcosqr8bMwX34OQ47RSPz/d2ExGstP5MTly0ydvjxKblYMK3LzaGcSqCGb6XNv1aO6t5PJkVkbi203y3x4OVeGv+4zkN5tbWRKKcWSRl2nZlwePdto/l2fgf4HTS/08097LG10h3s7mvAwXZu6xqIx12XmlM4hViB1OILM7p0X/PPmijTcDkBL0DKh7Lld5T/H/XpEpchRxsjKNRG0TYjvzxJv8/+HTvgl6Z7EogpvHVHJggZt5fVGmfMIZ0nJ8q7qEcHho6/10n8tQZD5F6NOu8lnV4ydh2ynLvyjkpmG+eUMTNiH2WJ7WtnzSvJ7dQf92P1R+TH+ODfg4usjLxZXFuxTn/3lTZrdymN/Dykh8j3kBTy7x85ONzQD8aCff9v2pifdC63Ljt90DNg84i8BdDLtb+NR1ZLCJgyONtMgCTv4UkxKoQnDLbpzqP4+uQ28duALgKBi+DnQd2pZDqAWKRkHhKLA6DGEy3gu9W4xvZ6FxLFcRdG+Euveh7j3o3gATT4EDvgVFo3f/dQyDlJJMKomuadhd7txCiHUzK7yOAuzcunI1MeHipLa3IaSBtxxqDjLaRD+meY0x6biAz8i/690CqSj4R4B9GE+rloZYD8S6IRWBZJjethaa6luYcMiR2MonGHUWboMt2brqWg/F46FiGpTvC+VTwbYdw10yjGz4iLal71JcUY61ZAwU1kLhSLDu4hidSRrXZXWCw29cl5aGYKOxPNwKnnIoGQ++alAUoz4TfYTq1yDbVuENrUJpXgBdG0C1gcUOFofxbXVmv11GPfsqjePY3JCOQToO6TgyFaGttZcV67pIJtMcOtFKwJmGdAISfRDtMupUTxvt1lMO3jIYdzwcetWuXfPnwN4zEuxBknWbsY4d+3kXw+T/KccVF+zxmUROLfGzKZb8VDMSmex5RmTf0L0hluTkkoJPN/OgroOWMgSkXd5XA2UnDDvpBMR7jIGvfyx3X6MhSPQ1woiDjY8lG67TvQnWvATNCyEwDk/VfoyyjySoM+T0wv2xBpu4q/tdCosPBHbhmelrRF/2L2JdLQhPCcJTilpQjr1ioiE4DWWF1HXoWGUIj30NUDwOyqZA6SSw+wzrpZY2Bn8t90lll6eM/zNJQyCNdfH7UIhNPVGan3iCWCJNIpmhctQoyqbsjwiMBXdJdttuo06LJ4B7GK9DKgZNC6D+Q2INy3GW1PDlkun8hMkAzFJC0N4NmYRRhnTc+LY6oGp/cGxj0NB147xCAUVFR6AH27AEN0PnOuirN9ZZHMYn0g6NH0PXOsCQvXpSLrZE/ehSMKMihqVsvCFAVu0HIw6FkglbBftEyBDGU7GtQpnFbpwjd8BIm6EktS2ndf0a1jXEWR/049NdXGix8uwTYQ4//nBGnnE1YtD1aMY969lsHLOg2hDyLA7oXAuNHxFeNw8Z78VX4DUEP7vXUBjcpca98BjfGWsBm1asQEn0UKS14g+vRA03GddVeyhUH2gIpSv+DSufgZChTGLzgr8Gp6cCAqOMMrgC0PARbHzTqMM8ArwVkAxDagdTRBdPgMBY+Oh+mHcvjD0Wqvc3jhfpMO6jowA8ZYZwi4CeTciuTdQ3dlFSXIC7dipU7GtcY/sqZMsyGjduxqMmKPI7wek3hONkmHg4xNsb3TSG3SQ1FU0qgOSI0noODDTmi2UHThh3A09XnoQnFeHgedcB/V62XDzeqK/AOHAFmKbX8B88nNvyMrzziKGo5XAWQUEVSCCTbbvJECS2zsynScHC7irmddWiSYV3Xp7DlIJ2ppUECajZ2Q0dfuN5XfcqLHncWKZYoXIG1B4ClfsZxw21QLAJ2leRalrBW62jWRMqpcgW46SqtZQ5oqBYDGWo9lCoOdio58aPoelj6KkDfw0UjYHAGOM+ti6HzjVGf5C/zQoZDZK6SlKzkJYKhbY4NkU36tsVoKc7xIdt5awLlwACgcTnKqTAfzQFHhsFboUCFYrdkoArjdCSkIqSqf+Yjc1JVvYWE0nb8FmTFNgSONQMG8PFdCVdWBQdVcDG5gQH1qY5aJwFi7/WqA93MVicEO3MtqV2iPdtvy1+QRByiLexfhbsv//+cuHChZ/Lufujp1Ksmz4D7yWXUP2j6z+XMsTDISx2O1bbHozLlXJI61A6lSTY1oqWyWB3ubG5XNhdblTL7tdxw+EwXu8XMKZdyxgDvv0LKOSn49D4kTEAOwqQdkN4E8mQYUlJRaFkotHps/06llLuXNiElMYn/7+eHUT6jIFE18Hpp709yEv33YuUUFwzgkBNLeVjxjFm/EjUhvcNAVBRDQGmeAIUjzWEhO1Zw3YGKaFhHiz7J6x6ATwlMOVM41NqCHLEug2BIh03BiBFNaxZrmKjwx5KSI/1GHVdP9cY1LwV4KsCX4Ux+GWSkEmQiEdxBGq2Wq20FASbIdRMureFWEInoQkSaYFTTVMiWxDdGwxhp3g8jDoCRs0yLIM5d76WMgT81qXc2uvkAds+PBZ8geMtQaO8AyyBwhC8ch9POZRONIQXMKyRS56AxY8aA3TtYTDhJGKVh2HzV2CRWaEgGTYEymT201MHHauhfbVRd8XjjIG+aj/jt8NvnEO1Gvd23auwaQ6ko0b7LBwF/hHIzvU0t3SzqLuK3rSTo8s2McKfhhGHGGXrWAVA0jMSEW7BQoqHq84krdq5svUF4/iKBc1VglpYA74qYtEYqxavYXmrg760E781zsnTNMoPO9s4buc6w8LdttLYPzDGECqsDlj5LN3rFvFC0yR6UwPbXok9whhfL2Mr7ZSWlyAsFqO9SAktS+jsTbCsr4K+tJtp/mbGero/kaMhmrHybMM+dCQH9zGFthiTCzoY5e4BAbpU0KUg4Erj2OckmHkJ1B4O7Stgw5vGp3khUsvwfucoFnRXU+UOc2igjssO/x2bXdWsmXsaqtSIZGy4LGlU0e95ForR9kYcQioWwta7ATrWGBZuoDnm49WWCYTSdjyWFH5bAr9Tp9YbYZS7G7uMgqOAdMUB1MsxbOqALRvqiQS3CuDlATun7pPAF1ljPItgCPHFE7KW6JadqreUpjKndworOwtQFUHtyDLKRs8g3B1n48oPSaRTeO1ORpdAla8Lj03Hb43hjdUZCua2qDZ64wofddWwOliGELBfZZRDytuxZUL5Osjds6W9FSzrrSCubc3vE0gKXTpVti6qXb1Uu0KkdZWmuJ9mdTy9GR8jqv1MqhQUK51oPVtQwy1EI1G6ky6kzYOlej8sIw9GLR6FJdaGGm5CDTcR1Z0EpZ9gykFKWigr8VIRsOKUEVL2Ejb2uli7aCmNq1aAAIvQUfUEBZYotQVJRpbbKS/1oaSChiAaNd4RFXGO5I3Gauo6warCQeWd7OdZj1XRaU/4mNMzmeagFUXAzPEuDhmdwarHaI66eGVxhmhCZ+LoItwuKw67hZaOKJvq+5h1SC37T68Bu4+wrZLbX1/O3w45jcnrlnDhmg855NRTmDC2FKVpPtR/aChxySBSwtp0OY+VnMLh6z4krhYTkW5sTieVJU6qvCkqHUHcLutWD4TNDe5ipLOI1l6dt16bT2dbF+OnT2Xc9ClsXryI9as2ommSQMBD1fiJVE47jJJRY9BSKZLdjaRa1mILbcIfWY2vZzGK7NdGPGW0W8fyyioXfaEk0489ng0LPyYWCnLYrBnsP0oY19G8yOivgV5Rxnp9Ct1pD1MqMoywNCF6Nxv9ddYDFLLX0FjXROPmJhoaughHB74oWiiCslI/VQGVcDjJ+oYICBXVPgOh+FHVCFZ7FKn1kYh0o6W3vnjUandSOWEi3kAxGxfMJxEJ4y0K4CsqJ9zbSzTUg5ZO4PLXUDbqYErH7I+UGTYteJbuhkXYXAFqJk+noMSNYrEgFAUtlSKTTqGl05SPncD0408CPn/5TQixSEq5/5Dr/r8rMlokSs/f/4aYPp3iI4/8TM/dsXE1C/5xH+tW12G3wJQJJUw/eDr+mnEQaSfZ1UBPUwPpSB82PYpNC+GQEZxeH8JbnrW4lBmCTNZ6RCpiCAuRdgi1kOrawpoN3axsMSwAVgtYLQpCUemLCyLJweE/iiKYOn0shx45A5fPmxUEsx8wBqKu9YbwkI4blo1RRxpWir4GQ8BZ9yq0rTAsQv5a8NeStHqxu3xGx6RY0MOdtNQ3smlLNx6HYOaMkfltsbm2CqBaxhgMcx/VCg4/HSGdui1doGewkEGRaYpHjKLqS+ehePvNiqaloXWZYe30lBr1ZfcYbuc1L8G6V4lF43QHDqfbN50+GaB60hTG/B97Zx0d13E37Ocuo7RiRsuSJVtmZggzMzO1SZM0TcqUQqhN0kDDzOSQg4aYmS3LYmZpmffe74+xVpYlO07epkm+7nOOji3t3QtzZ348M1lGpI4d0FMrokIhv3B4/A7wdhN29+LxycRPOB6mXCUiP/vx9nSy5pUnKZwwmYIZRw2ULYaDIhLZWSGMRVeHiDxGQpA/G0YsFNE2ZytsfAo2P4fs7aXFG88+VzJVriRCsppUg5s0g5sUvQeNSkYxJqEkFmLOKCS3bIzoG5ZUUGRkn5Pliz+hYlsFU8pTmJDuQNtXPUhpo8hRQ52w/2v7bpvPytuNY5AkDenmIO6wRK9Pg6xIWDQBJiW2UJ4RQK+WRXT5QPZHnlBrD7hmMBoNRqUR5QGppSICnlIijO6+BhEZblwn/tWaceYcR3dHF/bmGhwBPRGNmWmJdVhV7uFvHEBSi7FiiAP2W6WRIHJvHX1BIx1BGz2k4XKHcAbUuMM6skxOZiQ3YtMN3zbBiJrVXXls7ctEYbClm6APUJKloWRkKvTU4mhvxhnSE1FUpBtdpBncaFUDewo12EbxQu653NnyOmFnD932EF0BE90BE90BM+6QjrL4TiYltmDUHBDti88RUd/mjcI5KphLMGk0+9atYU+LTJPXhkaKkGlykmuyk2e2k2pwE53CpNLijSthhyuH2k4FqyZACm0kqbrIMjowHXgtgLgsakxzqO5So1d8GGQH6kAfe7rj6XaGkVQGkPQgO5kzMYXJpt1I5iR60haweoeDqq3boqdSqSRMRg2J8QYsJjN6rQF1uAWP04vDE6LDYyCiqMjMTMSQMJ72urX4fV7mpNQxKbGFsKKiJZhCKwVYDRGKNdXow2KJ3WqllI9r0lBpjGSPORZznBajzo860kvDngpamoWxZ9QpJJkVEk0RrHqZWoeVtp4gao0GY5wNd283yWlJTJ+QQU6aAUXSokga/GGFljYnTc29NDf3YI0zs+DY6WTmZYNah8Mv8dYTr+B2OJhzwZV0NWqp3upCkTVEQvUYNHtw90fxD0Ctkiiw2imztFCQ4EcT2W/AZIwnmDuXj9c7qKmoZcTk6XTUVuHu7SFUPh5DVgp51Xtoa+3B5/Wj0WhIzU4nsyCfgsJ0crWtwqhs3oisMaJKHwOpZcgJhWzYUM2atZXExxkYNboQV1CD3emjp7UNv9uFSq0hZ3Q5Wr2e+h1bCQcC6IwmknPLCAYycfWmIkc6kIOfo9VrOeGm2yjITdhvxK4l3FVNryqLbjmZbp+elJwcRo0uRIrszxwdQEunlyXvLsPR3U3R1OPRmqbSus9LwCv6oaJEiAR3EfGvR5EHj/figgSmL5hCSslEUBQifU00793N7l2N7K21I6nU6CwTQAnid27HkpDI7PMvRS0pdOzbRWd9Dc21DcgRmcL8ZMqLbJhTM+lTZ9DnVuhsqKNl724CXu+g65ribdjSMmirrkSRZbSGVFSaOCSpG7/LPuQdHym29AzcPT2EQ0EMlkQMccVYbCbM8Rq0epmepgbaaqtBUdCbzOSOGUfe2AnkjxlLe+0+vnjmCcKBAFNPP5eOuipqNq4jLimJzLws9m7dicFsJav0WHzOFlor1xCXkkbRlOls/eQDTHFJ6KwnEfAlEp9qIjHdRGKmkbbKN6jeuIYFl15N3tiJvP2X3+L1ePhi7rUsdLpIaPqc3pYG4lLSSB8xkuTcPJIyc+io2s3edatx9vQiSRJmWwKWxGSQzPg9TlxdjUTCwsEwWKwkZGSSkJGFSq2mu7Ge7uZG0e9M8RTPOJeknLEEAwFMFiPhoJuOmvU4Oqvoaa4h6PUcsk1VajVxtnj0Fgs6Uxxao5GGHVvRm+MonnkJvW3xIPmxt36Ms2MnlsQMUvKyMVnMaGUPLQ2tdDWLcaszmgj6vKQVFjH11LMwxsVTt3UTtVs20tPcuP96RiR1DpI6hfiUeFLyUkjOjqejtob26gpcvQ2ggFo/lqyyoxk9uwhFUeisd9LR4MLZ7cMcr8doBbXGTevefQQ8zWi0nYSDfSRlj0alHYO9KwkO0EEGM0gqLeGgTDgYQVFAo1eD3Ii3bxly2IVaoyBJMooso9bq0Gi1IGnIKZvCSbfcBMQcmWH5oTgy/XyjlyTLwggMeoRB37QBb816aiob0Mh+jOoAJlUAjVoiqE0goI4nqLYQUJkJSkYCip6Wlh4a2v1oVWHKUz24Iwaqu7TIqEg3uHCHdbjDw2dodBpIMkVI1HkwKi58YTW+iJZARINeHcaiCWLRBPBKVvb0JhKMSKQkGki0GQgFgoSCQeRIhHiTCptFg82qQSt7CDh6CLgcdPlN7HakoVVFmJLUzISEVvTqyEE3YRHRZbUWWragREJ4Izr6ggbsQQN2fSFuTapwAIIepKAbIgFUSgQJkVpt8CTgiwyUdJxY2MIofe2gy9S7bVS5kkkzuMk2OUgwhGh2m9nYk02dZ/hlJM2aACWZavJLinC0NtDe2kWbx4RakimO66YkrosEnR9XSEeFN5cKTw7djgEjTYUcfQ+zUurJswWR9Gb8mLAHjbT44qi3G2nuVQhHFMbYuliYtg9tgSifsFdv4+3NKuxBUSaTZXIxe0SQrASwtzbR5DbT4osjGFEjSxrQ6NFIMinqLtINLtKSzXidDpq9VprVpTT2afB6fGg0apJTsjBb9Hi9dro6egmHI0Oef2JiC3NS6tCoFMKyxJLWEva5UkjRu+kKWLDqI8waY6W0OBVV1IqVDijxMAw4rSAyeXprNCLf3NjOuy9+gEqlR9Gfh6SyUpZVzeS0ZXQ5/Wxqs9LU3IfOaCIlvwCNCtRyAEJefG43Xrcfjy+EXiuRkawnI9VMWooVlQSRcJhIOEzYYydibybi7iGiqNCrwhg1EYzxCYSsedTKI6ltctLT0hy9Ta1WjSJH0Gk1nHjSJHJHjxNRPDlCyO+jtrIeA24RDAj3EfS46LCH6eiL0GEP0+WQCYWFQ6FSq7EkJhGXmIDRoKVuTyVyJMKYWTMZM28u6Ql6JE8XuNupru7gyy+34Xa6KZ87n8yiIpSwmn1bvTh6ulAiNdg7qgZnuQ5ApZJITYnDFG8DQxyS1kQoGKCnuRFP34ATaLBYSM7ORavTUbdzO1qdjvGzpzO2PJe4YBOqrgrorSWYOYNa7QR2baqkafdm5EgIoyWRtJRsjHo3Xd3ddHeL/Uz0RgM5I0eQU1pGZ3sPe1evJBIOYbBmo9YE8PQJI19v0DP/uFmMLs1ACnmQMyayasV2Nr7/NhqdETkSQd4fpZRUiagNE8konoqr24vf8Ql+116Kp89GbzKxa9kXaA16xh19AopsoK/DibPbhbu3h4CnEzncQ39JismWRFJmJin5hWSOmsnGj5w4On0osg+TeRV9rTuJT7DicniQ5QFnUKPXUzxpMkaDls1Ll6M3Z4HmBCTVATJeAr1Rg1YXIBKqA6UVlcqBu7eNgMdNQmYWWaVz6G7OxtUnUz7PS+XqD+lrHehzB2KKTyBr1Bjaqvbg7u1h9PyjGD13IR8/fB/hYJAZ5/yM7ctCeB1BRk1PZ8rJBexe2crWTxswmH0UjFMwmHSo1GLsuXqqqFr/FV6HA51WIiM7jYzRk0kZOYZ1b79Gd1Mj8y+9mgnHnUQkFGLnss/Y8N6buHt7SMzKISlnBM5uC+GgnZCvBXdvE3IkzLhjTmT+JVehUatxud1Y4+Loa2/l838/TNOenZTOnk/50RfR1xZGjsjIssjQ6vTd9DTvpHbzekLBAHnlk1HrR9BabcbVE8KSqGfs/Bza6xxUb9qHTvs57t4WrEnJREIhwsEgIb8fRZEH5IqikDd2AkdffRPxqWkAdDfWs+2zj9nxxSdYk5PJKj2Hup06jHE68soSyR2TRMaIePQmLRqdinAowqaP9rH1swoU2U1qroP2qpUEfT5GTp2JzmiiZvN6/G4Xao0enXkcMhNIH5GB3x2ir70WrXolnj7xXlUaDdbELAzWPHSWCbjtRnzOILY0E2WzMhk1Ix2jVYcsR+hubKC5Yjdag57sUaOxpWfS1+ZlxavbaNy5HknZhyz7UUghOaeQScdPIi7ZRHh/e0RCQcLBIF6HF0eXm4BPi99jwtmjxe9RsKW6MRi7CfpaURQTzt5cgoEUrEkG3H0BUEBv1pA/Jpnc0SYioUaadm2jfvtWXD1d0b5pTc4jLu1ketp0JKSZyCzy0LDtXXpbm8gum4+9ezTBgAYU0GjbkQNL8TrasSSPIRSeR2JmIvljkrB3eulr92Lv9JJZZEWSP6Vm0zq0BiNavR5T4lmEgomEghG0ejVFE5zY27bS09SIvbMdFAVJpSJv7ARKZ82jaMp0Our8rH67ip4W4XQoSpj4ZDcWmx290Y2nr53e1hbkSISE9BxcdjNeVxxq3Ugk6dBVLGqtRFJmAJPVgynOhDHOijnOgtYQIeTvwd7RhqOzg6DXg9/jxWN3o5BAKDQLJCNpBXGoNSpcvT4c7VsJ+/eA5EejDaHIfpJz8yiZPpuR02Zhiotnz8qlbHz/beztbft1iAaTLR+/NwuNPo+0wgKyihORJGjc00tX40AGU6NXk5prIr3QTNnsAuJTvn4uTtAfZufyZrZ+3kjAI+Rlco6F/LHJZI60EZdkwGIzoNYOBKv77f3+yoxwMMKqN6vYvbKV9MI4Zp5RROOeXirWtOGxBygYl8wJ148V8ijmyAzlh+rIeB12ardsJH/cRCwmDax8ANp34OzpZUONQm2fnnSDi3xzH3nmPlxhPdv7MtjnSkFWjrzmwKIJMr4shXGnXYKh9GhQqXB3d7FjyVs07NpJfFo6SfnFJOUWoDcaCfp9BL1efG4XfW0t9DQ30dPcSNDrxWAxYzQZMOjU+AMh3E4PPrcbtUZD8Yw5jD/mBNJGlCBJ0gGG6yGIhMHdQW9LIyvfe5/q7TsBUGs06I169AYDBksc+rgE9CYzCmBva8be1kIwMJAylVQqLAlJSCoJRVFQFAU5IpwYRZZRqVVkl42laMp0cseM4717/0xXfS0X/uFukixA2E/Nzt28/9xrSEhEIsJg7498GK1xTFo4j7EzJqMxxyOrDIQVFc0bPmfvyqXUNXQTkcWzmgxq0nOzCIQUWupETa8tzoDd5QcFMopHMXLqTFJy8kiSujC1LGdPg4+1WztwOdwkpGfi87jxuwY2sEzIzCZ/3AQkScWWjxeTmmLllOy9+N1u3mkoQZbUnHrO0fS0tbJ2zR483jAGHfj3N5HJasFsSwS1BhQJn8uNu/fAmmmB2ZZISv4oVJoiOpsSCAdFZmfyCflMOi4HR1c7iizTXuNk9dvV+Jybifi3kZKZxjHHT2flsk001rYw96SjmXLCSTS1Olnxygt01Fah0etJzskjJa+AxIwsZFkmHAwSDgYG/RsJhVBrtWj1BtQ6LbuWfo7OFE9YPoXSWSPRG7XsXN6MWqeieGo67j4/HbXVuDo3oNa4sSRo0OjEezdahcFuttnwOhy0VVdGBf83QaVWk1FURlxaKUZrDjpTIpLaTCTQTdX657C3tTL7/EvIGzuBnV9+yu4VywgHfcOeS6PTY7BkoNano9akISspICWgN+nQm7QYzBrSC7Q42lewc+lnyJEwKrUavdmCVm/A2dVBcm4+R199E+lFJexc1sy692tBUUjMMNPZ4EKR3ZisbQR8EuGgGUklskFqdQfJWW7kcDtBvxdFlgmHZCRJTUp+HmkFBaTk5JGcm485IRGvM0hvmwet1sGmD96gct0qUBRUag3xqakYrfG011QhR8IgmVBri1Dry5DUGVHlVTAumTFzE/DYa2ncuZ2GHdtw9XQiqbSodWWodOMxxafjd4compRA8WQ1Gxa/QnPFLvLHT2LO+Zey4sVnaNy1DY1hLGrDfAxmAwaLGr0xQk5ZJqOmZ2JLM9G0t5f3/7kVW/JeOqo/RVKpGHfMCdgy5rL1sy78HhF5NcfrSM2PIyHdjC3NQMjvYvOnHXidEcrnZWNNNLBucQ2mOB3zLxpFw84edixrQqerQKdvQK1Nx+NMJhxOQ4n0oJIqCHn3Egn70RhGY7Qdw8wzR1E8NQ1Hp4/eNg/2Ti8Bd4iAL0zAG6a9zkHAEyY+1ciICXE07vHQ3eTGlmZCkRV87hCn/mwczo4K3L09hEMye1a3YW8PImkykFQ2JEkiY4SRhJQ9bPvsfeRIBHNCIrPOvY1Vb/WSkG5m/oUlpBcOzO9pr3Pw5XMV2DsGR/d1BjXjj8rCltpL/fYNtFVV0t3YgKLIaPVGyo+6CoVcnD0+iqekM2pGOooixnB7nY/PnxYlfHqTBme3H0UJEwmsIezbRGpBEafcehden4+dn7zPruVfoNHqWHTl9WhNo/ny2QrhwByE0aolrzyZSEimZmsnclghoyiesQtyKByfjEqtIhKW+eTfO6nb0U72yBoMpiBqrRZJ0hD0q3B0G+hpNYIUjxLehRxaDShMOPYkWvbuoXVfBWqNhtHzjkKtn0PF2h7GHZXDrDOKkA6jv5zdPla/VU3tti7SCvQkZVSza+lHSJJEzphJOLozcPamkjEiiSknFZBTmkgoEGHNOzXsWtGE0dyJpDbidVqQJDU6g5qEDDMJGWbikgw07emlrcaBSi2ROzqJhDQT1iQD1kQDXmeQjjoH7XVOets86AwaJp+Qz9j52bjcLmo32Nn0cT3hkIwlQY8pTiecoYhCV5MLn3O/YpAgIc1Eco4Vg1lLy74+elsHsgrZoxKYdFweWSUJ+D0hmiv6aNjdQ/2ObgLesHBqypMJBcL0NDdjb9tLJCKh1pWTlh9PVkkCLZV9dDa4UOtUmCwSrt4IuWWJzDprJAFviE1LGmjY1YkS6UJvzmTaKSMYMz8L9QGLt1Sub+eLZ/dQNCWJoPNjupsaSSk4n8Y9YU6+eTymOB1Ln6+gs8FFco4FryOIx+FBifQiqazoTVZS8qyAREtlH3HJBmacXkRihpn6nd3Ube+mvc6BJEkUTUxh3CLRz1e8UoksK8w9r5jCcSlIamHTuFwuTAYz4ZBMKBChu8lFyz47rVV9UQfpQPQmDSm5VuJTjLTXOulpERk9S4KekunpjJqRgS11oAxVkRXaauzsXN5C7dYuZEUhNddKVnECmcU2Mots6IwaZDlC7ZZNhIMhqjbraNztZvIJ+Uw8Lg+tbnA5s9cZpL3WgTXJQFKmGdW3XBwn6AvTXNlHSq4Va+K3W6q/alMHy17aS8gfAQlyy5IYPTuTvLFJ0fcec2SG4YfqyKx+/UXWvfO6EH5WDyWmFtqkfPa0a0GC/Cwrnb0B3AfUOeqNJsrmL6J8wTGotVq8Djtep4NwMIjBbEFnNKIzmgbmoBiMSBL0tPlp2tNLa7WdnNJEyudn/ceWfgyHQiiRCFqDgd5WD4sf3Eo4KJM50kZ2SQIpuRY8jiDObh/OLh9yREFn1GDW9JLteBvb6XeiS0iidV8FTbt3EvB5CXjcBDweAl4P/v3/VxQZW1oGtvRMkQJOz8SWkUlccuqQeTYHDgRFVuhr99JWY6e9xoHW6Gf3lw9gMFu48C8P0LJ3D4vv+zMpeQWc+as/4XU4aK7YRVtVJSl5BYyZfxQanVgqczjlFvB6aNu3l8TsHFSaOGq3dhPwhjBZg9g7dtBevYuUvCLSRkwlHLQQ8IWxpZpISDcRl2JErVYRDoXY+eUn1G3bjDUpWTxnWgZphUXEpaQSCkRo2tNLJFTLp489gCRJyHIEvdnCmXf9kaRssfZ9KOBn26cf0d1YT2ZJGTmjy7GlZ9JW5WD3yhZqtnUhhxUU2Y9a04Pe2ItKbUCWM/G5TYCEWquiaFIqpTMzqFzXTsWaNkZMTGXRpaVsX9rE+vdrSco0gwq66ndA6EuCPjeSSsWx191M2ZyFBHxhDGYtiixTvXk9zXt20dVQR1dDHX73QHRIrdWi0enQ6PRodDrUGi2RUJBQIEDI78eanInPdwxZJVmc9JNxqNUq+to9rHmnhqaKXmypRhIzLcSnGKnZ0klfu5eUXCuTT8gnvTAeo3VgmV+vM0jDzmZqt1bQWuPA75JRqTRo9FqCfpAkNeYEExYbaHVBVJoASgScvUk4u+VB71yllpAjClnFZlTKUqo2rN7/dy2SeiSmxLEE3DKpBTpKptrQGfVEIkls+LCPkF8hOceCwaLFaNai1qqiBq67L0BfmwdrooExc+PwuHYS8ftxdNpx9zowxmWTnDebcEihq9FFd5Ob3NGJzDu/hLhkI85uH1WbOmjY1UNcspGs4gSySmwEfRHWL66hfmcPpjgdBosWe4cXOdIfNYOkbAuZRTZCwQit++w4uoQzptGrGTEhhYwRCq6uGtqqG+ltacXd14NCGtaUMiafMIPiaRlotGokCULBCLtWtLDtiyaCvjCpeVZcvX58rhBKxInOZKZ0Zh6j52YRl2xg85IGtnzSgN6sYdyibPpa1rF7+VuEgwEkSYPauJCS6QuYd2EJRsuh9wja9HE969+vZcLRJgonZLPxox4ad/eQVZLAqOnpZBTZiEs2DJF9vV12di3tZOfyZlCEA7bw4lIMFpHFba7sY+kLFbh6/OhNGvLKkygYm0LAG6JhVw+NFZ2EfL2MmDSKeeeVYLYdfg5iOBiheksnu1a00FHnxJpkYOpJBRRPTcPjCPLOvZuJRBTOuH0iKPDRoztwdvuYdVYR1iQjfncQZ4+fLZ82EJ9sZPbZydRuXkZmyTyWvdSKLd3EaT+bgN40dGGBcChCd5M7mrQLhyLsXNZM3fZujFYto+dk4bYH6Kjroae5DkmKQ1IJY7e/39jSTEw9uQBXj5+179WQlGXhhOvKiUs2EvCF6WlxU7Gmjd0rVhLyfIJGq0aWQ0jA2KOPZ9pp59C4x8+yFytIHxHPMVeOQWtQo1JJhIMRmip6qd/RTcNukSUsmZ7O6DmZJGUOnfcTDkX4+NEdNO3tIyHNhLsvQCggglFGq5ZRMzIoGJfCJ//eiVrjwWRZQ8P2zSRkZFK+6DhGz1nI+o/a2bOylQnH5DLj9BFHrBsr17Wx/NV9aLQqFl5SjMceYM3bdajUEnPPL2bk5LQh52rY1cOGD2ox2/RklSSQXZJAYoZ5iG7paXVTsaqN+l3duHr9yOEB+0lv0pBWEE/GiDhGz82Kjol+vedxBNi5vBlXjx+vM4jPJZz4lBwLKXlWUnKsJGVb0BkG602PI0BrlZ34FCOpecOvOhkJyTRW9FK1sYOmPb0YLFriU4zEpxhJyraQNzppUP/vqHeya0Uzji4fE4/NI2/M4H3TOhuctFTaKZ6Whjl++HHTP64nn5CP0apl5etVTDulkMkn5AMgR2S2fdlE/Y5u4lOMJGSYSUw343MH6ax30dngxOsMMnZBDmMXZA/KHIBwTHcub2bPqlaCftF30griOPqKMuJTBs91O5yRHQnJ+L0hAp4wfk8Ie4eXzgYnnQ0u7J1eUvOs5JYlkVOWSHKW5bDOMoDHHqBiTRuNe3roqHMiRxRUKomMkTbyy5PIHpXAqjeqaNlnZ/Y5Ixm38MexB46jy0tTRR95Y5KGdYhijsww/FAdmffv/QPtuzcz2lzHXnc2dr8ajVZH+aJjGXvUKXTUy4yckoaru42GnVvRGYyUzJiD1iBevCIr1GztYuNHdURCMqfdOgFLwuBOUbm+nTXvVON1CGfIFK/D6whSOiuDeeeXoNaIAe3s9rHhgzp62zxodCo0WhVag4bEDDMpuVZScq1YEg6/7r2z28c7925GUSB/bDItlX1RY6gfo1UYblp/OyeYfoVN08amyJVkXvIbMkeKZVkVRaFhVw97VrUSl2KkYGwyGSPih40i+NxB6nd009XgwmDRYorXY47XYe9x4+kO093iprvJFa111hnUBP0RRk0Ls/3Tf5FZUkp7zT6SsnM5/qbf0rjbTW+rh55WN31tXiLhAQNWrVWRPSqB/PJk8sYkYbRq8dgDeOwBetu8VG/upHVf35CqHo1eTTgwtCwLRKlPYpaZtIJ40vLjyBwZP0Rw9rZ5+OSJXfS1ecgqtjHjtGQ++/f9KIrM6Xf+Dq9Tx4YP6gh4Q8gRRfzICoqsIEdE1MjnCqEzaiiZnk7+mCSc3T56WsRzqtQS1gQDliQD8SlG8suTMZi10Xex7fMm1rxbjd6kIeAJM3JKGgsuGoXD7uTLp6robekkPb+Csrlz8bkz2LmiBWeXj7hkA+kj4skojCcckulscNHV6MTZ5SA+zUpqbjwpufHEpxoxxekwxenQm7UEfWG8ziCuHj9LX6zAZNVx5h2ThhhlBy8oIMsK+za0s/HDOpzdYn6JzqjBlmok4A1H+6JaoyKnLJERE1LIH5uM3qihp9VDy74+2qoduPv8+FxBvM4gKJBZbCOnNJGc0kTheGpUqFQSe1a3suylvWQV2xgxvg9Hp509q81YkxM44+eT2LumjVVvVZGaayW9MJ4dy5pJzDRzzJWjScoafrEHRVFoquhl/eJaOhtc6Ixqgr7BfUerFxFcg0XHxONyhzWWDkVrtZ0tnzYgAYmZFpKyzBjMWtrrnLRW2emodaDWqsgospE50oYtzUT99i6qN3dGFTyAwawloyieUTMyyB+bfMjsa8AbYvvSZpr29GJLN5GcZSE520JqQdyQqGF3s5tlL+2ls15kI+WInUhgMwbLWBZcMpfiaelf+5yKrPDRoztoquhFZ9AQCkaYcfoIRs/NQHOYRUX6ZXJHnRNnj4+iSalDrhX0h+lr95KcY0GtVhEIBIhEIhgMBpQIuO2BIyrTOBh3nx+jVReVxSDG/Lv3bUGjVxHyR5AkieOvKydzpG3Qd1v29fHxYzvR6FTMOH0EX722D4tNz+m3TcRoPbJNYftpr3Ww9t0aWqvsGK3aqNxPzY0jJU/If4C67d2sf782Gr0vmpzKwotL0eqHLmrR1ehi+Uvrad79NmpdAiOmnEDpjBJcfX5WvVFFTlkix19XPqQv9CNHZBQYFKEfjlAwwqo3qvC5gtHMRXyqidzSxKjR2lLZx+J/bqVwQgozz0jHmpSMo9PH6rerqd/RzaTj85h2SuE3DvD1tXv49Mld0Wh8VrGNRZeVfeuI9XAosoLXJWSiwawlPtU47H1+3wbgd4WiKCx/aS97VrchqSRyRydy4vVjv9YR+KYE/WEq17WjKAqj52YN2+++rzYOBSN01Dpoquijfmd3dPypVBILLy2lZNp/aRn0/wLfdz+OOTJHQP9Lev66s4kLtXD6paejzPgpXS0tmG0JmOJtfPLELmq3dpGQYebYq0cPikTJskLdNuHA9LR4SEg34bYHMMcLBWaKEwps98oWlr9cSXphHGWzM8kpTcQcr2f9B7VsXtJAVrGNhZeWsmdlK9u+aEKShNEWCcuEg7Iw/jq9UcNcpZJQaSRUahVqrYr88iTGL8olMdOMxxHgnfu24PG6GHdKAjkjMsjKysLdF6C3zYPFpseaZBARIHsjPHcSiq+PiDYBp0vNq533M/6oXLKKbWz6uJ6OOifGOJ0wzsMKepOGjCIbBosWnUGNRqemvcZBW7UdRRHGXeggZ0GjVZGYaSY52yIM6hE24lOMfP7Mbqo2dVJQ3kDFV2+Tkl/IzHNuZ/kr9QQ8Ycw2PUlZZhIzzOhNA8aP1xGkYXdP1Eg+mPhUIyOnpDFyUhrWJAM9LW66m930tnkwx+tIyrSQmGlGZ9Tg6PTR1+Ghr21/xKbeGTUUM0faGDMvi8LxKVRv7mT5y3vR6tWMmZXK5i9asSQYOPGGcqwJejZ+1MC2LxoxWnUkZVvEO9qfAu9PhavUElnFCYyYlDrEYPD5fKjVanS6wxs9dTu6Wfn6PsYuyGbcohwkSaTYNeh59/4tuHpF6Vw4JJNRFE9uWRLdTS5aaxzRUgZLgp6UXCtxSUb6Orx0N7mEs3AYjFYtZ94xeYiBGAwG8fl8xMcPXRY3EpZp2ddHX7sXR4eXcNse9JogxlHTyRhhIzXXOiQidygUWTmssty7to0vX6gga6QNR5cPWVY46xeTo0ZM7bYuPn9mN+GgTPn8bGaeMQLNIYy2QddVFOq2dbNvUyvJWfEkZBpxRbqITzCTl5+HSjX4/n0+H01NTbS1tdHe3k5XVxdxcXFkZGSQnp5ORkYGiYmJQ753MHJEjmYee3p6qK2txev14vV46W5zoJF0jJ0whtKxRcMGFsLhMJ2dnXR1dZGRkUFqauohn6+zs5O6ujq6u7spKyujoKAAAL87hL3Th6PLi9cRpGhyKnFJxuj5HQ4Hdrudvr6+Qf8Gg0FycnLIzsxlx2I7kj5E0pgwdU3V9Pb2Mm/ePObOnTukDfr6+ggGg6SmDnVeDn62hoYG6urqqKuro7W1NVoHrtfrsVgslJaWMmHCBJKSvtkGin6/n3379lFRUUFHRwd6vR4VGnoa/Jh1CZx0wVwK9m9YKssyra2t7N27F41GQ176SFY8V4/HHsCaZOCM2ycOCWgdCYqi0NHRQUdbF6PLS4d1/Pr6+rBYLKjVGqo3dRAKRCibnXnYdlMUhaY9vexZ20JzhT1aY58/Npnjrh5DIORHkiSMxq93Ant6enA6nfj9fvx+P1qtluLi4sPKr7a2Nr788kt8Ph+akIWeKpmx00fgdQWo290BmggF45IpGp+B0WjEaDSSlJSEXj84OyDLMn19fRiNRkymwcGmcDDCxo/qMMXpGbsge5DMiEQiOJ1OFEUhLi5uULvKsozL5cLv92MwGDAYDOh0OmRZjj6jx+PBbrdHfxRFiR6r1w8OLqpUKgoKCqJj3ePxUFlZSUVFBX6/n/LycsrLywe1tc/no6ura9BYCoUGVtjS6XRMnjyZzP/QJt797eh2u/H7/fh8PiKRCCkpKaSnp0ffZSAQoL29nZ6eHhISEkhNSWX5CzXYO7ycecckDGYtsizT3t4eHZMej4cxY8YwduzYIzKEZVmms7OTtrY20tLSSE9PHyoj5QhIKmRFwe12Y7fbyc7O/lpZ+l3j6PLRVNFLUpaFjBH79WDA/d9dEbVhjZi/PfLo/+hpY47MMPwQHRmz2cRDF57C+ByZ+fcsGfT57lXNfPbGBmwjZPo6PcghmdwxSaTnJOFt19C2w4+3L4ItzcSUk/IpmpRGe42DDx7aRnyqidNunUDVxg6+em0feWOSOO7aMWi0g42nynVtLH1pbzRdXTwtjWmnFKDSDxagra1tNNU109HZAYqKnMRiMqw55LQ/w9bG0bT584kvDtPtbMUd6SaiHsjApKSkMHHiRMrLy7FY9g+u3jp4/hQIOODid6F5Eyy5g415r7JhvVC+lkQ9YxamEjR1Y7HEofZZaatw09nowufz4Qx34FN1YzHZGF8+gZJJ2aTkWpFlBZ8ziMcRJBTxk1mQQmdnBzU1NdhsNjIyMkhISCASlln8j610NrqYdEwYpGw2ftyKOR0mnpRJckY8BoMBo9GIwTC4DEVRFOwdXnZvrCUYCJGekYo10bQ/AmgkEonQ1dVFOBzGZrNhsViQJDF3x+fzRRVReno66gM2RW1saGTF8lU0NjUghbQQ0KOTjOA3kJ6ezhnTqjGt/A194+7gtdWj8ONCp9cQ7jFRPn0Es84aid4oFKQsy4MUkSRJaLWDd1IPBAKsWrWKNWvWoNFomDx5MlOnTo06BuFwmK6uLrRaLcnJgzcXO7AfW61WPPYAnz29G1uaifL5WSRnDwggRVFw9fjR6NRRB/tAPI4Arh4/boefXRXbqGrcTXpSNuPHTCEpRZRcGMxaIpEITU1N1NbWUldXR0tLC7Isk52dzcSJExk9evQQwwMQG3Q9OA7J3QHZU2DGjTDqZFBr6OjoYNu2bTgcDtLS0sjIyCAjI+OIFaDH46G9vZ2dG6qo3FmHGh0nnbOAsomD94nqbfPgdwfJHJmA1+uls7OTcDh8iDODVquNGiq9vb1UVVWxfft2PB4RgbPZbIwfP55Ro0bR1NRERUUF9fX10QnoiYmJpKSk4HQ66ezsjM750mq1pKenk56eTjgcjhpGfr+flJSUqNNjt9upqKigs7NzyD15PGKiu8VioaSkBI1GEzVGHA4HXV1dgybCFxUVMXPmTAoKCujt7Y0aHPX19dHnUavVRCIR0tPTmTFjBiUlJQMTRMNhmpqaqK+vp66ujo6OwXO7VCoV8fHxJCQkoFaraWxsJBAYWJFKkiRmp3kYZ/+MF/0LSR4xgTPOOAOz2UxTUxNLly6lrq4u+owJCQkkJyeTn59PQUEBycnJdHZ2snXrVnbs2IHX60WlUpGdnc0c9TbUJhsNSfPwB4L09PRQU1ODoijk5eWRmZlJIBDA5/MRCAQ4lP4Lh8PR/myxWMjNzSUcDuPz+fC4PfTuX4QhOTmZrKwsamtrcblcqFSqaFvn5uRhDKWRnGegz9VNW1sbLtfgPUJ0Ol1UrplMJmw2Gzabjfj4eNra2qioqKC3V1wrMzOTM844Izr2nU4nS5YsoaKiAkmSSE5OJiMjg6SkpKicPPCn3yE40Gh3uVyYTWZaq+w4ur1IiS62bdtKVVUVAAUFBZSWllJSUkJc3OCyptbWVpYtWxY99uDnKi8vZ8KECWRmZkYNTLfbzbJly9i8eTMmk4nU1FTa2toG9Y/DkZSURHp6Okajkfb2djo6OqJyNT4+Puqom0ym6HMHAoGoM9DvGPQ7Mf3ExcURFxeHx+PB4XAMGi9AVF8Mh9lsRqVS4ff7B8n4g+nvy11dXSiKgs1mQ6/X09HRgVqtZtSoUVEnoK+vb8g1DpSlHo+HQCBASUkJCxYsID1dRP4VRcHv99PR0RENoDidzkHn6u9zBoMBRVFob2+nvb2dYPDQAaz+IEBPT8+Qz2w2G1arNWqj+Hy+qCxNSkrCYDDQ0tKCJEkUFxeTkJAQPTYUCqHX66P3Y7fbqaurw+cbsFkMBgN5eXkkJSURCASQHE0cXftH1HIIF2ZcmOgjngZ1Ia7Uqdiyi6P9bjjC4TDNzc3U1dXR1taGyWQiISEBm82GyWSKyjlJksjJyTmsQx6JRKivr6ehoQGfz4fP58Pv90fle4avkqPaH+OL9OtoM44ChC6YNm3aIQNKsizjdDqx2+3RYILBYEClUuFwOKJ92ePxDGpHq9VKqWctI6ueQFIitJVcSn3eeQSCQbRabfQ8FouFtLS04XXzYYg5MsPwQ3RkZEcXT95+M6VTRpJ91KWA6FTV+2qp2L0XWXWAIYpCIn1EUGNHTNyNs9goKi5kVJJEft8qtFoNNbaL+OjVfWgtEfyuMBkFScw9sxSdQRvthAf+dLfZaWvoQWON4PW7cDgcgwSohjBhNCQmJkYNnNbWVmZoKzg29AkhSc/rnEK1ko0kq8nJzqW0vJjc3Fza2trYunUrLS1iyUCTyUSpqY+j7S+hQmbHuD8SThmNVeWnbMkZBCZdS9eI22lt6aDVtY9du3ZGByhAeno6JpMparCZTCa8Xi8ajYZx48YxadIkDP0ld4rCnj172LNnD21tgyd36/V6EhMT0Wn1dNf7iAQhrPIh6z3IytDyr9TUVCZMmMDYsWMxmUzU1NSwdu1aGmoqkVEhqbWkpqaSmJhIT08PnZ2dg1c00mjEwg5e7yAFqtPpyMvLIzs7m6qqKpqbmzEYDIwaNQqv10tXRw8OpwNZCVNEPRfwHgHJgFHxsZaJfMbc6NK7/cZPMBgUSqmvnji5jzpyo9eLj4+noKCA/Px8ZFlm6dKluN1uysvLUYW8tO9dT6LkICstmV3yCDq7e6PPkZycTGlpKUVFRbjdbtrb26OGUr8SL/JtRVU4l+zSKSQnJyNJEg6Hg71791JZWYlKpYoayunp6dhstqgj19nZyfvvv09zczPp6el0dnaiUqmYMmUKeXl5VFZWsnfvXvD1oSdIWloa2bl5qMxJbN1VSXd3N1qtlvz8/Gj2wWq10tzcjHbLM0zueoP1qsmMkuqIj/TgN6TxvvVi9nRFoobwgco8NTWV0tJSSktLSUpKiiqi+vr6aDT4YMPUYo7D5/dEDfLy8nLUanV0rPX19dHe3o7DMbDJ2pGiUqkoLhYKMxAIsHXr1qjxDUJZlZWVUVRURHp6enQcwIBD2v/O+g0yjUaDzWYjISEhauD0G2qSJJGbm0tpaSnFxcXEx8dH31V/5mDv3r1UV1cjSVLUMLBaraSnp5OZaCbTtY29/mRW7hAOi16vj/Z/q9VKQUFBtD9aLBZ27tzJ2rVr6erqYji0ahUnW3eRH6khbBsB6WPQ5U7GVHo0Ks1AyWEkEqG9vZ2GhgZMJhOjNM0Y3r0cIkHaC8/iyYZ8zGYzqampVFdXYzKZmDFjBrIs4/P5hrwng8GA3+9HpVIxatQoxo0bR35+PnpnAzwyRVy0YC6c8i9IyMPpdLJ9+3aqNi2j2x1GZYzDaDQOiZwfiCRJZGVlUVpaSrZnB6rKj+HoP0U3qHQ6nezdu5eKigra2trIz8+PvptgMMi2bdvYunUrdrsdgISEBDIyMrDZbNFrKopCMBiMGn/9UX6/3x/tY/2OhFar5ZNPPiEcDnNZQQfqsJeXmnPwy2pmzpwJMEgGHAqNRkNRUVH0Xvv6+ujs7KS+vp6qqio8Hg8Wi4Vx48YhSRIVFRVR47XfUUhPT6ejo4OKigoMBgMzZswgNzc32uccDgdbt25lz549UcO+31jtN3KnTp3KvLlzMZpMIuvU2sXm5ZXklaWQnGGLBqv6x6rX66WjoyP6jH6/PxroSEtLw+v1Rj8bztgGIZP7Ddb+fyVJijo4TqdzkFHb7wT134NGo4k+Y7/TGR8fP8jQDYfDBIPBqBzSbHoSt72HxtwzovfW36/S00VZZr9e3rVrF3q9PtrGaWlpJCYmDrkGiDG/bt06tqxZRn5wL7Ilg1o5E7/fP0jXWSyWQX0OGNTntLKfxLRs0jOzojqg/xlVKtWgNpckKXpvycnJ9PX1ReWXx+MZFGjMyMggPz8/6vx2dXWxfdM64rY8Qo2STZupDIPBgFarHdTGJpMpKocyMjLo6OiIBlpcLhcGg4EzQ2+RE6qlNmEecSofZsWNwVWPLijGWruUxldMJX3BNcyePTvqRLe3t7NixQqqqqoIh8NR59/n8+F2D79cv8FgYPLkyUybNg2r1YqiKNHn3rdvH5WVlfj9/kEy12AwiGCBonBy50OkBhvo0WawOO02FElFW1sb4XCYoqIipk6dSiQSGZS1H86RHo4Dg2satYqJPe8xJbSOfRTgxch49rCDUSzmaCIMzeT2BwWSk5OjAZR+vdN/P7m5uRx11FFAzJEZlh+iI9O98g1e/nwb4fjBJQgqNOiDSRx3/CjGuD9H3b4NpW27WFIYCBpS6Y0voy1iI6VnI9lKCxFUSCg4sfAex1LPkU34UqvVmEymaESzP4NgNBpJ7NtG5le3Ez7hAXSTLgL2lwjU7CXl1WPoiZjQqWSSlR7aZ96NZeKlxCUN3Xywo6ODfZWV2Pa9zujmV3CoEnhTfRqtoYGI24W8Syo9PChdjawoaDQaJkyYwNSpU/F6vYMiuMXFxZSWlpKZmUl3dzfr1q1j+/btKJEgMoOzTmlpaUyYMIGysjLcbjdtbW20tbVFFbjH7cNl9xBvjWfMCCul3vXEuyqJKBBRVIRl6PBCo0dHn5SI1mwjyV3BSFULmUorYUMS1RmnslkeRY/dTWJiYjSqr9PphiitfqUmy3I0wtzd3U1CQgLTp09n/PjxgyIXiqLgqlqL+Y0z8erTWJp3G5Mcn5Ld8gHBkSfgXHQ/DS1t1NXV0dzcjNFoJN/gZEHTg+jCLqpLb6Ij+4RoKUp9fX00+pSVlcVxxx5DzopboGbpoHart0ykZtydpGVk4fV6oxH//vGrUqlISUnBZDIRDoeJd1Vxlv0xtjCa9zkGi8WCxWKhvb0dgKNNFfRq09niTBy0JGNcXBzx8fE0Nzej1+s5/vjjKS8vp6+vjxUrVrBjxw4URSFRF+Ikyy4K+lYiHehsWtJQrltFc1+Abdu20dTUFI1AAqgJ8zPpeQLmdDaU/YH2tlYsbas5MfwxTk0K9Yv+TfnY8ZjN5mhksaWlhcrKShobG6NzcPr/zcjIIDk5eZCB0V+OYDQa8fl87Ny5k61btw5yoHU6HVarlYyMDLJSEyhtfRN/yRmEkgf2AjrwnYdCoUEBh3Hjxg1kNPfT19dHbW0tOTk5pCTakFY9ANVf7N900iWWIi89BebdIfZ7OQJkWaa3tzcaSRtC0Cv2jDl4Z3PxZWhYBVtehIr3IexHic8mcsnH7GzspaGhgezsbPLz80lKShrWqJdlmdra2kFZF5VKRXa8huy1v0FqWit2inc0i/2QAMaeC6f/e9gNeKlZBq+cCynFYM2ExnW0XfAlr7/7EX6/n1mzZjF16lT0ev3gxUH2GxD94yotLY3y8nLMZvPAuT+6XWwCuvA3sOLv4m+zbhb3VrdC7H9lToWL3ha7mh8Jm5+HD28R+ywlFsKFb4nNNg9sY0+X2M9rmLbr7u4mLi5ukCP7dfRn0uLj4weVGzmdTla+9k9ObL1f/K5JRjntceLHDC4hCYfDwwbJfD4fnZ2d7N27F5fLNSjLYDQaKSwsZOzYsRQVFUWdZEVR6OrqoqqqitbW1mhZkU6nY8aMGcyYMeOQz+b3+9m7dy92uz0aqdYqQeZk+Ilv+QqqPhN7Zp3+uNgrajhCPrEBaO1ymPVTSMj/2vY7sASsv9TNZrOh1Q5dZOFb4WwT+6SNPEbs5n4otrwA7/9E/P/UR2DCRYM/DwfFNg6m4bcRGIKiiL3Q+urEHm0VH6DUrkCSQ8io2Fp4I/asBRiNxmhJ2CENT0cLfPBTIZ9AbHRrTIC0MVB8HBQfK/YhG46eGlj7Lxhzptj77EhwtsFr50PrVnGdGzeKjYy/KXs/Fuc5+o9ibO/H5XRg9dRD9RfIO95E1VXBl8ykPvtM5i9YwJYtW9i9ezd6vZ5x48ZRWFhIXl4eRoMBJIlQKDQoiACi/27ZsoWKigpUKlXUvuk/xmAwUFJSwsTkANmeHagX/WbwxsXVX8JLZ0DRUaKdT3scxp+P1+tl06ZNrF+/PpoB73eq0tLSonafzWaL3kd/qV98fHz0s+i48zth8Q1Q8QGRSVfQO/UOQmEZ265nMK29DyVnOsFTn8Cnicfv9+NwOAYF0RwOBzalj3msp4h63JhxSDZC5gy0RfMoOe120cYxR2YoP0RHZtMTv2KFM4GJY8cwe8EiwuEIO75sZu+KHo6/IIURO64SZViZ4yFzAmSMh5BX7ARevwo8XSjJxThHnMpe/XiU3nrG1T6KwduKq+wSgkXHEIgoBEIKAY0VTUL24PS/Vo1234diw79FvwWjbeAGg154dLrYCFBnhetXDQj15X+H5X/Bf9FH6DJHo3rtfHGO2beA1iwUrbdH7A9iTRObJTZtgF1vQckJQpEY4olEIgQCAbxeL5Ftr5G26ldsKv8j/rRJTJw4cXANsrcXNj0tNm489i8H7TwOgS/+gm71fbhSJmHPWogjYzbGxAxGjDj86jOKorBj7WeMbnwZTeWHwoDIHC82MezfAd3RIsrg+r+DBJnjkfLniOdu3gBx2TDnVph4qVji+Bvg8/lEPbxKJZSHqw3UelHn6u2FpxaJv1/9JcTtT1+vfQQ+/aVQBMf8GUYsEH9v2ggvnSkMzeRiqPkSTvoH+3LOJi/JhFYl0dnZicfjoaCgANWe9+Cty2HqNZA3U2wOWrscvvwDjDlLGIj7n8fj8dDY2Eh8fDwpKSlotdoBYfPm5bD7HRStiW1HvUFtcydOp5OioiJGpxtIfPkoMNgIXbuGTq9wbg8svUhOTuaoo44ShqKiiJpbvwN7ez3Krnew7X0FKRIUu45nThTvKeSFT+6CqVfD8X+PtmcoFKKzsxOHw0FBzzKMX/5SlDCOWAgIwyO46SUMH/8EjvsbTL9+2PfidruprKykr6+PnJwc8vLyjtxAVBQ8NWuR0svRG02DSgh570bY9pLYKPWaZQPvdDgczfh3foBh9AmQkDfMZRSknhp45yqhtHOmC4PAECc2Pd39rjhw8pUw8yaIyxre4D+Az/d0kBFvYEzWQXOP/E545ljwdMNlHwnnoJ9wAN66AvZ+SFBjZYV+Pu/b87nP8Ax6WwZcvuTQhsrXUfcVvHWlMMJOfhDGniP+7umGNQ/B6gfhtMdg/AWDv1e/Cl46SzgEl34AvTXw9NFwwn00Fp4nyr9S4kRfW3k/QVcPOkuiGHeZEwfG1HD4HXB/KZSdCqc/Jub8Lb5R3Ks+ThhcuTNg/eOi3c5/RWRtDseqf8IXv4OiowhOvQHde1eLfn7eK2Kz1m2vwIYnhWFZuADm3wm504+8HWUZvklNv6KgPHMs4c59NE34BQUVjyA5W2D2z2D+L4fKOXsTvH6RcNqm3xDdsFeWZVqb6unYsoSAKYPCcTMxxyeytLKLE8oz0MpB2PE6oAjH+yBDOxAIIEmSyBK0boNld8PES6D05MHXdzTDu9dBb62Q3XJYtL0cAlMSnWlzSGz7Ck3YKwzTKVeL9nB3Cp1auUQYrsH9GaYxZ8FZTx95e30XuDvh2eOhp1r8njsDys8SRr0xYeC4upXw4mlQMI9wKICmZSNcsQSyJonPe+vg1fOF83/daojPOvQ123fCF38QOvsAvUdCvng/xcfB0j9B03o4/QkYe/awp5Flhb8vqSC/5T1Ob/8XKiJUF1xMaXYikt8hxm/jWrFRM4iy3ylXw5gzxH5xigJbnkdZchdSWCwVvsU0m3eSrmbEqHFcPqtg+Ptv3Sqe1e+Ehb8WY6r0FLqOfZQ3NjVxzdxCtEey9HDQA49MF3uDXbdS3NN+BhnZ4YBwIHe8zg7VGBbLC4jTKhyX46MosBO1vX5g42dFhrxZou+OOnFY2d/b28u6detob28nNTU1WmGQnpKEeuU9sOof4jwTL4FTHhZfUhQhmx3NKD/ZjPTMccIGu2kTaIXOCofD1NTUYDabSUtL++aOtqLArrfh01+JDdCP/YvQnQfqk13vwHvXg0or2n7KVYPlRF898or7kLa/gqLS4Mqai1EKo/W2Idkbxbs/9ZGhbfw9EHNkjgCXy8Xrf7+NDFU7s8uKqfQtYvsOM0FfmLGTFOZ4bxMOwYVvCgPzYBRFdCZL2uCOFPTAZ78RRv/BpJaJyEfRUWI37vVPgKtVfDZiIVzw5kCn+/x3sPqfwqtfcodQSpd9LHZNf2iCOP7cF8WxIR+h1y9DW/2J+F0fL5RR2C8EsRIBJFjwK5hz2/DKNOiBe0cKIX3KQwN/76uHtY/C1heF4Qri/s97RWymCCIC/P5NkDtTCEV7A6h1BCdcge7Evx3acFMU1j13J9MbHscjWTBMuwz11KsgsWDIcXh7RGTIbxcCt1/ZKgrULCX45V/QtW0inFKG5uR/HNrAUBTY/By0bBbtEZcx8JmnB967TkQOD0RngSs+gfTywX+vXCLejb0RRiwSQmDJL8Qu8pe+L/rG6xdD1afcFboS7dQr+OOpYwa+L0fg0Rmifa5fI3a576ffqCo/RzieqsGZrn5cLhfWiB0eHCf6af1KUWIz8eKBg5b8AjY+La5TejKc9czQE8myMCa2vQx73ofQQWvxjzkLFv5KGKUH8v5PYNur8JPNQw39SAgemigM6Ku+GNwPFAVeOUcYuzesPaLI6xDCAejYJYzeg/vYygf2O4Nn7ncG9yuNba+KdzzuApG1SB4pxpVuaCaTmmXCOfD1ApIYc5Mug6yJEPKxtaaNzz9dzK3Sy2i0ejFuyk4dfA57I6y4RxjBSkQ4yNZ04dDMuBFKTzqgSRT++UUVz3y5nazkOD6+9ZiBlcjkCLx2oeibRptQVJd/LLIFIT+8cQlUfcp9kfN5MnQsaYk21CqJkf5d/Fu6GymxEC77cLDx1U/Fh8Lgn32LGNv9yDKs/gcs/bOIpJ/zIqSOGvxdOSLm27VuhWu/guT9c5N2vAGLbxJj+dIPRTRWUeDJhYT9TmY6/4oiqfjytnnEfXYrbHkBRR8vst79Gb9THhbGwnCsfRQ+vQuuWS6CTP33a2+A+JwBOepoEVHS3lqhoE2JIlBQuxxcHeL+EgtFX931Fow5iwett/LixlY+uyyHxHcvEudUaYT8y5kO+bNE9N3TBYXz4ag/iODL4WjbDs+fDMklwvEvO1XIz5BPZGNrlgoZMuqEge/sWSze68kPin7nd4pn3voSjD1POI/7ZbnD4UD93PHonbVoJJDCPnG+wnlQv1rIhZAXRaVBGn0GLyjHc/cmibvSN3JJ+B1U7v3ZS5VW6Kjys0V/78/8yRHhtC69W7wfRYajfg+zbhFjr22HGM9BjzC21RoRjNJbYeTR9CROYNa9X5Gnc/Nh/utoaz4XRn7AJTaZBrEBb+nJQo5WfwnrHhWG4IEZsYPZ+7Fwwmb+BLKHtXmODEcLdOyGokUDstbXB8+dLBzw0x6DnirY+RZ07RU6YfIVMOMm4eA/uVCM6ys/w+2wY3nlJNFO16yArgrxHhVF9LPsSXDx4qF62N0lHJQtLxAxJBAqOQVD2kjRR5NGClnVL+cCbnj1PJSG1TwadytHnX8LJemDjc4Nu/biev06Fqm3spky7pKvY18wmccvmshxY/brPUURMrTyE9j5JnRXCtk09RrhKFV+TIVhAj91XcLFcVs4y/cWWkL8K3Qq0y6/h5lFB83drFkmnBhzMpz/GqSPiQZen879O3/al8Nfzyjn/Km5fC1f/AFWPSCCMAfZYEOMbEURcnb5XwgYUtEFupEUWQQasyaJwKvGIAKjVZ+LdwkiAKpSg6QS/1ozhC5KyBNyxGAT8lZRxNhr3QrjLxIZrXWPCEdy3LniuV88jdqpf+C8rWN4dp6P0V9cJMpTZ/306591OLy9ImAT9Aj7Z+X9ItOcMR5OemDAST6Ynhr4+OciiJo+VsiO1q1iUYDeGlDrRN+d/TPRZw9sw3Ag6njFHJlh+ME4Mn4nbHoG7+bXMfXtAUBWVKgkmW7DdKTx55O4934kn0OUJORM+XbX6awAV7sYOOGAMGj2fSIiIPL+ScYF84QgdLcLg3DK1XDifUKg/nsujDtPKN8db4qI7/xfgqcTNj0LN26A5CIUReH97a384f3dSN5ujNZETp2cz1mTcihINgvl7usViufrIrLvXCPu8fYqoYRW/0MIIRCKbeZPoGWTuNfi4+GcF6B2v+AqnAcXvCEUfssW2PAE7HhNDJgT7h8qtCMhGp6/mrzGd1mmX8gNjos4YWIR95099hsvvWn3BjnrsTWM6FnO3YaXSJa7RFp/0e8Hp7MDLnj/p7D7HcQ231Y4+g/U5Z1Ntnsn2nevEsbJ7FuFwRNwCSEy6iShfIYjHBBR2q/uFU5WcglcsjjqIC3Z2oDhnUtYoN7GL+Vr+fkv/kyCeX/984434J2r4eznYfRpQ8+98n748o+ipOHoPw01ItkvbNbeIzJEN28XRpsxAa78bOCZHygTUbzkkSKaev7rUHKc+FyWYeNTQij31YtodtmpwnA12oTATikd9tqAMAAemrDfYXhs8Gf7HdzQea/zYEMBNpOWq+Yc4Ag5muGRacIAufi9oc6IHBH3W7NMjIO0soHP/A5h2NevFONi/i8GPqtbCS+cIt5FV4Xoq2c/JwzSJ+YLx+fS94VT8Or5wnA68+mB6yuKiLot/RMkl+Bd+CdM7ZuEM98fvTyAVZHRdCz8B2cumDZ8G4FQLvs+Fdk+V5uIbPfWwhlPQPlZyLLC7z/YTeW6T3jC8CAeWUPP/HsoX7A/2tqv1I+/FwrmwHMnCYV00dvw+W+g+gvulq5hQ9Kp/Pbk0UzMtbFkVzs3vLyF944LMH7ltSIYsvA3wkBVqUXf/vSXwrFX6yESEOP16D8JufXudVD1KYw+Qzhp+sOUrTw+Syj+Kz+D5X8TQZi8WUJGmAeMHXn766jevYYrw3eyNDKWv4+q5Zy6X8PsW3FNuxWrxUJTexfS25eT1b2arRPvxl58FrOKktFr1AP94uGJIqN25aeHbvN+vL3iPTetE7+rdZAzTRgrfQ0iWu5uhylXsXf8XZz08BrCssK18wq5a346fHCLePapV0PGOHGOoAc2PSOyUUEvXPzOoYMn9iZ46ihhLGmNwpgwJQuHuH6VcJAktZDRJ9wrrhMOwiNTxfHXrRocyPjqXlj6ZyJTruYh7dW8s7WZO9z3cKJqPVeEbidnzGz+lL1RyCV3ByQUCAM9fw7Bmq/Q7noDKejCgxEzPnaqS0k96fekpaULmbTrLfE9lQayp4rMWO1yEegoOxX/orsxLP2tkKMTLoKSE4UcM9jgwjcgbfSQJnjgs0oeWlqNJMGl0/P4fdZGWPOwkDN5M0UGLWNcNOCgONtQHhxHTcbJ/MN4A3qNmgfOGTegG+QILPsLrLxvf9tFhI5a9LvDl38NRzgITy4QBn1SkTDwRp0IL58DbduEQV60SByrKNC+A1Y/JJ5fpRVyUg7DVV9CYoGQye5aePoYsOWKcZ44As5/VbzvD34qsvgzfzJwzq0vikh7yItvwpUcvXk6nSEjJ5Snc8nMfCbkDJ73Eo7IPPzpDqasu4GZ0h5W2U5m7tX3D+j4upXYX7oUQ8SJ+pg/op1+HWEFTv7XauzeIF/cOg+z/qCMniyLkqg1Dwm5qtazqegnnL19PL85aQxXzC4AVweRJXei3vMOvzP8gl/dfie6/iXLPd0iMGdK2h/IS422b/DR2XT3dHNs8B7i4hNZdvt8dISFs9ifvTvwx9UuSlLLzx6qVziMkb3zLRG0y58lgm+H0ltdlVDxgci0KYoYe3JIVJz01Yv+fzDGBBFUKDtVbCT+wv4AztXL4MNbkPvqWRR6kDp7mOwEI8sz/oWmdTPcvG34AFLAJa5rOCjzrijw2a9FOd+B6OPhqN/CpMsPGdgcdI4974mKCVebuEbuTDHWxpx5+IzgfmKOzDD8YByZoAflnhF0KTZ2BXPpdeYSNJzOOcfsRLP1GdGBDTa45L2BSN9/Ep9dCImEAhGt6OezXwvBftzfhSLprRXRqP7Mw9tXi7SiJInyqZMeoM3h49fv7uLLvZ2My7Fx4bRcPtnVzvLKTmQFfnnCKK6Ze5ho1sFUfyHKoo76vRjkLZuFEXPMnwd3/I1PwUe3CUeseaMoobrsw8GGjqIQ+PiX6Dc+KqKqJz044Mz47DheuID4ttW8ZbmQk29+iMdW1PLPL6q4edFIfnZ0MUeKLxjhwqfWsavFyaUz83h5ZQWP53zB3J43xAH5s4UjklwMH90q2nXhr6H0VFELX7+SPXIeJapm1Ak5wqn4uujqsDfSJ9K6ZadFJwgv3dvBNS9sZmqOiX9r7sfUvJJPyu7hxHOvEYKw31C5duWhS07WPS4i4kG3yJbNu3Mg6g24etqxPjEVihYKY331Q8KwvXGDqEPf/662HP0GloLJFL97IgSccMM6IUjfu06U4+TOFJGb0pOHz04cjs9+DWv+JTIr+8tZiIThX5MIaOM4O/IXdrSIlXR+fmwJNy44YEWx/r504gPCiO5X1t5eePtKEanWWYRgPu0RGH26iKS/dKZwUnJniPG06Lci2+hqh8fnCOPi6qUiWvvR7dRaJ6L1dZOl86C6btVAJq4/czPhYlFm4O4UQYimdfsN+IdxBRUh0CNhqF1GxNHCI6taqeoJ87NTp/HXXQl8vreLnx9bwvXzRrC2toc3NzXxRUUn180r5MYFRUOd84BbRLAb1xI+9XFurSjGsOtl/qp7BimhgLpePyNoFhm5nKnw8e0w6TI+yLkDuy/ExYUe4cz47aAofDXqN1yybRRvXTeDyflCZgTDMtP/+iXTChJ5bEqnKL3y9giHY+w5IvPWUy0ihnNuF/NM1j4iDHxFFnXux/5FGNb7798TCNPlCpCfbB78PJVL4NXzxDwYV6tQtsffA5rBk5afWVHJSUuPIZgyhldTb+Ga3ZegTS3GdN0XuLx+eoMqznxsLS63iye19zNbtYtbQjcQLD2Txy6aKNqx8hN49Vw461nhhB4JIR9sf00Yubkzh/ZxOYKMirMeX0N9j5dx2fGsr+tl1S8WkmjWDX9OEP3tuRNFn7z43aGBL58dnjlOGEhXfiqc69plot93VggDedSJYt7RO9fAviUw/y4hSz/9JVz4Now8avA5FQX74juxbXuch8KnkZGcxNn2p6kb/3OelU7jxXUNfHrLXIqTdOJ9H1A+43K5WFfdzuq3HuK6Eb30Fp/D+V8YUKtVPHnJZCblJYh+3rh2IFPUtk2UN59wL7WZJ3HSv1ZzyfRc7jS8C1/dI06cPlYEsg7McO/HHQgz629LmV6YSIpVzyvrG/ngJ7MZnRk/5NhwROatzc08sryaa53/4mz1Ck6UHqHab+WVq6aJDIC3F96+SkScJ1ws9NW6xwYMv7k/F87IcMaeogwNmCy9G766h405VzA5tBGpfadw7OUQnP087VnH8Nmedo4dnU5a3AGlrT01wmGv+lz0xbwZ0Ta2Wq2w/XV49xoYeSyc+ZTIbimKKP+r+kzIp4R8+PBnIhtSMBdOfIC7vvLz5qYmzpyYzUc723AHwoxKtzI2O578ZDM5CSaeW1PP5oY+LpyYysmdjzKpazFqnR7VrJtFSeJX91Arp/PF6L9z7TmnRG95c0MfZz62hmvnFnLXCUPnB0bprKDWoXD88w1ML0ziucunDMiwSAjnIwuI9NTx3oy3uPy4GeK53rhYjM1rlg+2bYB/PPsSN9ffRFPOybxcZ+byjAYy7FvFPMJDYbAJG2iYuTVOpxOPomVHs4PKdhfzS1IYm2079LkOQlEU/rW0mqY+L388dQyGg1aUJegVDoDfLsZwwCV0jTWNDXW9/G1JBX8/JoWR7xwv+pm7g4+zb+WG6sncefwo/v7JXm4dG+QnlZeLrG3GWOFwo0B3lQhW99WBxgjH/VXoXkkSzuSSO2Djk6JqoGAO6Mxsag0QyZjAtNEjj/gZAfY2trNzz27mzphBWvw30+sxR2YYfjCODLB3yxpee/8zDK11JOnHkFFyDCfdNE5EZio/EunI5G/WYf7PyBEh4Co/Fr/3pyz78Tvgsdko3m7en/cxH9REWFnVhUqSuP3YEi6bmY96fxlKh9PPL97ewfraXlb8fD6pBwrfwxEJwwOjRFbCmAAn3i+89+FY9xh8cqcQxFd+Ho2+BMIR2ux+Wh0+cswSObsfFVGz0aeLibfNG1DadxKWFf5huIFrf/o74k1aFEXh52/t4K3Nzdxz1ljOmfz1UbVwRObaFzeztLKTRy+YyPHlGfx1SQX/XlHLg0eZOFVZDns/GkgjW9JEWVX+bBRF4f5PK+lY+TS/0r7CGnkMU3/6EsnJ32JC4n72tDpp7PXQ5QrQ6vDz9Ko6RqVbeemqacSpglTft5CcYA3ShW+hc7eICXvnvSIMmcPh7RWR3w1PiAzQ3Nth7h2g1uBf8SCGZb+FK78QRpS7Ex4oFTXyR/8RHp1Ob1DNxI5fYtCqeWKBwtyvLhAZtNZtotThuL8KZ/MgBa8oCjuaHXQ4/UzJTxzIJA13fw+OE4r43JeEobbiXmhcw83czlKmcs+ZY/lkdzuLt7Xyu5PLBuqrZVmU3DSsEiU+o88QGZolvwBXG9vG/ppHmwt5RPtPtK2bYOq1Ikvg7oJzXxBzFd69VhgCR/0e9n0mDK+rl0adqh0f/5uy9XeiQuFvSX/m1uuvH1BciiIM/G0vA5KIJlrSRHtMuxb279VzoEDvjy7fd/Y4zpqUTSgi8/M3t/PetlaSLTq63UGsBg0jUy1sabRz/fwR3HFsyVBnJujB+9yZ6FvXszQygaPVm0W25KxneeirZuSV93Oz7gMkOQR5s6g+7kVO+NcGghGZZy+bwoL4dnjvBoJTr2fmklRK0q28fNXgrMCfPtzDC2vrWXfXIpIMkpBvm58X78iaKcoWC+cNfKF+taixliNwzvNDynVueHkzn+3u4J/njeeksQfVl3/yS1GidsI9ojb7IHY2OzjjsdXcl/oJp/Y9TyRlNP6uGm5N+BeP/uQsGjt6ueylHTh8IV68YhrJ+jC29y5C37KOp8LHk3PUdRw/fy68cCp07SPy0+08vqqR+m4PiRYdiSYdGTYjx5SlDTVMDsIfihCWFSwHRKVfWd/IL9/dyX1nj2NcdjzH/PMrbpg/gp8fOxDVbe7z8vyaesx6DelxBtLiDUxN8mN++RThNFyyWGRaQOiTl84Q8/guentwOw9HJCyy3dtfEUZP4TzhHB14iKzwyoZG7v5oN39RP8UZfCk+GHMWnPkUvd4Qc+9ZxuyiZB6/eGgW2eVyceObFVR1uFh5xwI0ahW1XW6ueG4jvZ4g79wwi6LUgxaZ8PQIY81o49Y3tvHOFpGV/NNpY7jYskmUrBz1h0PunfHUylr+/FEF794wk8JkCwvvX05ekom3rpsZLZ1UFIVPdrVz72eV1HZ5mJBr49JRcOrKk4hMvZ6pmxYwOS+BJ47WCj3pahfZq0mXDVzI3gSf/UqU5BXOhzOeFHpJUYSz8eUfRFbs3JcGymBbt6I8uYj3IrP4WfA6fn5MMTdm1wlZO+483MWncdZja9jb7kKtklg4KpULpuYytzglqm8P5Mmvaul2evjFCWPEs/XVQ3zu4ECVpwcemyGy34osDNoFv4TZt7Krzc3J/1rF5TML+O3JZbgDYd7d0swHO9qo7fLQ7RarDlr0Gv5yRjmnjMukuc/LJfe+wqPpHzGqVywaU5l2Iqc3nMn7tx5DUepgY/TOt4We/einc6LlaHvbnXy2u4PiNCuT8xOw6DWc9shqulwBPrllLinWg5bu7a4i+Mgs1sujyP/pEnKaPxBy+KjfCyfyACrbXRz34Fe8mfcek9tFgLFWyiFvyomoU0aKrJZKs/9HPfD/jHFDsmvVnW6eW1PHkp1t9HgGVpXVa1Q8fP4Ejhl9ZBtS/ntFDX9dsheAWUVJPHnJZEy6I5tbe94Ta1lX20ucQcNbxwYp/vRigqZUyvv+zrnTR/LHU8fwpw/38PSqOlZOWknOvueFPFUioi8m5AtHL61cZDlrl4lg68kPwdI/igz5jJtEAFmSqGhzctLDq5AVhduPKeGG+Yefd9xPRFY44cGVVHYcWd89mJgjMww/FEcmEonwyCOPoNibCe3eg956MpNPPIoZp3+DzMV3RcAtlLQlDc57eYhh+ch7K/howy72yPlk2YwcXZbGFbMKyB1mpbL6bg9HPbCCc6bk8JfTB+Z2yLLCL97eQURRuOv40qECatMz0Lgejv7D4PrJ4ahZSqehgOWtGlbs62JTQy+drkB08870OD3vXD+TzG0Pwoq/gdZEIG08r7dl8Jkyhb/edCk5iQP3HorIXPHcRlZXd/OPc8dz6vjDpz9//d5OXlrXyJ9PG8NF04ViisgKVz2/kZVV3bxw5VRmjkiGrn1iQYCRx4AllXBE5lfv7uL1TU2cOzmHq2bnccyDq7hpQRG3HXOI1XQOQ4fTz+/f382SXe3Rv6kkmJibwJOXTI46AOt3V5Hw+qkU6OxojfFCyV6zHAWOrJzO3Un401+j2fm6KI05/d/IL5yKqn8OSj+vXbh/Iujj8NKZ3B66jvaCMwhGZDbU9fJ67ntM63xDRIHPeGJIDXq3O8B7W1t4Y1MT+zrESn2SBGUZcUwvTEICOl0BOl1+LHotd58+hrStD8OyPwvh3LETty6Vv3lOZEf6mTxy4SRyEk2EIzI3vrKFT3d38Pczyzl3yv466YBbZBt3vyOyQ4oM1kxCZz3P3FdctDn8TM8183L2u6i3PAfGRLGaVH+5XyQssjd73hO/n/FUdAJstzvAsf/4imNMlZxabOD8NRksGpXG4xdNRHPghFNvrzAshlko4kCBvrKqi0ue2cCZE7O57+xx0WNkWeHvn+ylssPF6ROyOHZ0Ojq1it8s3sXL6xu5bGY+vz2pLGq4RWSFp1bW8shnO3lKey9T2SWctGP/AmoNnU4/M/+2lNvGR7g+fh2Rmbdw9ov7qO32kGY10OMJsORmYWD0G4pvXDuDqQWDJ2pXtrs49p9f8ZuTyrhy9gFzz1wdtAe0bGjxs7Gul50tDnzBCKGITCQcZN7IJP545mBDuKnXy7x7l2HSafAGw/ztjLGcM+UAQ6N/laUDJosrikKnK8CeVid/+GA3gbDMJ1eVEP/4BIgE2TTxr5y1Jo9fHDeKxVubaOj188rV05iQu78UI+hBfv9m5F3voCGCP30ShvbNRBb8mlvbjmLxtlZSrHoc3hDBiAxAskXP1XMKuGh6XrR8JhyRqe/xsrKqi+WVXayr7QHg/Km5XD9/BCpJYtH9yynLjOPVq6cjSRI3vrKFFZVdrPrFAmwmHW0OH+f8ey2tdj8ReUCPTsi18c4FOUjPnQjePmF8BVxEvH2oQ25Cpz6OdsL5Q/rVsCgKzg9+iXHH8+w78W3yy6Zg1mvo9QR5bWMjL69rpMXuY87IZO47cwxpy+8QJZMXvBHNMv3j8308+GUV7980a0iUem9TF8c/uoGfLhyc+W7q9XL6o6sx6TS8d+OsYbNQ9d0eFj2wgoun59HY62V5ZSdPXzqFBaMOXbIcCEeYe88yCpMtvHqNcLLf3NTEz9/awT1njWXRqFTePUDWFKVa+PmxJRxTliZk4ttXw96PeHjcu9SvfYd7Dc+hMiWK+aHDzYlRFDF/ackdopxm0W9FJq6/CsLXK4zkc16A7CkEH52DvbeLy00PkZORyad72nnmsiksKElFlhWueXEzyyo7+fuZY6nudPPW5ia63UFmFSXx1CVTMB6wse6rGxq5652dAJw6PpP7zh43aFJ7U6+XLY19aNUq0rtWM/GrK5Et6ajOegbyZ6EoCmc/vpa6bg9Lb59PvHHoZHCXP0R9t5f0eMMg3X3Dy5tZXd3D+kvj0fl6WPihkVSrgTeumzHkHH2eIAvvX87IVCv3nj2Wf3y+j8XbWznQNEwy6+jxBEXA5BDv177iUWzL7uKj+PM50f+RmAN8+cdDMmHXvbiZVdXdrLx1JgltK1nty+HC1xuPeK6M0x9iXU0PL65rYGVVNzqNikXFSUwvSqU8O570OAPXv7yFnc127j7968/51uZmbn9zOyePy2RecQp3vLWdibkJPHP5FOIMh5+Av6fVyQkPreSymfksr+ykwxngtbndPLXVxRa5hE9/NheLXoMvGOGEh1YSDMvRvw2LLIuy7i/+IPpl2CdK2xf9FiRJbO68P0s8Y0QSH+1o46SxGdx71rhBfW843tjUxB1v7eA3J5XR7Q7w5ibRd7NsRs6dksM5k3NIjz90kDvmyAzDD8WRcblcvPnG6+RWvsz2BjO6uIs59pp5FE85Mk/+SJFlZWCi7jeh//0cZNgu2dnG9S9v4bTxmVw9t5CyjLivNX5/t3gXL61v5LOfzWVEioiW9UeT1SoJi17Db04q48yJWUdkSCuKQn2Pl80NfWxu6GNTfS9VncLQTYvTM3NEMvlJZjJtBow6NXe+vYP0eCNvXjuDBMVBn2LmnCc30ubw8+rV0ynPHlpa4AmEufL5jayv6+Xes0TEezh2tTg46eFVXDm7gN+cVDboM6c/xGmPrKa+28O5U3K4eVEx6fEGIrLCxzvbeGRZNXvbXfxkYRG3Hl2MJElc++Im1tX2subOhUNrhw94/oYeL1qNCqtBg0mr5rWNTfx9yV6CEZmfLCxifkkqqXF6ksz6IVEPRVG45J/vcZ/z56QpXXDBm2wxTOFnr29jZKqFB8+bMOy1FUVhdXUPT6ys5at9XdyeuYPrXY+glgNiLsPZz6GUnUZjrxeLXkNSyzJ49VwCRrHfwnWpL/Ls1XPQqlXc/VEFr6yp4vKMBtInHE9RRgLFaVa63QGWV3axorKLzY19RGSFCbk2zpmcw4gUC+tqe1hd3c3WRjsqFaRaDaRa9expc2Izann+4tGMfGMRikrFJ7bzuXlvGSdOyOdvZ5YPzG1AGDbXvLCZr6q6eOzCSRw35qBx5+4SUaq8WbxR4eeOt3dw0fRcXlrXyBkTsrh/QidSSvHQxQEiITHB0ZouVpPa327XvLiZFfu6+PAnsylOs/LC2np+u3g3Z0zM4r6zxh3RGHW5XKA18K+l1Tyzuo78JDOLb5p1RBE8RVG4+6MKnlpVx/TCROKNWtyBMG12P7XdHo4dncbdJxeT7K0ZUsp682tbWVrRydpfLuKtTU38/oM9PHDOOMZkxXPyw6uYOSKJRy+cxNx7l1GUMmAoHsypj6zGH4zwyS1zkCSJTqefG17ewqaGPgDMOjVjs21YDRp0GhVdrgDr63p5+/oZTMobcEr++IHI7nz2s7n87v3drKzq5rcnlYna+YPon/Pz8c42ut1i4z2DVsXzl09lWmGSyDD6nSgLfsUFT21gbW0PGpXEU5dOZn7JUMOpraWB1578G+eql5OhcfPzjOd4a68/WqqoKAqeYIQdzXYeXVbDqupubCYt5VnxNPV6ae7zEd7vfBQmm5lfkorLH+KdrS2oVRJ5iSYaerwsuWVOVFbubXdy3D9X8tNFI7lkRh7n/Hstnc4AL181jdKMODpdfhZva+XeTyt5+appzEryiLJOOUJEa+GdPS6W+orYk7CAX51QytH9xvkwBMIRPt/Twesbm1hZ1R3dP0ySIDfRRJvDTzAsM6MwiUtn5nFMWfoh+67LH2LOPcsYm23jhSumDvrsLx/s5Kk1jaz8xUKybINXntzS2Md5T6xjXHY8L101bdC4Bbjjre0s3tbKyjsWYNZrOPeJtdR2eXjj2hlDV9jbz+sbG/nF2zt54YqpzC1OifaNs/+9lj2tTkIRmbCsMC7HxkXTcjl9QtbgAEPHHnhsBqGkErQ9lTRYJ5J37RvRcqN+mWzWa0g06wZkbvsuePMykY03JcG8O3mTRTTU7uX6tl9jcjcSzp6BtnElN0l3cesNN5ERb+SMx9bQ0ufl/Ztm89rGJh5fUcMfThnNpTPzAVGu+frGRn73/m6mFSTx9GUikr+muptLntnAzKJkxmWYeXhFPUeVpvGvCybgC0Z4eGk1L66rJxQZsL8mSvtwWwq46aSpnDw2g/e3t3Lza9v42xnlnHckk+EPYFN9L2c9vpY/nTaGEclmLnhqPf88dzynTRg+GNj/XiRJZDMum1nAFbPzaer1sam+l00NfYzPsQ0uAz4YRaHx4RPI7V1DQGWk4exPGTlq8BzXfj19YMm4oiic9ugaul0BMVdGoxpy6j2tTl5a38CWhj4qO1woirAxLp6ex/lTc9EpwUFGtjcY5vqXtrBiXxfXzC1kZKoFf1gmEIoQZ9QyIsVCUYqFzY29XP3CZmYUJvHMZVPQaVQs2dnGT1/byqj0OF64YuqhKw+An7+5nQ93tLHurkUEIhEueXoDe9vFKnsH9vH+d3L2v9dybFk6fzptzNCg8YG0bhMl1iXHixLp/W342oZG7nxHZInPnJjF4ytquefTvYzOjOO+s8cxKj1u2NP5QxEW3Lec1DgD790wE0mSCIZlvqjo4NUNjays6kYlwZT8RIw6NbIi3svMEclcP18ENmOOzDD8UBwZAKV2BWvuv4l13XnobT/h/N/NIinTQp8nyOXPbSTTZuD3p4wm1XrkewEcSH23h/OeWMctR438WoG0rcnOs6vruO3okmEzKyAiOSc8tJLCFAtvXjtj2IE/HN3uAPPuWcackSk8fvEkPt3dzrUvbubsSdlcO6+QO9/eyaaGPmYXJXPl7AJmFSUPOndjj5cV+zrZ0+akst3Fvg437oBYqMBq0DAxN4GZI5KYV5JCSZp1iJJeuquJ617bRWlGHE9dMpmrX9jEnjYnz18+lRkjkg55375ghKtf2MTqmm7+cogIy2XPbmBro52Vv1gwbBSl1xPk4aVVvLSuAbVK4oyJ2ayp7qa+x8uIFDM/O7p4UGnMlsY+znh0zbCGWTgi8/Gudh5fXsOeNueQa80qSuLu08qHzhsYhne2NPPAm1/wxBwfX5mO5r7P9pG0vxypNMPKM5dNifa7UETmwx2tPPFVHRVtTpIteo4fk85HO9sweZt5Pv5JktQ+/pb/FCuq7bQ5xHr3yUYVn0k3kCj38rr+LI67+XHiTQNt9OamJv7+yd6ogXkgozPjmF+SwqnjsyhOGyrEwhEZtUqKvutdLQ4uf24j/lCEJ84r46M93by0oZWLp+fxh1NGD2ts+YIRzn9yHZXtLt68bngjKCIrHPXACsx6NR/cNJuHvqzmH1/s447jSrhh/mGU6wH0R94Oniv24BdV/OOLfdx5/Ciumzc0E7umupvGXi82k44Ek5bKll4e/qqBLleAsydl84vjR5FsOfJdkhVF4dHlNby+sQmTTo1ZrxGlGxMyOW38oYMI/X3y2rmFvLiugSn5idFa9efX1PO793czOS+BTQ19vHbNdKYXDj+mXl7fwK/e3cXiG2dh0Kq54rmN9HmD/HTRSGaNSKY0wzrIePQGw8y9ZzmFyWZev1ZkJ1z+EDP+upRFpak8eN4EAuEIP311K5/u7uCu40dx7UHt+Miyau79tJITytOZkp9IWUYcpZlxw47Vmi43V7+wiWtm5nDejENnxhdva+GW17aQH6emzqkc0onqb7vHltfQ5vCRl2QmL9FEfpKZaYWJ5CUNjNOmXi+PLKvmrc3N3LxoJD9ZNLik+LoXN7O6ppssm5H6Hg8vXDFtUNYrEI4w5+/LKE4TJaT9vLSugV+/t4tbjhrJRzvaqOp0M7somV8cN2pQAEdRFD7d3c7v399Du9NPls3IOZNzOLosjRa7j4o2JxVtTlKtei6ansfIYcbkcDzxVQ1/+Xgvr18zXTiOiLE7469fMiYrnmcvnzrs9z7Y3spPXt3K6ROyBk2ub+r1suC+5Vw0PY/fnyIm83c6/Zz2yGpaHX6seg1xRi02k5biNCtTCxKZkp/ANS9sxrR/DB/YzyvbXdz25jZmFCZx9uScYWVNlFfPh8qP+cJ2Dj+3n87qXx6DSachIivc9sY23tsmVv5USZBo1nHVnEIxrgNuMXer+FgaPRqOemAFIVnGonh5RP8Ic6WtvCnPp+CKZ6Pzypp6vZz8r1Xo1Co6XQEunJbLn08bM2SMvre1hVvf2MbUgkR+fWIZFzy5jrQ4A2/fMBMp5Oe9XT38ZvFuRmfG0djrxRMIc/akHC6ZmYdaJYzKLleABz7fx+5WJ9MKEmno8ZJi1fPejbOOqPTnQBRF4bRHVuMKhClNj2NVdTfrf7nokCWWsqxwx9s7MOnU3LSg6MjLzw8iZG+l/fFT+af7GN4Oz6Qkzcr8USnIsoIvFGFjXR/tTv8QPb1sbyeXP7eRv5xezgXTBuv3LleA4x/8Cl8wwqT8RCblJjApL4FphYnRDNdwRnYoIvOLt3dESx+HQ5JgTGY8r14zfVCWZNneTq59aTMjUiy8ctW0YZ2ZbneAmX9dyrlTcvjTaWIOkMMb4qevbaU4zcKvTiwb8p1HllVz/2eV6DVqLp2Zz7VzCw/rKB1I7/7MWXGaldevmR7tg19WdHDbm9tx+kJcOC2PW48uHnLOx5bX8PdP9h5SLzT2eHltYyOra3pg/x5tkgTzilO45SjhcMYcmWH4ITkyLPsrH77yHvXhYtTmK7jmwXkEIjIXPLk+aqgatWp+f0oZp+0vb6rqdLOutoeIrFCeFU9ZZtywEdlgWOasx9ewo9mBzaRlxe0LBhmRB7K1sY9Lnt6AKxAmwaTl0QsnDTHwQxGZc/69luoONx/9dM4hnZ1D0W+03XPWWP74wR4KU8y8ce0MDFo1sqzw8voG7vtsHw5fiHijlmNHp5Fg1rG0ojOabbGZtJSkWSlJt1KaEcekvASKUixfG812uVysbfRw3UubMWjVBMIyj1048YjqWP2hCNe9tJnllV1DUtAb6no5599rD2mIHkhTr5f7P6vkvW2tlGfFc+OCEYeMZp7z+Fpa7D6W/3w+WrWKcETmjU3NPLaimqZeH4UpZi6ZnodRp8blD+P0hylOs3BiecYRr7QWDMvMuWcpdm+IQFjm+DHp/O3MsWxp6OOGl7eQaNbxrwsmsKm+j2dW19Hm8FOUauGaOYWcMj4Tg1aNyx/iyZV1PLWyFn8whNmgY3ZRMjOLkgmGZao73UyufYRT3W9iv2odydlD53spikK3O0hVp4uqDjcmnZp5xSnfSqE193m5/NmN0f4i5hUMMyfkADpdfk5/ZA1hWWbxjbOHpLg/3NHKTa9s5bELxdwnRVG4+bVtvL+9NTo35XB8ta+LG1/eQmlGHK9eM32QYaAoCte/tIVllZ0suXkOhSkDtf3LKju5/NmNQ843IdfG708ezbgc25E0yX8ERVE49ZHV7Gh2YNap+fRnc8lOMEU/u+K5jSyr7GJaQSKvXzu0hKQfpz/E1Lu/YGy2jYpWJ0admmcum3LIKDrAi+sa+M17u3jmssksHJUWLV87sFwpHJG55fVtfLijbVB55+rqbi5+ej0njc3kwfPGH/HYOBLFectrW1m8vfWQAY5viy8YwaBVDbnX3a0OTnxIGLZPXzaZOSOHzqHrdxr628YfijD/3uVkJxh587oZhGWFl9c18I8vqnD4QswrTuGmhUVkxBv43eLdfLm3k9KMOO44roS5I4+sfv3r8IdESVeyRc9dJ4xiemESy/Z2cs2Lm3ni4kmHlcH/WlrFfZ/tY+aIJP5+5lhyEk3c9c5O3t7czFd3LBg0Vpt6vby9pRm7N4TTF6LXG2RXi2NQkOSRCyZy4tihiwAcMd5e6KlhY2QEZz++lr+cXs55U3K4652dvL6piatmi/LqbleAjfV9rKvr4c1rBxa9AOGQrtjXxWc/m0tVp4tPdrSgVH/BwuPP5vgJg53hVVXdXPLMeqYXJvH8FVMPuefJ4m0t/Oz1bQDYTDoW3ziLnERTtB+/u7WZO97awdyRKfzi+FHDOmsRWeG1jY3c+2kldm9oSBb0m7B4Wws3vybu54pZYo7Nfwu7N8iHO9p4e0sz25rsGDRqjDo1Jp2a244p5vQJg+W1oiic+dgaKttdvHL19KhclWWFS5/dwIa6Xj7Yn0UfjkPJCkVRaO4TCwjotSr0GjV2b5DqTjc1XW4cvhCXzyoYNhD11b4urnph0yGdmX5b6svb5kWztkdCbZdblHpub8Ws03BieQbHl6czc0TyYYPSP39zO+9ubeHjm+cMaYc+T5B/frGPl9Y3YtFruHHBCM6fmovVoKXPE2TuvcuYmp/I05d9y1V3iTkyw/KDcmSePZEXV0Vwa0pJzD2fM+6czDUvbGLFvi4eu2gSRakW7nhrB5sb+hibHU+r3R+dZNePSoLiNCt3Hj9qUCnE35bs5fEVNdy8aCQPLa3i6jmF/HKY1UG2Ndm5+Kn1JJh1/P3Msfz6vZ009IgVNPojFP119//+qvZbKwNPIMy8e5fT7Q6QZNbxwU9mk3lQSUEgHGHlvm4+2tnG53s68IciTC1IZFFpGotGpZKXZPrGSyLDwEB4c1MTv1m8iz+dOoazj2AS/4H3de2Lm/lqXxePXDBg0J7z77U09HhZ8fMFX1sn2o8nEMakUx/2Ob6s6ODK5zfxz3PHYzVo+MvHFdR0eRifY+P6+SM4ujTt25ULHsTza+q5++MKfnNiKRdNz4ve045mO1c8tyna12YUJnHN3ELmFacMe91ud4Dq1h4mj0gfXI4BYqKxo+nwezD8B3H4Qvz6vV1MyLEdMkp+MBVtTs56bA0F+53r/sCAoiic8NAqguEIn/9sXvTZ/aEIlz27gXW1vZw/NZffnVw2JOLYavfxpw/3sGRXOwXJZl64YuqgeVj9dDr9HPXACkZlxPHa1dNRqSQ6nH6Of3AlqVY9T1w8Gac/hN0bwu/3snB0zn/k3X9T3tvawi2vbxtU3tJPlyvAL9/dyc2LRh7WKQG49fVtvLO1hVHpIut3sAw4mFBE5ugHVqDXqPngJ7NZeP9yMuINvHndzCHHXbd/wY0HzhnHjMJkTnxoJQlmYdgdqkxzOI5EcYYjMi1236CsynfNy+sbKEg2i/l2w+Dyh5j1t6XMKkrmsYsm8cyqOv744R5euXraoO+4/CFeXNfA0yvr6PEE0agktGoVtx1TzGUz84eO4f8jH+1o4+dvbccbjBBv1GLWqQlFZNbeteiw11IUhdc2NnH3RxVEZIXr5o3gX8uqOG9KbjQSfTgURaGu28OGul56vUGunTviP+KcKYrCiQ+tIiyLErvn1zbw04VF3HrAvEZPIMyx//wKrVrFkpvnYNCqWVvTw/lPruO2o4uHZNwORU2Xmyyb8WsXjXh/eyv3f1bJ/WePizpOB/ZjfyjytecA4Qg09Hj/T4GS/iBZhzPAF7fOHTLJ/7+Fsj/C/3V0OP2c9fga3P4wb1w7g5Fp1mhQ4O7Tx3DhtLxDfve7MrIP5cwEwhFm/30ZYzLjDpnN/Doq2108vqKGz/d04A6EiTNoWDAqlemFSUwrSKQg2Yw7EGZjfS9f7evmuTX1XDdvBHcef4glpPef888f7WFlVTcWvYbzpuTg8IV4e0szn9wy9/CZzq8h5sgMww/GkQn5Uf6ay8OV01EZJ1Ay6xyWmEO8s6VlUJozIis8t6aeNzc1MSrdyswRycwYkYROo2Jns4MdLQ6W7BQlAzctKOKWo0ayvq6Xi55ez3lTcvjrGWP5+ZuipvjL2+YNMqa2N9m56On1JJh0vHbNdDJtRhy+ED99dSsr9nWRn2TC5Q/T5w0iK3DBtNxBE/a/KW9uauK3i3fz7OVTDll+0o8/FCEiK9/IADkUBw6EUEQ+st18D8IbDHPRU+vZ1eLkuSumEAjLXP7sRrFizvRDC7pvgywrHPPPr2js9RIMyxQmm7nz+FGHrW3/tgTCkSE16CAinC+vb+TE8oxh5xAdzPctbP6vfFnRwVUvbGJKXiLXzitkbnEKq6q6ufy5jcNmXkIRmQc+38djy2sYlW7l/nPGEY4o7OtwsbvVyesbm1BQuGlBEVfPLRy2jfvprxO/+/QxnDcll4ufXs/WRjsf/GTWICPg+2xjRVGo6nQzMtXyf+qDTb2ilODaeSO+dkJrP/1lRsePSWfJrvbBG+kdgD8U4fJnN7Khvpf8JDGf4/2bZn1jQ+rH3Jfv+7SSR5ZX88FNs7ns2Q2MTLUecs6SLxjh1Q2NNPR4uGbeiCFzVf6T+EMRVlZ1R5flv3x6NjcdfZhldw+g1e7jrnd2smJfF1q1xIqfL/haB/i7pn8CM8A1cwu56/hRQ8bFmupuLnhqPVfNLuCuE0o56eFVOH0hvrxt3hE5Ff9Xvs9+/P72Vna3OA6/tPIPiIYeD2c9vha1JPHbk8v46atbOao0bWCp9UPwXbZxvzOTEW/gzInZHDs6nV0tDm57c/uQeTDfBn8owqqqbpbsamfFvs5o9jLRrMPhCxGRFXQaFfOKU3jwvPFHNBdzR7Odp1fV8dGONsKywjmTs7nnrHFf+73D8X3L45gjczj8Dtxf/IN/v7gJjXEh9dNm8W5DN7ceXcxPjzBaEz1VKMLvFu/m9U1NTC9MpLbLg9Wg4YOfzMak09Du8DP/vmUcXZbOw+dPQFEU3tzUzO8/2E2SRcdr18wYpMQissKjy6rZ3eok0aIjyawj02bkjIlZhzXIjoRDGc7fJf+pgWD3Bjn78bW0OfykWPWEZZkvbx1+kuD/lU92tfPnj/Zw1ewCLpye962cr/8m37ew+U/w+sZG7vmkkh5PkGSLLtpP+0v8hmNZZSe3vbGdXs9ACYtOo2JhSSq/OrF02CzMwSiKwoVPrWdHs4MzJ2bx/NoG7jnzoJW4+P+jjb8NsqxwyiOr2NXiJCfRyPLbFxwysu4OiIDDtiY7D58/gZPHZQ573OH4MbdztzvArL8txWrQ0O0ODtrP54fEN21jRVH4YEcbAKd8i3f6n8YfinDaI6uZXZTMr04sPaSx++v3dvLy+kbOnZzDaxub/u/lbd+AH3M//j6oaHNy7r/X4vSHyYw38PHNc7CZDj+P5Ltu4zU13dz3aSVbm+woCmhUEvnJZj7/2dz/aFBTURRq92cvtzT0kRZnYGZREhNzE76V093m8PHJrnZOn5D1tW34dXzf/TjmyHwNjbt28OaffsmOlItYYbFy8fQ8/njq6G/dQd/a3Myv39uJLMO7N84ctNFX/yphz14+hTc2NrFkVzvTCxP557kTDrv03f8P/CcHQpvDx1mPiTks/zh33JCa2/9Vvm9h858iFJFZXtnFW5ub+LKik7tPHzOwPPMhaHf4+WhnG1k2A8VpVnITTd+4PKexx8sx/1yBPyRz6vhM/nnu0Dkd/7+08bdhVVU3Fz29fvDeP4fAHQhT2e4Smyp+C37s7fzbxbt4YW0D84pTeP6Kb1d+8l3zY29jOLLSJXcgzLH/+IoWu4+p+YnRRSv+G/z/0Mb/bTY39PK793fzh1NGH9Ecof9WG3c6/Xxe0cGKyi7On5p72KXG/3/j++7HMUfma9j++cc88urnfJZ6FMeMSuWxSyb/n2t467s99HmDA/sf7McdCDN//xwVrVri9mNKuHpO4fdSb//f5j89EBp6PHxZ0cmlB2z++b/O9y1svgsisvJffb9vbGpi8bYWHr9oEtZhyq7+f2zjb0JFm5OSNOt3LrN+7O3cYvdx48tb+OsZ5ZRmDL8s6vfNj72Nvwlra3r41Xs7efj8CYOCi981/0tt/H0Ra+Pvnu+7jWOOzNfw0CMv8M/GBHLR8undR3/nJVcf72zjuTX1/Paksq+dlPv/E9/3QPhfINbG3z2xNv7vEGvn755YG3/3xNr4uyfWxt8933cbH86R+b/P4P6R09Tr5V9NNpLCTq7PHvVfmTdyQnkGJ5T/d+pzY8SIESNGjBgxYsT4/5H/eUcmO8HIgsAucvtcZM/4YdYxx4gRI0aMGDFixIgRYzA/7CWY/gtEwmFK2tZiVswkZR/5pkYxYsSIESNGjBgxYsT4/vifd2TkSJhRs09Hrc0nKSvmyMSIESNGjBgxYsSI8WPgf96R0RmMJObMQ63LIjH9v7c7dIwYMWLEiBEjRowYMb49//OODEBPi4f4VANqbaw5YsSIESNGjBgxYsT4MRCz3IGeZjcJGcbv+zZixIgRI0aMGDFixIhxhPzPOzIBXxhXr5+EDNP3fSsxYsSIESNGjBgxYsQ4Qv7nl1/W6FScdedkFHXw+76VGDFixIgRI0aMGDFiHCH/8xkZtVpFWn4cZpv++76VGDFixIgRI0aMGDFiHCH/845MjBgxYsSIESNGjBgxfnzEHJkYMWLEiBEjRowYMWL86Ig5MjFixIgRI0aMGDFixPjREXNkYsSIESNGjBgxYsSI8aMj5sjEiBEjRowYMWLEiBHjR0fMkYkRI0aMGDFixIgRI8aPjpgjEyNGjBgxYsSIESNGjB8dMUcmRowYMWLEiBEjRowYPzpijkyMGDFixIgRI0aMGDF+dMQcmRgxYsSIESNGjBgxYvzoiDkyMWLEiBEjRowYMWLE+NERc2RixIgRI0aMGDFixIjxoyPmyMSIESNGjBgxYsSIEeNHR8yRiREjRowYMWLEiBEjxo+OI3JkJEk6TpKkSkmSqiVJuvMQx8yXJGmbJEm7JUla8Z+9zRgxYsSIESNGjBgxYsQYQPN1B0iSpAYeAY4GmoGNkiS9ryjKngOOsQGPAscpitIoSVLqd3S/MWLEiBEjRowYMWLEiHFEGZmpQLWiKLWKogSB14BTDzrmAuAdRVEaARRF6fzP3maMGDFixIgRI0aMGDFiDPC1GRkgC2g64PdmYNpBxxQDWkmSlgNW4EFFUV44+ESSJF0DXAOQk5ODy+X6Nvf8neDxeL7vW/j/nlgbf/fE2vi7J9bG/x1i7fzdE2vj755YG3/3xNr4u+eH3MZH4shIw/xNGeY8k4BFgBFYK0nSOkVR9g36kqI8ATwBMHnyZMVqtX7zO/4O+aHdz/+PxNr4uyfWxt89sTb+7xBr5++eWBt/98Ta+Lsn1sbfPT/UNj4SR6YZyDng92ygdZhjuhVF8QAeSZK+AsYB+4gRI0aMGDFixIgRI0aM/zBHMkdmIzBSkqQCSZJ0wHnA+wcdsxiYI0mSRpIkE6L0rOI/e6v/r717D5OiuvM//j5VfZsr98twEdDEgDgiyagYEzVh4yUxooZfJDFuglmzxjvJuppoIkmMMVk2TzSruG7WJRoSIRhdY6JuVBR1vYGLooKoCDIgMDDDTM+lb1Xn90f1NDMwAwNMT9Pj5/U80NNV1VWnvl1dfb7nnKrOjx3NSb7462f586qthS6KiIiIiIj00D4TGWttBrgceIwgOVlsrX3DGHOJMeaS7DKrgUeB14CXgN9Ya1/PX7F7z6DSCJt2tvHC+p2FLoqIiIiIiPRQT4aWYa39K/DX3abdudvzfwH+pfeK1jccxzDt8MEs39BQ6KKIiIiIiEgP9egHMfu7aYcPYXNjko31rYUuioiIiIiI9IASGYJEBuD5dTsKXBIREREREekJJTLAR4eXM7g0zAtKZEREREREioISGcAYQ824Abzw7g6s3f0nckRERERE5FCjRCbruMMGsrkxwcb6tkIXRURERERE9kGJDGB9y3HjBgBoeJmIiIiISBH40CcyXjzFtttXMrY+zdDyiBIZEREREZEi8KFPZJxYCAy0PfQ+Z44axPPrdJ2MiIiIiMih7kOfyJiww5CvHYUJO1y4OU1TY4L39XsyIiIiIiKHtFChC3AoCA2MUnreePyF7/BDSnjh3e2MG1JW6GKJiIjkWN+SfLsBpyxMZExFoYsjIgXmJzIk1zeR2dpCemsr6W2t+K0ZjAEcg3EdSqqHUn5iFU5puEfrtNaSrm0GQ1GcZ5TIZIUOK2fgFw7npD+v4/nnPsAedxjGmEIXS0TkkOE1p0i+10T08AG4ZT37UjxY7UN9i/l87MVTpGrjeE0pjGMg5GBcQ2R0OaEhJft8vZ/0aF2xlfhzm/B2JAAo/+QoKs8YjxNx97s8fmua1pV1pDIp0h9zCA0rDcpFEG/bloGQc0DrbmetxWtK4cRCONEDX8/u/EQGrzFJaHAMEz6w9VpryWxrBccQHlbaa2WD4L3C87EWsBa/KUW6rRWb9LAZH7cygjsolov3wbLW4sfTpD5oJr25hUxdKybkYGIhnBKX0KAYsYmDg2H0+1iPTfn4iQy2LYP1LeGRZQdVTq8xSXprKzbtYTMWm/bxGpNkdrSR2ZHAa0piIi5OSQinJCifTfvYlIdN+8F+RF1M2MGEHOhQFLcySmhYCaEhJfgxD1sSLN/Ob02TrmvLHoO7tuGUhDCxUG6/vMYkyQ1NpDY04Sc8QkNihIaUEBoSC5YLOZiQAd/iNabwmpJ4TSncAVEi4yoP6jxorcVryG5/fWOw3oFRQoNiuIOiex7f7Zc9WEh/0EJibQOpjU3gB5OdigjhEaWEh5bsOv6a0zT9bQPxZbWUT6uiZMow/LYMfjyF15zGRBzcyihuRQTr+bS9vp2217bj7UwSO2oIQ//+qAPev76iRKaD8k+O4pln3+fErWm2/GYVw877aI++ZETyJVUbJ/H2TmJHDiI8qqzHlTlrLenNLbgDo71a4fTbMmTqE7kvFOMY3MGxPSo8ftIjtb4R69vcSdIpD3f5pegnM2Tqk+BnT9IGnNIw7oDIHvtrPYufyARfRh3W5ac8vPoEXkuayKjy3JciBK3YqY1xUu83ERpcQmRsOW5lFOtb0puaaVtTT/LdnThl4eBLYGQZoUGxYB+NCcoTdXNfgF2xGZ/0lhbSH7SQ2ZnE25nEa0xiwg6xIwcRmzg4WGf7/ta1BV8ijgEHjOPglIVwB0S7rHBYayHj46d88Cwm4mAibi4GfsrDb81gExmcsnAQ616o+Ftr8VszJN9uoPX/tpF4uwF8MDGXys8eRvknR+UqD+m6VhJrGzCuwR0QxR0Ywy0PYz2LzfiQ8fFa0niNQUXAb0rhZyssNu13ev+xkI4naG7z8eMpMIbw6DIiYyqIjC7HejYXYz/lER5WSnhEKaGRZWCz83YmgxiHDCbsYiIONuPjx9N4zamg1TLk4ERdTMwFY4LKZsrDT3nBe14ewS0PB++75+f2xSa9oDLQlsGmPOjmskqb8UlvbsFrTHYb49DQEmJHDiIyrhKc7M5b8JpSZLa3kdneRqo2jk14RA6rYMBp40ltaKL5fzfTtqaegTOOwBhDalMz6c3N2IxP5LAKIodVEhlb0emzmd7eRvNzm2hdvjWIOdD2142YWIjwiFL87PvTPs8dEFQW3YFRbNLDa07jt6TB2qBCXhnFqYxgXBN8VgDbliH1QfBZsIkMGAgNKw2StuGl4AXHsU1lY9gSrNNvy2QratnPXHmY6LhKIuMqCY8qJ7WhibZV24Nj0LPZ8kUIDSnBqYwEldTSMG55mNDQEkLDS3ErIwD4zWky9Qky21pJvLuT5Ls78eNpAMKjyyn7+HBKpgzDLY/kYuU1JUm8s5PkOztJrm/CibqERpQSHl5KaHAs+/kAPEumvo305hZSm5vxm1J7vMfx3Se4htDgGO6AaLbV3ATvvWex3q7Pg4lkK/ERF2yQCNhMMD93/LVlcu8XgFsZCZKShLdresgQO3IwpccMDeZ7Futb/JZ0UO5NcdKbW7BJr1MxnfIwJZOHUHL0UEJDS/DiKfx48H5Za4NzTIfzJAbwLanaZpLv7iRT1/XPWbiVEUJDS4iOqwyOhUQGb2fwGTERFxN1ccrCwb6m/GB7mV37iIW2N+uhw7Q44JSGcMrD+C3BcdUtQ5CkuAa/ObtcyMEpcXPHRU+FhpYQGVuBOyASnC8qIpiwg/Us+D7WJ3fuIBvzTH0i+Le9Lbd9E3VxB0ZJrmvc433obh/Co8upOGUs0Y8MJFJV1m2PS2pzM/GnNhJfVkv86dq9r9c1xD4ykMrPjaNk0uD9ikWhmEJd2F5TU2OXL19ekG13JR6PU1FRwZNvbuHRe1dxsY0SdR0GfvYwKk4efcAtP8XEej5eYwq/NU1oWGmvtqLBrhgfLOtbUusbaVmxjfTWFspPHEXp1OG91sLVcTt+cxo/5REaFMW4HVp7khmS7zWR3tQMELTYuEELplMWCiqTsRBePEWmIYHXkMR6lnBVGZGqMkLDSnLr273F2fqWxJp64s/UknqvKbfN8MgySmtGEBoUI7UpTqq2mcy2VsKjyymZNJjYxME0t7TgvNVCy0tbyGxvAweiEwZQcvTQXGUg+W72i7kkRPQjA4l9dBDhqjJSG+PBl/a6nVjfEhlbSXRcBaER2XlvN5DaGN+z0uaYYL8Oq8AtC5N4dyep9+O5ykaOITjRVwYne5v2SNe1dfnFD2SHz5QTrirDi6eDRGFrC2RssK6yME5ZGL81aF3quJ3wiDIi4yvx24JKuN+a6bzuykjwpdKczn0h2KQXxGxvp0QTVOLdsvaKU/Aep7e27tpfE7SMhQZG8ZrTePVBC3poaEmQcHSzv7lNZL/Eyfj47ZX8jl/iHZcNO0Flarf5JuzgDo7htlcGshUgE3ZwYiFMtmUyNDCaTTqi2LQfHKvZL1mvIUGmPhlU1AkqtaXHDiN6xECan9tE4q0G3CExSiYOJrG2odtKy97200RdnLATnF9dE9QMs3VZGzVEBpTglEewGT9XUe94XDnlYUzIyVWCerztWAinLBTEOOHlkhETzrYAR9wgWWlNd3s8mLATxDHqdmop7ryQITyyjMiYciJjKnAHx4LKqm+xKY/ke40k1zaQeLexy/fYxEKEh5UQGlFK2XEjBZWQbgAASFZJREFUiY6rzM1Lrmuk/v61uR4aAHdwDOOaXe+FAVwnyDEM2JQPrqH02OGUnzSK1lQb4e0eqQ1x0ttbccsjwfFQGQmOh2wildmZCHpWyoJEAYJEy2tK4cVTnd4TE3YIV5UF/0aW4TWnSW9qJrUpvquSGHJwIkH83Ozn2CkJ5ZIhrCXTkCRdG+9cSR8YDc5lo8uD43R7G5kdbXgt6Vwi3/H96pgAtHPKw0SPGEjsIwODnq5XtpLe3BLEyjHZ19tdrdylISITBkDGJ721tetjzUBoeCmRUeWERpQGx0b2/U+mk5QMKAuOq+yxmtkRxNWLp7G+zVV0jWuyPQAOOCbXM2FTHhiT65kwYSdoWMmeg9zKKJFRwbmyUyNO9nPT9modrau2dz5P7v5+jSoPvudiwbnBZnwSq+tJrKnvFL+eMBGX6IRKokcMJDK2YldC5hqcishB9fTl9s23uWS/ZfNOTAa2lzSTDvnB1d8dE8Rs74S1BA0m2edYoD3m2WTc2iDhwM8u3/F4cgiOUSfoobEZH5vJvn9+z+vSQQOW2dU7GzIYZ1ePU64Me1tl++v3J2btx5kJGtByn7f2/YUgFl01OPo+jpP/y+pjsRhjxowhHO6clBljVlhra7p6jRKZrI6V7Nc3NXLzotc4Y1uazxLGuobY+OyHclxl8IHMHgBORaRTy3F7S3jr/23DZnwqPj2613p1/ESG5LrGoDt1aMkBt7hm6hMk3qon05DE25nY1XoZT+364DgQHlUetIgdVkl4VBmhISWdW8GTGfw2r0OrssFvywStdvEUXms6+4EJPnDJUIbKw4d12UPQ3qKd2tRMektLUKlo79JtPxH5wRdS25p6vPpE0IIxIEJmWxuhEaUMOG084VFlpDc3k9rUTKY+QWhAlNCwUkLDSoKWoo1xUrVx0ltacUpCQY/FwChOxMWLZ7+Ys13Hfqd4GEJDY4SGleI3pUhtiue+6Hqk/aTR/oXvBmNXrR+0sLdX3nCyLVsZizswSvlJoyg5eiiJt+ppWb41GLfa/v4MDxKi1IYmvKbUrpYx3xIZV0npJ4bjNSRpe317p0pmaFgJ0QkD8FvSJN5tDL7824tZFiJ6xECM65B6v4lMeyXJQHhMBbGPDiQyqjzXam49G7xv7zeR2tiMTXmER5cT+8hAoh8diBMNBfHMxTaIq9eUwoSc4FgeVhp047sOudboeIpUbTPpTXHSW1uD3pJsxcgdEMVvDVoFveY0TiwUvDeDS3BibpB0bWgitSGOiezqEYmOH0CmIRG8/7XNWGsp+dhgokcOyh2TNu2TrutQWcl+2fntLfCtaZKNbbgZE5ShNegdiowuJzy6PKgMDIzmeimstWS2t5FY00By3c4geRhWSnhY0IpMtkXXen62NTw4/vyWdPAFl63kB4/Zf66DTXtBBTzp7UrqSkO55NmrT5BpSOK3pnMVHxNygpbcRGZXS3jznq2P7UlQaHAsGOIwOBZUxA+r7PT5T6xtYOdf1pGpayN6+IAgmZ40BBNyyGTPK35rGuNmK2YhE7SYVwaV5X1VZrpq+LAZn/S2VpyIizsgigkHcfaTHpltrUGi65ggQRsYwykPB+eNbA8AISfoYQl1/kK22fd59y/w9lZrP+kFlUzXAdcEvTih3vtSt2mP9Pbgs9Z+WncqIjilob2e5/2UR+KNHTiVkU49kX5rmuT7cdK1cfy0nzuOnbIwZZ8YgVsR9Dz0VuNSp31pb6nvprzdVZS6XFfGJ/1B0NMRGVVOeEz5XuPR3viUrmsls601OO85htCQGO6gWDBsqIvvzvSWFtre2IFNe+R6hEpDRA8fSLiqbI/vPa8xmxA4JqjX7qVyno8YHwjr26BnL+XnvledWCj4Xnf3fowl396J35LGqQx6KNt719uHL+HTadiTu1vDX77F43G2b99ORUUFQ4YMKcgw1Pbkw3ZMQAyY7PHU/hyz/wnIocDzPFw3vw361lp27NhBPB5nwoQJneYpkemB3U82ac/nrmXrWPq3d5nmu3wqHGVMNz2OTkWYyNhKQkNiQYKwrS1oXcxWKstqRlAx/TAMBC1w7wVjIWMfGRgMOemQ6FjfYpNe7ovfGEOqNk7LS1toXbktaFEjOHFGJ1QSGV2ercQEFRmvMUmmro10XRs2kSFcla1gVZWRer+J1uVbSa5rDDbmtn/h72qVDQ2MYUpCpDc3k1zfFLTAZ1sKTdghNLwUm/bwGlM96/7sKl6VEcLDS3cN0Uhkgop4tpJvoi7GNcGYWi875CTbdW0cQ+SwCkprRlIyeQgm7ND2+naaHtsQtKa3M0EL8u6thRC06oWryoIW+MYgicOz2ZatCE52KFRQ4YpgQi6Z7W2kt7WSqWvFKQ0TPXwA0cMHBImta4Ju44wftLhnu7X9RAa3PIw7KIZbGQUgs72VdPuwi2wLXO5YsTbXWhsZU0HJ0UP3+IJJb23BT3hBy1v2i7M9eU6s3kGiOcGgaWMIjyzb43WZurag1yRbFggSkdSmOJktrYTHlO8xJtprSZPZ2kJ4ZPfd1rl1ZVuZ9zUWe3/l4rS/r/ODnpve/lI7VComvcFm/CDB3JmAkENocAynrOfD0oLWZJtLKHpTf4rzoUoxzj/FOP/i8Ti1tbVMnDixqK+lO5T1RSIDQX1mzZo1TJo0qdN0JTI90N3Jprahlf9euZmHVm5m69ZmPorD8NIIoweVMGZgKeNDIUa0ZCjdkcTsTAYt4R8fTunRQ7EZS9PS92l5aUunbsL2oSO5ISfDSjCxEH5TEi+e7jRW3ISdoAUl7FAyZRilU4aRqU+QfK+R1LogIdqDIbiYMOwELVIdujzdwTHKPjGC0mOH9eiCQ5vtTg8q382dWkPdARGckvCulgjP4sRCuBXhbGtimPYueuv5NH+wk9DOoIUts70tGF4Qc4PXDIgQHlVOZHR5MDxiP09G1rO0vVaHn8wQHhVUyJ2Ii/UsmYZE7sLOyOjyXGtk7rXZbtXebGEtFH1p5p9i3DcU5/xTjPNPMc6/9kRm98qv9J6+SmQAVq9evV+JjC7234cxg0q57DMf4bLPfIS3tsR5cs023trSxDNbm3l3zWZS3q7xRVFjGNGUYexrbRxWW8ew8iiRCocBnx7GhE1tlA6MMWzSUKqOHIwbcshsb6NtTT2JtQ1gLeFhA4OLJ8tCuYvcbMojNLSE0mOHdxr7Wn5CVXBBXzK4yLf9Ykm3MhIM08le02PT2SFbHzQTHlpCZPyA/erWNCGHyOggwYARBxXLUMzL2wnduIbSqcO7nB4eWkJ4aPfD+9rHq4qIiIgciPLycpqbmwtdjA8dJTL74WMjK/jYyF0V8Yzns3lngo0NrWysb+X9+lY2NrSxsb6Vv725le3NXfSWvPwuJWGXqgExEmmP1rRHW8oj5BhKoyHKIi4lkeCxNBqiNOxS1tZMRV0DFbEQZdEQEdch5BpCTvAYdg2u4xB2DNGdKWLNbUTDLrGwQyzsEqsIERs0GBN2CQH9/7YFIiIiItLfKZE5CCHX4bAhpRw2pOv70FtrSXuWZMajLe3x/o5W3t7WzNtbm9kaT1ASdimNuJSEXTK+pTXl0ZrK0JL0aEtnaGpLs6WxjZakR1MiTXMyQ2+MBAy7hljI7ZTsVMZCDCmPMrQ8yqDSMMmMT2sqQ3P2OpjKWIgBJWEqS8LBYyx4LIm4ZDyfjG9Jez6OMdnkyiHkBI/hbOLlpxL4oRjl0RBuh98syPgWx5jcNBEREZFiZK3ln//5n3nkkUcwxnDDDTdw/vnn88EHH3D++efT1NREJpNh/vz5fPKTn+Sb3/wmy5cvxxjDRRddxJw5cwq9C0VFiUweGWOIhAyRkENFLMzwihg14w/8vtzWBslOOps4ZDyb+9vzfVKZIGlKZnwSaY9E2ieZ8XJ/5x47TGuf39SWYWN9K//3/k52tqaIhhzKokEPEEBTW5rGtjSZ/bjF4N5EQw5+NtFrVxJ2KY+FKI+GiIZ2JUCxkEtlSYjKWJiKWJiSSDAvEgqSpXR7HDxL2vdJZywZP4hLuD2Zyq4v4u5KriIhh4jrEA51mJZ9DLvB+9a+XG5a+/zsa13H0JYOEtDWpEcqWw7Pt/jWUhYN5coe63ALb5u9FaRl111+lMiJiIgcnB/9+Q3e3Ny07wX3w1GjKrnxi5N7tOyf/vQnVq5cyauvvsr27ds57rjjOPnkk/n973/P6aefzvXXX4/nebS2trJy5Uo2bdrE66+/DsDOnTt7tdwfBkpkiogxJpdYFIK1lra0R2M2qWlqy9CW9gg7hlC2Ut/eC5Xx/Vyi1f68oamFjAnRnMzQlvJws68LO4aMb2lJZmhJZYgnMqQyu3p5EmmPDTtaaWpL05TIkEh7XSZUrmM69AIFiUHGt6QzQRk6Xs9UCB1uZ98lY8glU6URl8qSMJWxEKWRIGbB/qfxfEssHPTkRcMuJdletZKwi4NPLBoh5AT77/tBj1fGz74PHZLg3DTfZ/fQhByTS/Si4eAxEnKIhlxCjsG3Nrh/hQ0Stvbb8wMdlm1PVn2SGZ9U+z8veIyFXYaVRxlWEWVwWQTPtyTSQe+lb8klnSHXwWLxPJtN2i2eDR4zniUSciiPupRFQ0RDLi3JDE2JNE1t6exnxqU8GqY8FqIiGiTK5bEQYdd0SOZ3PSay2y+N7Oox9W17j6lHvKWN8rKSXPk6JbxOsM+etfj+roQ2uPleUNb29bqOQyoTbDeVCXozd61vV/wjIQeDwRIkv+1laU5maE1lMBgGl0UYUh5hcFmEsOvgGIMBUp7PztY0Da0pdramsdjckNSI61AZC1NZEqIiFu6USO+eaAf3KrG5Yze4q7rBNQZnXzcMsZZEOujhjYZdyiLuPm/m4fdSg4mISF979tln+cpXvoLruowYMYJTTjmFl19+meOOO46LLrqIdDrNOeecw7HHHsvhhx/OunXruOKKK/jCF77AaaedVujiFx0lMtJjxhhKI0HFumrA/v82Tm/evcX3g8Qk41vCriHsOD2qULUnR+0V6rTXnuh0eN5xfqbDNC9YLt3htRnPUhJxctc1Bb1EQVLnGIIEJBEkIW0pL7inQLaSabL3mM/dedn3SXmWVManLZ3JJYstqQwVsRCjB5UwoCSMa0zQo5bxaUu1964FCWZbKoOlLZdIBpXjIGEMOSZ3bVU4+xgLm10V312/RZctSxCH1pZMLhFJZnwyvo9rgluDB7/hFeyrYwwWcsulMh6Os6sXKxrK9oJlK+iNbWle39TI9uZkxxvr4TpBBbm7xLN9vptN1trfq44cA+XR4Dc4mpMZPFWM92lfiXZ3Qo4JksRYiPJoGM/3aU0F1/61poLEtKOwaxhUGqGyJIzn207HS/sx59tgvSVhl5JI9l/271jIxbOWZMYnmfY6PSbSXvY37oIEK/gcGoKffzFUxMKMHBBj1MAYw8qjpLMNKM3JoEe1JbXrb2Mg1OH6w45DZjO+DT57GY90xlJZEmJgaYSBJWGc7DEXTwaNLsPKo4waGGPUwBJKIy71LUFi2dCSwrO20+fHZG8X7phdyWL79Pbht+370z7Pzf6eh83eFrM9ASXbwLDr5z06JqfBND+TZkB5Sa4HvC17zWYi7RF2HQaVRRhcFgwlTmb8oLEpmcG3UJJNyGNhN9eA5WWTd9fJxr/D57S9zO2fXyfb8NRxudx8J2gYaS9LyvMZVBqhakCMwWXBXSfrmpO8V9fChh2thNxsMl8WpTwWojmxqzEj49tcw0445DCgJMyg0giDSsOEXSd3rLalg/Nz0CDm4Lom97pdj07ueVffN+3Hc6zDb811x8t+F7W/Z+2fjVAf/v5Kf9XTnpN86e5uwCeffDLLli3jL3/5CxdeeCHXXHMNf//3f8+rr77KY489xu23387ixYu5++67+7jExU2JjBQlxzHEnP27bYHJVurDrkNpZN/LF6NivNWn51ua2tLBMMKwS9jd9WOSwZe9DSqV2cpEVxWEZMajJemRzHiUR0OURUK5ikZ7j0A8maY5EVRUm5MZ0p4lFgp6s6Jhh1goqJRFQ0Fi15YOKrbtvYftFelUWyvR0tJcEtxe+W7vfXQMe1TOQm5QOU2k/VxlMeP7RENuLrFrTwI7JtLtvVjtv5faXqEtjbiUR0OURkN4vqW+JUV9S5L6ljSe72d7y8B1YFBZhEHtlWzH5IZgJtM+8USaeLbSl8nG2eyWaLdXqs1uya6f7RlLZvxcXOOJTHDjkmzyUZpLQEKUhB1Snh9U5FtSNCXShFynUw9ebrin69Dc2kbGuEEvXYekKJEO3o+BJWGiFdHcexb0HLo4hl09Yu29YdmeyaZEmg8a23hjcyPbm1OEnKCXuzwaoizbq1ceDTGsPPu7T/6uYaueb2nOZMh4lpAbHA8DSoKerKZEmo31raxqTeNbGyR1sTDRkMPqD5p4fPVWkpkOd7gMOQwui+xKQrK9Xn4u+ejY4xmUf1dPH7m/95V0Zn9+K/eZ6fi+QvB7aV2tIhJyyHg+h2L+H8n2uLekDux3zHpLLOxQGglREnbxfEs8kc6VKewaBpQEyZJrLGmfXK9vMju8u+Ow6o5cxxALOUSzx3X78d2xx7TjKdDQ3fSAZ3c1FqQzPm7uGtmgh71zsrnrX9gNGi7LIsHnwrOWxtbsaIxEOnt+MbnE28k+QtAIlch+Xj0/+Dy0X18bCTkdljcdEvZd55j23t7SqEtFhyHu9S1Bz/LOthQhx8l+bkN4mRTHDUnzwc42vFwmz57BYNfnoeP5tP18Hfz0367PYu7E2/Wq9nhmge3xJFOPO5F7/us3nHf+V2nc2cDTTy9j7k0/44233qFq1Gi+/LVvsL2hkf998WVOPOXvCIfDnHL6WQweOZYrv30x9S2pXDw6PbLrOXTVa74riTLZA2LXZ77D89yxYjqcI3b9eGfHc0YxUCIjIgXlOoZBZXtmliabAIR6kK9GQy7RbhY0xuRa9YfvR443gK5/ADRu0lRUxHq+Ijkg+U7K23sO+oK1lh0tKRJpj8FlEUojvfPV257sd6yYQc8rIU1NTURLy0ikgwS6JBwk8+3DUpsSaepbUjQlMsTCDmWRoOLoGLLXBnrZnuZdPb+OodOQyva/24eF+tky70o0d/3LvcYGDQIl2SGz4ZDDjuYUW5sSfNCYIJnxGD+kjPFDyxg/pDSXzO9oSdGSzFCRvRlNRXYIaftw2mTGp6kt6BGrb0mR8W2HZDs4f7QPWfV8m7v+NNOhjJlsr0si29DRmvIIO86u6zvDDvFEJqhwt6ZoS6YoK4l2SkraH8Ou0ymxzHhBktOe7CTTfq6n0be7etxy7/9ux0JX0x1jco0EYdfB822n4bReduhxMrNr2G4mO4y3Ndvo05LycI1hQGmYgdmb/hh2Vfo7JuK+DRL1krDLsIoojoGmRHAN7httaVKezQ1JziXvudfuWl9wPOx5zLqOoTIWyg1Hb1/mP86uYkdLqtPogj0+L9n/cr2THXoye4O1sLmxjWNPPo2lzzxLzcenYozh8utupMUt56G//pkFd95GKBymtLSMm351JyvfepcffvdyrB80dFx53Q+pbWjttTIdjEGlEcYO7vpmVocS/SBmVjG2ZBcbxTj/FOP8U4z7huKcf4px/vWHGOda+fuwld5me3vjiWA4IwS9yxXRPXvb6xubaKz7gKOOOmq/t+N36L21dlfvkNPFvu5ZW94teWwfsplNzNqT3449o53+3m1a+yp275Hd/TrFIKntvC5nt56U3YeXdnpOhyTOdv88FnYYmB2+oh/EFBEREZGiU4hhRsYEQ41j2Z6d7pYpiQQ/H9F0gGV0jMFxzQFWhotn+FV/pqvKRERERESk6CiRERERERGRoqNERkREREREio4SGRERERERKTpKZEREREREpOgokRERERERkaKjREZERERERIqOEhkRERERkYNwzjnn8IlPfILJkydz1113AfDoo4/y8Y9/nClTpjB9+nQAmpubmT17NtXV1RxzzDHcf//9hSx20dMPYoqIiIhI//DIdbBlVe+uc2Q1nHnLXhe5++67GTx4MG1tbRx33HHMmDGDiy++mGXLljFhwgTq6+sB+MlPfsKAAQNYtSooY0NDQ++W9UNGiYyIiIiIyEG47bbbeOCBBwDYuHEjd911FyeffDITJkwAYPDgwQA8/vjj3HfffbnXDRo0qO8L248okRERERGR/mEfPSf58NRTT/H444/z/PPPU1payqmnnsqUKVN466239ljWWosxps/L2F/pGhkRERERkQPU2NjIoEGDKC0tZc2aNbzwwgskk0mefvpp3nvvPYDc0LLTTjuNf/u3f8u9VkPLDo4SGRERERGRA3TGGWeQyWQ45phj+MEPfsC0adMYNmwYd911F+eddx5Tpkzh/PPPB+CGG26goaGBo48+milTprB06dICl764aWiZiIiIiMgBikajPPLII13OO/PMMzs9Ly8v57e//W1fFOtDQT0yIiIiIiJSdJTIiIiIiIhI0VEiIyIiIiIiRUeJjIiIiIiIFB0lMiIiIiIiUnSUyIiIiIiISNFRIiMiIiIiIkVHiYyIiIiIyCHK8zymTp3KWWed1Wn6r3/9az72sY8xefJk/vmf/7lApSss/SCmiIiIiMgh6tZbb2XSpEk0NTXlpi1dupT//u//5rXXXiMajbJt27YClrBwlMiIiIiISL/w85d+zpr6Nb26zomDJ3Lt8dfudZlzzjmHjRs3kkgkuOqqq/jWt75FeXk5zc3NACxZsoSHH36YBQsWsHXrVi655BLWrVsHwPz58/nkJz/Z5Xpra2v5y1/+wvXXX88vf/nL3PT58+dz3XXXEY1GARg+fHhv7GrR0dAyEREREZGDcPfdd7NixQqWL1/Obbfdxo4dO7pd9sorr+SUU07h1Vdf5ZVXXmHy5MndLnv11Vfzi1/8AsfpXGVfu3YtzzzzDCeccAKnnHIKL7/8cq/tSzFRj4yIiIiI9Av76jnJl9tuu40HHngAgI0bN/L22293u+yTTz7JPffcA4DrugwYMKDL5R5++GGGDx/OJz7xCZ566qlO8zKZDA0NDbzwwgu8/PLLfPnLX2bdunUYY3pnh4qEemRERERERA7QU089xeOPP87zzz/Pq6++ytSpU0kkEp2SikQisd/rfe6553jooYcYP348s2bN4sknn+RrX/saAGPGjOG8887DGMPxxx+P4zhs37691/apWCiRERERERE5QI2NjQwaNIjS0lLWrFnDCy+8AMCIESNYvXo1vu/nemsApk+fzvz584HgjmQdL+Lv6Gc/+xm1tbWsX7+e++67j89+9rP87ne/A4Jrcp588kkgGGaWSqUYOnRoPnfzkKRERkRERETkAJ1xxhlkMhmOOeYYfvCDHzBt2jQAbrnlFs466yw++9nPUlVVlVv+1ltvZenSpVRXV/OJT3yCN954Y7+3edFFF7Fu3TqOPvpoZs2axW9/+9sP3bAy0DUyIiIiIiIHLBqN8sgjj3Q5b+bMmXtMGzFiBP/93/+9X9s49dRTOfXUU3PPI5FIrnfmw0w9MiIiIiIiUnTUIyMiIiIiUiA7duxg+vTpe0x/4oknGDJkSAFKVDyUyIiIiIiIFMiQIUNYuXJloYtRlDS0TEREREREio4SGRERERERKTpKZEREREREpOj0KJExxpxhjHnLGPOOMea6vSx3nDHGM8bsea85ERERERGRXrLPRMYY4wK3A2cCRwFfMcYc1c1yPwce6+1CioiIiIh8mCxYsIDLL78cgLlz5zJv3rwCl+jQ05MemeOBd6y166y1KeA+YEYXy10B3A9s68XyiYiIiIgUDWstvu8XuhgfCj25/fJoYGOH57XACR0XMMaMBs4FPgsc12ulExERERHpoS0330xy9ZpeXWd00kRGfv/7e11m/fr1nHnmmXzmM5/h+eef55xzzuHhhx8mmUxy7rnn8qMf/QiAe+65h3nz5mGM4ZhjjuHee+/lz3/+MzfddBOpVIohQ4awcOFCRowYsV9lPPXUU5k6dSorVqygrq6Oe+65h5/97GesWrWK888/n5tuuumA9/9Q1pNExnQxze72/FfAtdZaz5iuFs+uyJhvAd8CGDt2LPF4vIfFzL+WlpZCF6HfU4zzTzHOP8W4byjO+acY559inH8tLS34vo/neQBY32L3qKYeHOvb3Pq743keb731Fr/5zW/44he/yJ/+9Ceef/55rLWcc845LF26lCFDhvDTn/6UZcuWMXToUOrr6/E8jxNPPJHnnnsOYwz/+Z//yS233MK8efPwfR9rg237vt9pP/coo7WEQiGWLl3KbbfdxowZM3jppZcYPHgwRx55JFdeeeUB/7hmX/Yu+b6/X/lBTxKZWmBsh+djgM27LVMD3JdNYoYCnzfGZKy1D3ZcyFp7F3AXQE1Nja2oqOhxQfvCoVae/kgxzj/FOP8U476hOOefYpx/inH+NTQ04LouAFU3XF+QMriuy7hx4zjppJP4p3/6J/72t79RU1MDQHNzM+vWreP1119n5syZud6WYcOGAfDBBx/w1a9+lQ8++IBUKsWECRNwXRfHcTDG5P52HCe3n7szxnDOOefgui5Tpkxh8uTJjBkzBoDDDz+czZs3M3z48IPav77gOM5+fWZ6co3My8BHjTETjDERYBbwUMcFrLUTrLXjrbXjgSXApbsnMSIiIiIi/VVZWRkQ9I5873vfY+XKlaxcuZJ33nmHb37zm1hr6Wrk0hVXXMHll1/OqlWr+Pd//3cSicQBbT8ajQJBMtD+d/vzTCZzQOs81O0zkbHWZoDLCe5GthpYbK19wxhziTHmknwXUERERESkWJx++uncfffdNDc3A7Bp0ya2bdvG9OnTWbx4MTt27ACgvr4egMbGRkaPHg3Ab3/728IUukj1ZGgZ1tq/An/dbdqd3Sz7jYMvloiIiIhI8TnttNNYvXo1J554IgDl5eX87ne/Y/LkyVx//fWccsopuK7L1KlTWbBgAXPnzuX//b//x+jRo5k2bRrvvfdegfegeBhre/eCqJ6qqamxy5cvL8i2uxKPxzWONc8U4/xTjPNPMe4binP+Kcb5pxjnXzwep7a2lkmTJhW6KP2W53l9do3M6tWr93gvjTErrLU1XS3fk2tkREREREREDik9GlomIiIiIiKFddlll/Hcc891mnbVVVcxe/bsApWosJTIiIiIiIgUgdtvv73QRTikaGiZiIiIiIgUHSUyIiIiIiJSdJTIiIiIiIhI0VEiIyIiIiIiRUeJjIiIiIjIIWb58uVceeWV3c7fvHkzM2fO7MMSHXp01zIRERERkTzb3x+WrKmpoaamy9+BBGDUqFEsWbKkN4pWtJTIiIiIiEi/8MzitWzf2Nyr6xw6tpxPf/nIvS6zfv16zjjjDE444QT+7//+jyOPPJJ77rmHo446iosuuoj/+Z//4fLLL2fw4MHceOONJJNJjjjiCP7rv/6L8vJyXn75Za666ipaWlqIRqM88cQTrFixgnnz5vHwww/z9NNPc9VVVwFgjGHZsmXs2LGDs846i9dff51EIsG3v/1tli9fTigU4pe//CWf+cxnWLBgAQ899BCtra28++67nHvuufziF7/odj/Ky8u57LLLePzxxxk0aBA333wz11xzDRs3buRXv/oVZ599dq/G9mBpaJmIiIiIyEF66623+Na3vsVrr71GZWUld9xxBwCxWIxnn32Wv/u7v+Omm27i8ccf55VXXqGmpoZf/vKXpFIpzj//fG699VZeffVVHn/8cUpKSjqte968edx+++2sXLmSZ555Zo/57b8vs2rVKv7whz/w9a9/nUQiAcDKlStZtGgRq1atYtGiRWzcuLHbfWhpaeHUU09lxYoVVFRUcMMNN/DYY4/xwAMP8MMf/rA3w9Ur1CMjIiIiIv3CvnpO8mns2LGcdNJJAHzta1/jtttuA+D8888H4IUXXuDNN9/MLZNKpTjxxBN56623qKqq4rjjjgOgsrJyj3WfdNJJfOc73+GCCy7gvPPOY8yYMZ3mP/vss1xxxRUATJw4kXHjxrF27VoApk+fzoABAwA46qij2LBhA2PHju1yHyKRCGeccQYA1dXVRKNRwuEw1dXVrF+//oBjky9KZEREREREDpIxpsvnZWVlAFhr+dznPscf/vCHTsu99tpre7x2d9dddx1f+MIX+Otf/8q0adN4/PHHicViufnW2m5fG41Gc3+7rksmk+l22XA4nCuL4zi51zqOs9fXFYqGlomIiIiIHKT333+f559/HoA//OEPfOpTn+o0f9q0aTz33HO88847ALS2trJ27VomTpzI5s2befnllwGIx+N7JA3vvvsu1dXVXHvttdTU1LBmzZpO808++WQWLlwIwNq1a3n//ff52Mc+lpf9PJQokREREREROUiTJk3it7/9Lccccwz19fV8+9vf7jR/2LBhLFiwgK985Sscc8wxTJs2jTVr1hCJRFi0aBFXXHEFU6ZM4XOf+1zu+pZ2v/rVrzj66KOZMmUKJSUlnHnmmZ3mX3rppXieR3V1Neeffz4LFizo1BPTX5m9dUXlU01NjV2+fHlBtt2VeDxORUVFoYvRrynG+acY559i3DcU5/xTjPNPMc6/eDxObW0tkyZNKmg51q9fn7uDWH+zv7eNPhirV6/e4700xqyw1nZ5H2r1yIiIiIiISNHRxf4iIiIiIgdh/PjxRdUbc8IJJ5BMJjtNu/fee6muri5QiQ6MEhkRERERkQ+RF198sdBF6BUaWiYiIiIiIkVHiYyIiIiIiBQdJTIiIiIiIlJ0lMiIiIiIiEjRUSIjIiIiInIQbrvtNiZNmsSXvvQlTjzxRKLRKPPmzSt0sfo93bVMREREROQg3HHHHTzyyCOUlZWxYcMGHnzwwUIX6UNBiYyIiIiI9AtLF9zFtg3renWdw8cdzme+8a1u519yySWsW7eOs88+m4suuog5c+bwl7/8ZZ/rXb9+PWeccQaf+tSneOGFF5gyZQqzZ8/mxhtvZNu2bSxcuJDjjz++N3el39HQMhERERGRA3TnnXcyatQoli5dypw5c/brte+88w5XXXUVr732GmvWrOH3v/89zz77LPPmzePmm2/OU4n7D/XIiIiIiEi/sLeek0PRhAkTqK6uBmDy5MlMnz4dYwzV1dWsX7++sIUrAuqREREREREpgGg0mvvbcZzcc8dxyGQyhSpW0VAiIyIiIiIiRUdDy0REREREesGWLVuoqamhqakJx3H41a9+xZtvvkllZWWhi9YvKZERERERETkIHa9nqa2t7dFrxo8fz+uvv557vmDBgm7nSdc0tExERERERIqOemRERERERPJkx44dTJ8+fY/pTzzxBEOGDClAifoPJTIiIiIiInkyZMgQVq5cWehi9EsaWiYiIiIiIkVHiYyIiIiIiBQdJTIiIiIiIlJ0lMiIiIiIiEjRUSIjIiIiItJHysvLu523fv16jj766D4sTXFTIiMiIiIiIkVHt18WERERkX5h55/fJbW5pVfXGRlVxsAvHtHt/GuvvZZx48Zx6aWXAjB37lyMMSxbtoyGhgbS6TQ33XQTM2bM2K/tJhIJvv3tb7N8+XJCoRC//OUv+cxnPsMbb7zB7NmzSaVS+L7P/fffz6hRo/jyl79MbW0tnufxgx/8gPPPP/+g9rsYKJERERERETlAs2bN4uqrr84lMosXL+bRRx9lzpw5VFZWsn37dqZNm8bZZ5+NMabH67399tsBWLVqFWvWrOG0005j7dq13HnnnVx11VVccMEFpFIpPM/jr3/9K6NGjeIvf/kLAI2Njb2/o4cgJTIiIiIi0i/sreckX6ZOncq2bdvYvHkzdXV1DBo0iKqqKubMmcOyZctwHIdNmzaxdetWRo4c2eP1Pvvss1xxxRUATJw4kXHjxrF27VpOPPFEfvrTn1JbW8t5553HRz/6Uaqrq/mnf/onrr32Ws466yw+/elP52t3Dym6RkZERERE5CDMnDmTJUuWsGjRImbNmsXChQupq6tjxYoVrFy5khEjRpBIJPZrndbaLqd/9atf5aGHHqKkpITTTz+dJ598kiOPPJIVK1ZQXV3N9773PX784x/3xm4d8tQjIyIiIiJyEGbNmsXFF1/M9u3befrpp1m8eDHDhw8nHA6zdOlSNmzYsN/rPPnkk1m4cCGf/exnWbt2Le+//z4f+9jHWLduHYcffjhXXnkl69at47XXXmPixIkMHjyYr33ta5SXl7NgwYLe38lDkBIZEREREZGDMHnyZOLxOKNHj6aqqooLLriAL37xi9TU1HDssccyceLE/V7npZdeyiWXXEJ1dTWhUIgFCxYQjUZZtGgRv/vd7wiHw4wcOZIf/vCHvPzyy1xzzTU4jkM4HGb+/Pl52MtDj+mu2yrfampq7PLlywuy7a7E43EqKioKXYx+TTHOP8U4/xTjvqE4559inH+Kcf7F43Fqa2uZNGlSoYvSb3meh+u6fbKt1atX7/FeGmNWWGtrulpe18iIiIiIiEjR0dAyEREREZE+tGrVKi688MJO06LRKC+++GKBSlSclMiIiIiIiPSh6upqVq5cWehiFD0NLRMRERERkaKjREZERERERIqOEhkRERERESk6SmRERERERKToKJEREREREekj5eXlhS5Cv6FERkREREREio5uvywiIiIi/cIjjzzCli1benWdI0eO5Mwzz+x2/rXXXsu4ceO49NJLAZg7dy7GGJYtW0ZDQwPpdJqbbrqJGTNm7HNbzc3NzJgxo8vX3XPPPcybNw9jDMcccwz33nsvW7du5ZJLLmHdunUAzJ8/n09+8pO9sNfFQYmMiIiIiMgBmjVrFldffXUukVm8eDGPPvooc+bMobKyku3btzNt2jTOPvtsjDF7XVcsFuOBBx7Y43VvvvkmP/3pT3nuuecYOnQo9fX1AFx55ZWccsopPPDAA3ieR3Nzc97391CiREZERERE+oW99Zzky9SpU9m2bRubN2+mrq6OQYMGUVVVxZw5c1i2bBmO47Bp0ya2bt3KyJEj97ouay3f//7393jdk08+ycyZMxk6dCgAgwcPBuDJJ5/knnvuAcB1XQYMGJDfnT3EKJERERERETkIM2fOZMmSJWzZsoVZs2axcOFC6urqWLFiBeFwmPHjx5NIJPa5nu5eZ63dZ2/Oh5Eu9hcREREROQizZs3ivvvuY8mSJcycOZPGxkaGDx9OOBxm6dKlbNiwoUfr6e5106dPZ/HixezYsQMgN7Rs+vTpzJ8/HwDP82hqasrD3h26epTIGGPOMMa8ZYx5xxhzXRfzLzDGvJb997/GmCm9X1QRERERkUPP5MmTicfjjB49mqqqKi644AKWL19OTU0NCxcuZOLEiT1aT3evmzx5Mtdffz2nnHIKU6ZM4Tvf+Q4At956K0uXLqW6uppPfOITvPHGG3nbx0ORsdbufQFjXGAt8DmgFngZ+Iq19s0Oy3wSWG2tbTDGnAnMtdaesLf11tTU2OXLlx9s+XtNPB6noqKi0MXo1xTj/FOM808x7huKc/4pxvmnGOdfPB6ntraWSZMmFboo/Zbnebiu2yfbWr169R7vpTFmhbW2pqvle9IjczzwjrV2nbU2BdwHdLp/nLX2f621DdmnLwBj9rvkIiIiIiIiPdSTi/1HAxs7PK8F9tbb8k3gkYMplIiIiIhIf7Vq1SouvPDCTtOi0SgvvvhigUpUnHqSyHR1i4Qux6MZYz5DkMh8qpv53wK+BTB27Fji8XgPi5l/LS0thS5Cv6cY559inH+Kcd9QnPNPMc4/xTj/Wlpa8H0fz/MKXZT9ctRRR7FixYo9ph+K++H7fp9ua3/yg54kMrXA2A7PxwCbd1/IGHMM8BvgTGvtjq5WZK29C7gLgmtkDrVxo4daefojxTj/FOP8U4z7huKcf4px/inG+dfQ0NBn13B8WPVVfB3H2a/PTE+ukXkZ+KgxZoIxJgLMAh7quIAx5jDgT8CF1tq1+1FeERERERGR/bbPHhlrbcYYcznwGOACd1tr3zDGXJKdfyfwQ2AIcEf2x3oy3d1dQERERERE5GD1ZGgZ1tq/An/dbdqdHf7+B+AferdoIiIiIiIiXevRD2KKiIiIiMjBKy8vL+j2m5qaGD16NJdffnlumrWW66+/niOPPJJJkyZx2223FbCEPdejHhkRERERESl+P/jBDzjllFM6TVuwYAEbN25kzZo1OI7Dtm3bClS6/aNERkRERET6hbVrf0K8eXWvrrOifBJHHvmDbudfe+21jBs3jksvvRSAuXPnYoxh2bJlNDQ0kE6nuemmm5gxY0a362jX3NzMjBkz9njd+vXrOeuss3j99dcBmDdvHs3NzcydO5d33nmHSy65hLq6OlzX5Y9//CNHHHFEl+tfsWIFW7du5YwzzmD58uW56fPnz+f3v/89jhMM1ho+fHiP41NIGlomIiIiInKAZs2axaJFi3LPFy9ezOzZs3nggQd45ZVXWLp0Kd/97nextsufYewkFovt9+suuOACLrvsMl599VX+93//l6qqqi6X832f7373u/zLv/zLHvPeffddFi1aRE1NDWeeeSZvv/32Pst6KFCPjIiIiIj0C3vrOcmXqVOnsm3bNjZv3kxdXR2DBg2iqqqKOXPmsGzZMhzHYdOmTWzdupWRI0fudV3WWr7//e/v8bruxONxNm3axLnnngsEiVB37rjjDj7/+c8zduzYPeYlk0lisRjLly/nT3/6ExdddBHPPPNMDyNQOEpkREREREQOwsyZM1myZAlbtmxh1qxZLFy4kLq6OlasWEE4HGb8+PEkEol9rqe714VCIXzfzy3Xvq6e9PK0e/7553nmmWe44447aG5uJpVKUV5ezi233MKYMWP40pe+BMC5557L7Nmz9zMChaGhZSIiIiIiB2HWrFncd999LFmyhJkzZ9LY2Mjw4cMJh8MsXbqUDRs29Gg93b1uxIgRbNu2jR07dpBMJnn44YcBqKysZMyYMTz44INA0LPS2tra5boXLlzI+++/z/r165k3bx5///d/zy233ALAOeecw5NPPgnA008/zZFHHnkw4egzSmRERERERA7C5MmTicfjjB49mqqqKi644AKWL19OTU0NCxcuZOLEiT1aT3evC4fD/PCHP+SEE07grLPO6rS+e++9l9tuu41jjjmGT37yk2zZsmW/y3/ddddx//33U11dzfe+9z1+85vf7Pc6CsHsT5dUb6qpqbEd75ZQaPF4nIqKikIXo19TjPNPMc4/xbhvKM75pxjnn2Kcf/F4nNraWiZNmlToovRbnufhum6fbGv16tV7vJfGmBXW2pqullePjIiIiIiIFB1d7C8iIiIi0odWrVrFhRde2GlaNBrlxRdfPKTXfahRIiMiIiIi0oeqq6tZuXJl0a37UKOhZSIiIiIiUnSUyIiIiIiISNFRIiMiIiIiIkVHiYyIiIiIiBQdJTIiIiIiIn2kvLy8z7c5d+5c5s2bB8A3vvENlixZ0udlyAclMiIiIiIihxjP8wpdhEOebr8sIiIiIv3CD96u5fXmtl5d59HlJfzko2O6nX/ttdcybtw4Lr30UiDo/TDGsGzZMhoaGkin09x0003MmDFjn9t66qmn+NGPfkRVVRUrV65k1apVXHfddTz11FMkk0kuu+wy/vEf/xGAX/ziF9x77704jsOZZ57JLbfcwn/8x39w1113kUql+MhHPsK9995LaWnpfu3v+PHj+epXv8rSpUtJp9PMnz+fG264gXfeeYdrrrmGSy65ZL/Wl09KZEREREREDtCsWbO4+uqrc4nM4sWLefTRR5kzZw6VlZVs376dadOmcfbZZ2OM2ef6XnrpJV5//XUmTJjAXXfdxYABA3j55ZdJJpOcdNJJnHbaaaxZs4YHH3yQF198kdLSUurr6wE477zzuPjiiwG44YYb+M///E+uuOKK/d6nsWPH8vzzzzNnzhy++c1v8txzz5FIJJg8ebISGRERERGR3ra3npN8mTp1Ktu2bWPz5s3U1dUxaNAgqqqqmDNnDsuWLcNxHDZt2sTWrVsZOXLkPtd3/PHHM2HCBAD+53/+h9deey13TUtjYyNvv/02jz/+OLNnz871tgwePBiA119/nRtuuIGdO3fS3NzM6aeffkD7dPbZZwPBj2vG43EqKiqoqKggFouxc+dOBg4ceEDr7W1KZEREREREDsLMmTNZsmQJW7ZsYdasWSxcuJC6ujpWrFhBOBxm/PjxJBKJHq2rrKws97e1ll//+td7JCSPPvpol7073/jGN3jwwQeZMmUKCxYs4Kmnnjqg/YlGowA4jpP7u/15JpM5oHXmgy72FxERERE5CLNmzeK+++5jyZIlzJw5k8bGRoYPH044HGbp0qVs2LDhgNZ7+umnM3/+fNLpNABr166lpaWF0047jbvvvpvW1laA3NCyeDxOVVUV6XSahQsX9s7OHcLUIyMiIiIichAmT55MPB5n9OjRVFVVccEFF/DFL36Rmpoajj32WCZOnHhA6/2Hf/gH1q9fz8c//nGstQwbNowHH3yQM844g5UrV1JTU0MkEuHzn/88N998Mz/5yU844YQTGDduXG5YWH9mrLUF2XBNTY1dvnx5Qbbdlfbxf5I/inH+Kcb5pxj3DcU5/xTj/FOM8y8ej1NbW8ukSZMKXZR+y/M8XNftk22tXr16j/fSGLPCWlvT1fIaWiYiIiIiIkVHQ8tERERERPrQqlWruPDCCztNi0ajvPjii31WhnPPPZf33nuv07Sf//znB3yns0JQIiMiIiIi0oeqq6tZuXJlQcvwwAMPFHT7vUFDy0REREREpOgokRERERERkaKjREZERERERIqOEhkRERERkT5SXl7e59t86KGHuOWWW7qdv3z5cq688so+LFHv0MX+IiIiIiJFZH9/2+Xss8/m7LPP7nZ+TU0NNTVd/lTLIU2JjIiIiIj0Cz/68xu8ubmpV9d51KhKbvzi5G7nX3vttYwbN45LL70UgLlz52KMYdmyZTQ0NJBOp7npppuYMWPGPrf11FNP8cMf/pAhQ4bw1ltvcfLJJ3PHHXfgOA7l5eV85zvf4bHHHuNf//VfWb9+PbfddhupVIoTTjiBO+64A9d1efTRR/n+97+P53kMHTqUJ554ggULFrB8+XL+7d/+jT/+8Y/86Ec/wnVdBgwYwLJly3jqqaeYN28eDz/8MPX19Vx00UWsW7eO0tJS5s+fz9SpU5k7dy7vv/8+69at4/333+fqq6/uthdn/fr1nHHGGXzqU5/ihRdeYMqUKcyePZsbb7yRbdu2sXDhQo4//vgDe0M60NAyEREREZEDNGvWLBYtWpR7vnjxYmbPns0DDzzAK6+8wtKlS/nud7+LtbZH63vppZf413/9V1atWsW7777Ln/70JwBaWlo4+uijefHFFxkyZAiLFi3iueeeY+XKlbiuy8KFC6mrq+Piiy/m/vvv59VXX+WPf/zjHuv/8Y9/zGOPPcarr77KQw89tMf8G2+8kalTp/Laa69x8803M3v27Ny8NWvW8Nhjj/HSSy/xox/9iHQ63e1+vPPOO1x11VW89tprrFmzht///vc8++yzzJs3j5tvvrlHsdgX9ciIiIiISL+wt56TfJk6dSrbtm1j8+bN1NXVMWjQIKqqqpgzZw7Lli3DcRw2bdrE1q1bGTly5D7Xd/zxx3P44YcD8JWvfIVnn32WmTNn4rouX/rSlwB44oknWLFiBccddxwAbW1tDB8+nBdeeIGTTz6ZCRMmADB48OA91n/SSSfxjW98gy9/+cucd955e8x/9tlnuf/++wH47Gc/y44dO2hsbATgC1/4AtFolGg0yvDhw9m6dStjxozpcj8mTJhAdXU1AJMnT2b69OkYY6iurmb9+vX7jENPKJERERERETkIM2fOZMmSJWzZsoVZs2blekdWrFhBOBxm/PjxJBKJHq3LGNPl81gslrsuxlrL17/+dX72s591Wvahhx7a4/W7u/POO3nxxRf5y1/+wrHHHrvHD3N21XPUvs5oNJqb5roumUym2+10XNZxnNxzx3H2+rr9oaFlIiIiIiIHYdasWdx3330sWbKEmTNn0tjYyPDhwwmHwyxdupQNGzb0eF0vvfQS7733Hr7vs2jRIj71qU/tscz06dNZsmQJ27ZtA6C+vp4NGzZw4okn8vTTT/Pee+/lpu/u3Xff5YQTTuDHP/4xQ4cOZePGjZ3mn3zyySxcuBAIrtkZOnQolZWVPS5/X1KPjIiIiIjIQZg8eTLxeJzRo0dTVVXFBRdcwBe/+EVqamo49thjmThxYo/XdeKJJ3LdddexatUqTj75ZM4999w9ljnqqKO46aabOO200/B9n3A4zO233860adO46667OO+88/B9n+HDh/O3v/2t02uvueYa3n77bay1TJ8+nSlTpvD000/n5s+dO5fZs2dzzDHHUFpayt13333ggckz09MLj3pbTU2NXb58eUG23ZV4PE5FRUWhi9GvKcb5pxjnn2LcNxTn/FOM808xzr94PE5tbS2TJk0qdFF6Rce7hx0q9vdWzwdj9erVe7yXxpgV1tou7w2toWUiIiIiIlJ0NLRMRERERKQPrVq1igsvvLDTtGg0yosvvsipp55amEIdgB07djB9+vQ9pj/xxBMMGTIk79tXIiMiIiIi0oeqq6v3uFtYMRoyZEhB90NDy0REREREpOgokRERERERkaKjREZERERERIqOEhkRERERESk6SmRERERERPpIeXn5Xudfc801TJ48mWuuuYZly5bx8Y9/nFAoxJIlS/qohMVDdy0TERERETlE/Pu//zt1dXVEo1HWr1/PggULmDdvXqGLdUhSIiMiIiIi/cMj18GWVb27zpHVcOYt3c6+9tprGTduHJdeeikAc+fOxRjDsmXLaGhoIJ1Oc9NNNzFjxox9burss8+mpaWFE044ge9973ucf/75ADjOvgdRPfXUU9x4442MGDGClStXct5551FdXc2tt95KW1sbDz74IEcccUQPd7o4aGiZiIiIiMgBmjVrFosWLco9X7x4MbNnz+aBBx7glVdeYenSpXz3u9/FWrvPdT300EOUlJSwcuXKXBKzP1599VVuvfVWVq1axb333svatWt56aWX+Id/+Ad+/etf7/f6DnXqkRERERGR/mEvPSf5MnXqVLZt28bmzZupq6tj0KBBVFVVMWfOHJYtW4bjOGzatImtW7cycuTIvJbluOOOo6qqCoAjjjiC0047DQh+gHPp0qV53XYhKJERERERETkIM2fOZMmSJWzZsoVZs2axcOFC6urqWLFiBeFwmPHjx5NIJPJejmg0mvvbcZzcc8dxyGQyed9+X1MiIyIiIiJyEGbNmsXFF1/M9u3befrpp1m8eDHDhw8nHA6zdOlSNmzYUOgi9ku6RkZERERE5CBMnjyZeDzO6NGjqaqq4oILLmD58uXU1NSwcOFCJk6ceEDrffnllxkzZgx//OMf+cd//EcmT57cyyUvbqYnFx7lQ01NjV2+fHlBtt2VeDxORUVFoYvRrynG+acY559i3DcU5/xTjPNPMc6/eDxObW0tkyZNKnRR+i3P83Bdt0+2tXr16j3eS2PMCmttTVfLq0dGRERERESKjq6RERERERHpQ6tWreLCCy/sNC0ajfLiiy/m9bX9jRIZEREREZE+VF1dzcqVK/v8tf2NhpaJiIiIiEjRUSIjIiIiIiJFR4mMiIiIiIgUHSUyIiIiIiIHoby8vNBF+FDqUSJjjDnDGPOWMeYdY8x1Xcw3xpjbsvNfM8Z8vPeLKiIiIiJSHDzPK3QR+r19JjLGGBe4HTgTOAr4ijHmqN0WOxP4aPbft4D5vVxOEREREZFD2lNPPcVnPvMZvvrVr1JdXV3o4vR7Pbn98vHAO9badQDGmPuAGcCbHZaZAdxjrbXAC8aYgcaYKmvtB71e4jz4+Us/5426N/rsV0s/rPryl2E/rBTj/FOM+4binH+Kcf4pxvnneR4XV13Me43vAfAfr/1H7u/eMmHABC4+5uK9LmOxvNf4Hh80f8CLL73Io//7KGPHj+31svSVWChGVVlVoYuxTz1JZEYDGzs8rwVO6MEyo4FOiYwx5lsEPTaMHTuWeDy+v+XNi1Qqpe6/PqAY559inH+Kcd9QnPNPMc4/xTj/cjG2ed5QT9afXWbKx6cwdtzY/Jcpj6xvc7H1fb/Ptuv7/n7lBz1JZEwX03Z/a3qyDNbau4C7AGpqamxFRUUPNp9/P/jUD4jH4xwq5emvFOP8U4zzTzHuG4pz/inG+acY5188Hqe2tpYJAycAcPOnby5IOQyGCQMnsKF8A0MGDMmVp7/oq55Fx3H26zPTk4v9a4GxHZ6PATYfwDIiIiIiIiK9oieJzMvAR40xE4wxEWAW8NBuyzwE/H327mXTgMZiuT5GRERERESKzz6HlllrM8aYy4HHABe421r7hjHmkuz8O4G/Ap8H3gFagdn5K7KIiIiIyKGjubkZgFNPPZVTTz21sIX5EOnJNTJYa/9KkKx0nHZnh78tcFnvFk1ERERERKRrPfpBTBERERERkUOJEhkRERERESk6SmREREREpKgFVzlIMTuQ91CJjIiIiIgUrVgsxo4dO5TMFDFrLTt27CAWi+3X63p0sb+IiIiIyKFozJgx1NbWUldXV+ii9Eu+7+M4+e/7iMVijBkzZr9eo0RGRERERIpWOBxmwoQJhS5GvxWPx6moqCh0MbqkoWUiIiIiIlJ0lMiIiIiIiEjRUSIjIiIiIiJFxxTqDg/GmDpgQ0E23rWhwPZCF6KfU4zzTzHOP8W4byjO+acY559inH+Kcf4VOsbjrLXDuppRsETmUGOMWW6trSl0OfozxTj/FOP8U4z7huKcf4px/inG+acY59+hHGMNLRMRERERkaKjREZERERERIqOEpld7ip0AT4EFOP8U4zzTzHuG4pz/inG+acY559inH+HbIx1jYyIiIiIiBQd9ciIiIiIiEjR+dAnMsaYM4wxbxlj3jHGXFfo8vQHxpixxpilxpjVxpg3jDFXZafPNcZsMsaszP77fKHLWuyMMeuNMauy8VyenTbYGPM3Y8zb2cdBhS5nsTLGfKzD8brSGNNkjLlax/LBMcbcbYzZZox5vcO0bo9bY8z3sufot4wxpxem1MWlmxj/izFmjTHmNWPMA8aYgdnp440xbR2O5zsLVvAi002cuz0/6Fjef93EeFGH+K43xqzMTtexfAD2Um875M/LH+qhZcYYF1gLfA6oBV4GvmKtfbOgBStyxpgqoMpa+4oxpgJYAZwDfBlottbOK2T5+hNjzHqgxlq7vcO0XwD11tpbssn5IGvttYUqY3+RPV9sAk4AZqNj+YAZY04GmoF7rLVHZ6d1edwaY44C/gAcD4wCHgeOtNZ6BSp+UegmxqcBT1prM8aYnwNkYzweeLh9Oem5buI8ly7ODzqWD0xXMd5t/r8CjdbaH+tYPjB7qbd9g0P8vPxh75E5HnjHWrvOWpsC7gNmFLhMRc9a+4G19pXs33FgNTC6sKX6UJkB/Db7928JTkZy8KYD71prD6Uf8i1K1tplQP1uk7s7bmcA91lrk9ba94B3CM7dshddxdha+z/W2kz26QvAmD4vWD/TzbHcHR3LB2BvMTbGGIJG0j/0aaH6mb3U2w758/KHPZEZDWzs8LwWVbh7VbZ1ZCrwYnbS5dlhDXdryFOvsMD/GGNWGGO+lZ02wlr7AQQnJ2B4wUrXv8yi85eljuXe1d1xq/N0flwEPNLh+QRjzP8ZY542xny6UIXqR7o6P+hY7n2fBrZaa9/uME3H8kHYrd52yJ+XP+yJjOli2od3rF0vM8aUA/cDV1trm4D5wBHAscAHwL8WrnT9xknW2o8DZwKXZbvgpZcZYyLA2cAfs5N0LPcdnad7mTHmeiADLMxO+gA4zFo7FfgO8HtjTGWhytcPdHd+0LHc+75C5wYmHcsHoYt6W7eLdjGtIMfyhz2RqQXGdng+BthcoLL0K8aYMMGHYaG19k8A1tqt1lrPWusD/4G61A+atXZz9nEb8ABBTLdmx7u2j3vdVrgS9htnAq9Ya7eCjuU86e641Xm6Fxljvg6cBVxgsxfJZoeH7Mj+vQJ4FziycKUsbns5P+hY7kXGmBBwHrCofZqO5QPXVb2NIjgvf9gTmZeBjxpjJmRbXGcBDxW4TEUvO2b1P4HV1tpfdphe1WGxc4HXd3+t9Jwxpix7UR7GmDLgNIKYPgR8PbvY14H/LkwJ+5VOrX46lvOiu+P2IWCWMSZqjJkAfBR4qQDlK3rGmDOAa4GzrbWtHaYPy97MAmPM4QQxXleYUha/vZwfdCz3rr8D1lhra9sn6Fg+MN3V2yiC83KoEBs9VGTv3HI58BjgAndba98ocLH6g5OAC4FV7bdEBL4PfMUYcyxB9+N64B8LUbh+ZATwQHD+IQT83lr7qDHmZWCxMeabwPvA/ytgGYueMaaU4M6GHY/XX+hYPnDGmD8ApwJDjTG1wI3ALXRx3Fpr3zDGLAbeJBgOdZnu8rRv3cT4e0AU+Fv2vPGCtfYS4GTgx8aYDOABl1hre3oB+4daN3E+tavzg47lA9NVjK21/8me1y2CjuUD1V297ZA/L3+ob78sIiIiIiLF6cM+tExERERERIqQEhkRERERESk6SmRERERERKToKJEREREREZGio0RGRERERESKjhIZEREREREpOkpkRERERESk6CiRERERERGRovP/AYVP/5juijoqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"FF_WOE\"\n",
    "EPOCHS = 200\n",
    "PATIENCE = 200\n",
    "BATCH_SIZE = 8\n",
    "HIDDEN_LAYERS = [10]\n",
    "ACTIVATION = 'relu'\n",
    "L_RATE = 0.001\n",
    "model_name = '{}_ep{}_pa{}_bs{}_hs{}_lr_{}_{}'.format(base_model_name,EPOCHS,PATIENCE,BATCH_SIZE,HIDDEN_LAYERS,L_RATE,ACTIVATION)\n",
    "model_name\n",
    "model = get_FFNN_model(X_train, y_onehot, HIDDEN_LAYERS)\n",
    "\n",
    "model_path = os.path.join(RESULT_PATH, model_name)\n",
    "\n",
    "forge_gen = True\n",
    "\n",
    "if not os.path.exists(model_path) or forge_gen:\n",
    "    history = net_train(model, model_path, X_train, y_train, X_test, y_test, EPOCHS, save_model=True, VERBOSE=2)    \n",
    "    \n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    plt.figure(figsize=(14,6))\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.history[key], label=key)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(alpha=.2)\n",
    "    plt.title(f'batch_size = {BATCH_SIZE}, epochs = {EPOCHS}')\n",
    "    plt.draw()\n",
    "else:\n",
    "    print('Model loaded.')\n",
    "    model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: \n",
      "acc: 74.21%\n",
      "Test Set: \n",
      "acc: 71.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 780,  444],\n",
       "       [ 298, 1093]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores = model.evaluate(X_onehot_train.values, y_onehot_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# scores = model.evaluate(X_onehot_test.values, y_onehot_test)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "confusion_matrix(y_test, model.predict_classes(X_test), sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_kf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x000001838F983D88>, <tensorflow.python.keras.layers.core.Dense object at 0x0000018391ED7348>]\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 38us/sample - loss: 0.5595 - acc: 0.7285 - auc_48: 0.7936 - recall_m: 0.7944 - precision_m: 0.6921 - f1_m: 0.7302\n",
      "2\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x0000018391ED7108>, <tensorflow.python.keras.layers.core.Dense object at 0x000001839468BA08>]\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 41us/sample - loss: 0.5552 - acc: 0.7141 - auc_50: 0.7896 - recall_m: 0.7069 - precision_m: 0.6829 - f1_m: 0.6861\n",
      "3\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x0000018391ED4E48>, <tensorflow.python.keras.layers.core.Dense object at 0x000001839341F808>]\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 40us/sample - loss: 0.5453 - acc: 0.7337 - auc_52: 0.7988 - recall_m: 0.7907 - precision_m: 0.6957 - f1_m: 0.7299\n",
      "4\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x0000018391ED4BC8>, <tensorflow.python.keras.layers.core.Dense object at 0x00000183958392C8>]\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2092/2092 [==============================] - 0s 46us/sample - loss: 0.5526 - acc: 0.7242 - auc_54: 0.7917 - recall_m: 0.7534 - precision_m: 0.6951 - f1_m: 0.7128\n",
      "5\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x00000183946873C8>, <tensorflow.python.keras.layers.core.Dense object at 0x00000183959CEE88>]\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2091/2091 [==============================] - 0s 48us/sample - loss: 0.5474 - acc: 0.7212 - auc_56: 0.7985 - recall_m: 0.7482 - precision_m: 0.6879 - f1_m: 0.7081\n",
      "\u001b[1m\n",
      "Mean Accuracy=  0.7244 , Sd=  0.0066\n",
      "Mean AUC=  0.7945 , Sd=  0.0037\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if run_kf:\n",
    "    n_folds = 5\n",
    "    kf = KFold(n_splits = n_folds, random_state = 1, shuffle = True)\n",
    "    \n",
    "    fold = 0\n",
    "    result_metrics_list = []\n",
    "    for train_idx, val_idx in kf.split(X1):\n",
    "        fold += 1\n",
    "        print(fold)\n",
    "        X_train = X1.iloc[train_idx]\n",
    "        y_train = y_onehot.iloc[train_idx]\n",
    "        X_val = X1.iloc[val_idx]\n",
    "        y_val = y_onehot.iloc[val_idx]\n",
    "\n",
    "        model = get_FFNN_model(X_train, y_train, HIDDEN_LAYERS)\n",
    "        history = net_train(model, model_path, X_train, y_train, X_val, y_val, EPOCHS, save_model=False, VERBOSE=False)    \n",
    "        score = model.evaluate(X_val, y_val)\n",
    "      \n",
    "        result_metrics_list.append([score])\n",
    "        \n",
    "    print(\"\\033[1m\")\n",
    "    print(\"Mean Accuracy= \",\"{:.4}\".format(np.mean(result_metrics_list,axis=0)[0][1]),\", Sd= \",\"{:.2}\".format(np.std(result_metrics_list,axis=0)[0][1]))\n",
    "    print(\"Mean AUC= \",\"{:.4}\".format(np.mean(result_metrics_list,axis=0)[0][2]),\", Sd= \",\"{:.2}\".format(np.std(result_metrics_list, axis=0)[0][2]))\n",
    "    print(\"\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Weights and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = os.path.join('results')\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: \n",
      "acc: 73.57%\n",
      "Test Set: \n",
      "acc: 72.20%\n"
     ]
    }
   ],
   "source": [
    "new_model = load_model(checkpoint_dir,  compile=False)\n",
    "new_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.1),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy',recall_m,precision_m])\n",
    "\n",
    "def get_train_test_accuracy(model):\n",
    "    # scores = model.evaluate(X_onehot_train.values, y_onehot_train)\n",
    "    scores = model.evaluate(X_onehot_train, y_onehot_train, verbose=0)\n",
    "    print(\"Training Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    # scores = model.evaluate(X_onehot_test.values, y_onehot_test)\n",
    "    scores = model.evaluate(X_onehot_test, y_onehot_test, verbose = 0)\n",
    "    print(\"Test Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "get_train_test_accuracy(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.72275335\n"
     ]
    }
   ],
   "source": [
    "baseline_model_accuracy = model.evaluate(\n",
    "    X_onehot_test, y_onehot_test, verbose=0)[1]\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 0.001 0.0001\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_dense_10 (None, 10)                3712      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 10)                41        \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_11 (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 3,776\n",
      "Trainable params: 1,891\n",
      "Non-trainable params: 1,885\n",
      "_________________________________________________________________\n",
      "Train on 5883 samples, validate on 1961 samples\n",
      "Epoch 1/3\n",
      "5883/5883 [==============================] - 2s 260us/sample - loss: 0.6288 - acc: 0.7178 - recall_m: 0.7542 - precision_m: 0.7215 - val_loss: 0.7146 - val_acc: 0.6512 - val_recall_m: 0.9392 - val_precision_m: 0.5988\n",
      "Epoch 2/3\n",
      "5883/5883 [==============================] - 1s 111us/sample - loss: 0.6218 - acc: 0.7182 - recall_m: 0.7424 - precision_m: 0.7287 - val_loss: 0.6841 - val_acc: 0.6910 - val_recall_m: 0.8998 - val_precision_m: 0.6368\n",
      "Epoch 3/3\n",
      "5883/5883 [==============================] - 1s 113us/sample - loss: 0.6149 - acc: 0.7180 - recall_m: 0.7489 - precision_m: 0.7254 - val_loss: 0.6321 - val_acc: 0.7160 - val_recall_m: 0.8365 - val_precision_m: 0.6779\n",
      "Baseline test accuracy: 0.72275335\n",
      "Pruned test accuracy: 0.7086042\n"
     ]
    }
   ],
   "source": [
    "run = True\n",
    "if run is not None:\n",
    "    import tensorflow_model_optimization as tfmot\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "    # Compute end step to finish pruning after 2 epochs.\n",
    "    validation_split = .25 # 10% of training set will be used for validation set. \n",
    "\n",
    "    num_images = X_onehot_train.shape[0] * (1 - validation_split)\n",
    "    end_step = np.ceil(num_images / BATCH_SIZE).astype(np.int32) * EPOCHS\n",
    "    initial_sparsity = 0.001\n",
    "    final_sparsity = 0.0001\n",
    "\n",
    "    print(end_step,initial_sparsity,final_sparsity)\n",
    "\n",
    "    # Define model for pruning.\n",
    "    pruning_params = {\n",
    "          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
    "                                                                   final_sparsity=final_sparsity,\n",
    "                                                                   begin_step=0,\n",
    "                                                                   end_step=end_step)\n",
    "    }\n",
    "\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy',recall_m,precision_m])\n",
    "\n",
    "    model_for_pruning.summary()\n",
    "    \n",
    "    import tempfile\n",
    "    logdir = tempfile.mkdtemp()\n",
    "    EPOCHS = 3\n",
    "\n",
    "\n",
    "    callbacks = [\n",
    "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "      tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(X_onehot_train, y_onehot_train,\n",
    "                      batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=validation_split,\n",
    "                      callbacks=callbacks)\n",
    "    \n",
    "    # strip dropped parameters and evaluate accuracy\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "    model_for_export.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model_for_pruning_accuracy = model_for_export.evaluate(\n",
    "       X_onehot_test, y_onehot_test, verbose=0)[1]\n",
    "\n",
    "    print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "    print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # fit and evaluate a model\n",
    "# def evaluate_model(trainX, trainy, testX, testy, n_kernel):\n",
    "# \tverbose, epochs, batch_size = 1, 10, 10\n",
    "# \tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv1D(filters=10, kernel_size=n_kernel, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "# # \tmodel.add(Conv1D(filters=64, kernel_size=n_kernel, activation='relu'))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "# \tmodel.add(MaxPooling1D(pool_size=2))\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(10, activation='relu'))\n",
    "# \tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "# \tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \t# fit network\n",
    "# \tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# \t# evaluate model\n",
    "# \t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "# \treturn accuracy\n",
    " \n",
    "# # summarize scores\n",
    "# def summarize_results(scores, params):\n",
    "# \tprint(scores, params)\n",
    "# \t# summarize mean and standard deviation\n",
    "# \tfor i in range(len(scores)):\n",
    "# \t\tm, s = mean(scores[i]), std(scores[i])\n",
    "# \t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "# \t# boxplot of scores\n",
    "# \tpyplot.boxplot(scores, labels=params)\n",
    "# \tpyplot.savefig('exp_cnn_kernel.png')\n",
    " \n",
    "# # run an experiment\n",
    "# def run_experiment(params, repeats=10):\n",
    "# \t# load data\n",
    "# \ttrainX, trainy, testX, testy = np.expand_dims(X_onehot_train,axis=2) ,y_onehot_train , np.expand_dims(X_onehot_test,axis=2) , y_onehot_test\n",
    "# \t# test each parameter\n",
    "# \tall_scores = list()\n",
    "# \tfor p in params:\n",
    "# \t\t# repeat experiment\n",
    "# \t\tscores = list()\n",
    "# \t\tfor r in range(repeats):\n",
    "# \t\t\tscore = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "# \t\t\tscore = score * 100.0\n",
    "# \t\t\tprint('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "# \t\t\tscores.append(score)\n",
    "# \t\tall_scores.append(scores)\n",
    "# \t# summarize results\n",
    "# \tsummarize_results(all_scores, params)\n",
    " \n",
    "# # run the experiment\n",
    "# n_params = [2]\n",
    "# run_experiment(n_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
